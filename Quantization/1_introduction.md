# A Survey of Quantization Methods for Efficient Neural Network Inference(効率的なニューラルネットワーク推論のための量子化手法に関する調査)  

**Abstract**
抽象的な数学計算がデジタルコンピュータ上で実行可能になると同時に, これらの計算における数値の効率的な表現, 操作, 通信の問題が生じました. 数値表現の問題と密接に関連する問題として量子化があります. すなわち, 連続する実数値の集合を固定された離散的な数値集合にどのように分布させるべきか, ビット数を最小化し, かつ計算精度を最大化するにはどうすればよいかという問題です. この恒常的な量子化問題は, メモリや計算リソースが厳しく制限されている場合に特に重要であり, 近年, コンピュータビジョン, 自然言語処理, 関連分野におけるニューラルネットワークモデルの顕著な性能により, 注目を集めています. 浮動小数点表現から4ビット以下の低精度固定整数値への移行は, メモリフットプリントとレイテンシーを16倍削減する可能性があり, 実際, これらのアプリケーションでは4倍から8倍の削減がしばしば実現されています. そのため, 量子化がニューラルネットワークに関連する計算の効率的な実装における重要かつ活発な研究サブ領域として最近台頭してきたことは驚くべきことではありません. この記事では, 深層ニューラルネットワーク計算における数値を量子化する問題に対するアプローチを調査し, 現在の方法の利点と欠点を網羅します. この調査とその構成により, ニューラルネットワークのための量子化に関する現在の研究の有用なスナップショットを提供し, この分野における今後の研究の評価を容易にするインテリジェントな組織化を実現することを期待しています. 


## introduction
過去10年間にわたり, 広範な問題に対するニューラルネットワーク（NN）の精度が著しく向上してきましたが, これは主に非常に過剰にパラメータ化されたモデルによって達成されています. これらの過剰パラメータ化された（したがって非常に大きな）NNモデルの精度は大幅に向上しましたが, これらのモデルの非常に大きなサイズは, 多くのリソース制約のあるアプリケーションに展開することができないことを意味します. これは, リソース制約のある環境でリアルタイム推論, 低エネルギー消費, および高精度を必要とする遍在するディープラーニングを実現するための問題を引き起こします. この遍在するディープラーニングは, リアルタイムのインテリジェントなヘルスケアモニタリング, 自律走行, オーディオ分析, および音声認識など, 広範なアプリケーションに大きな影響を与えると期待されています. 最適な精度を持つ効率的でリアルタイムなNNを達成するには, NNモデルの設計, トレーニング, および展開を再考する必要があります [71]. これらの問題に対処するために, NNモデルをより効率的に（遅延, メモリフットプリント, エネルギー消費などの点で）しながら, 最適な精度/一般化トレードオフを提供することに焦点を当てた大規模な文献があります. これらの取り組みは, 大きく次のように分類できます. 

A) 効率的なNNモデルアーキテクチャの設計：一つの研究の流れは, マイクロアーキテクチャ [101, 111, 127, 167, 168, 212, 253, 280]（例えば, 深層畳み込みや低ランク因数分解などのカーネルタイプ）およびマクロアーキテクチャ [100, 101, 104, 110, 214, 233]（例えば, 残差モジュールやインセプションモジュールなどのモジュールタイプ）の観点から, NNモデルアーキテクチャを最適化することに焦点を当てています. ここでの古典的な技術は, 主に手動検索を使用して新しいアーキテクチャモジュールを見つけることでしたが, これはスケーラブルではありません. そのため, 新しい研究の流れとして, AutoML（自動機械学習）およびニューラルアーキテクチャ検索（NAS）手法を設計することがあります. これらは, モデルサイズ, 深さ, および/または幅の制約の下で, 適切なNNアーキテクチャを自動的に見つけることを目的としています [161, 194, 232, 245, 252, 291]. NAS手法の最近の調査については [54] をご参照ください. 

B) NNアーキテクチャとハードウェアを共同設計する：もう一つの最近の研究の流れは, 特定のターゲットハードウェアプラットフォームに適応させるためにNNアーキテクチャを共同設計（コーデザイン）することです. これは, NNコンポーネントのオーバーヘッド（遅延やエネルギーの観点から）がハードウェアに依存するため重要です. 例えば, 専用のキャッシュ階層を持つハードウェアは, そのようなキャッシュ階層を持たないハードウェアよりも帯域幅に依存する操作をはるかに効率的に実行できます. NNアーキテクチャ設計と同様に, アーキテクチャとハードウェアの共同設計の初期のアプローチは手動で行われ, 専門家がNNアーキテクチャを適応/変更しました [70]. その後, 自動化されたAutoMLおよび/またはNAS技術が使用されました [22, 23, 100, 252]. 

C) プルーニング：NNのメモリフットプリントと計算コストを削減するもう一つのアプローチは, プルーニングを適用することです. プルーニングでは, 感度（サリエンシー）の低いニューロンを削除し, 疎な計算グラフを作成します. ここで, 感度が低いニューロンとは, 削除してもモデルの出力/損失関数にほとんど影響を与えないニューロンです. プルーニング手法は, 大きく分けて非構造化プルーニング [49, 86, 139, 143, 191, 257] と構造化プルーニング [91, 106, 156, 166, 274, 275, 279] に分類できます. 非構造化プルーニングでは, 感度の低いニューロンが存在する場所に関係なく削除されます. このアプローチでは, 非常に多くのNNパラメータを削除しても, モデルの一般化性能にほとんど影響を与えない, 積極的なプルーニングが可能です. しかし, このアプローチは疎行列操作を引き起こし, これは加速が難しく, 通常はメモリに依存します [21, 66]. 一方, 構造化プルーニングでは, パラメータのグループ（例：全体の畳み込みフィルター）が削除されます. これにより, 層および重み行列の入力および出力形状が変更されるため, 依然として密な行列操作が可能です. しかし, 積極的な構造化プルーニングは, しばしば精度の大幅な低下を引き起こします. 高いレベルのプルーニング/スパース性を維持しながら, 最先端のパフォーマンスを保つトレーニングと推論は, 依然として未解決の問題です [16]. プルーニング/スパース性に関連する作業の詳細な調査については, [66, 96, 134] を参照してください. 

d) 知識蒸留：モデル蒸留 [3, 95, 150, 177, 195, 207, 269, 270] では, 大規模なモデルをトレーニングし, それを教師として使用して, よりコンパクトなモデルをトレーニングします. 生徒モデルのトレーニング中に「ハード」なクラスラベルを使用する代わりに, モデル蒸留のキーアイデアは, 教師が生成する「ソフト」な確率を活用することです. これらの確率は入力についてのより多くの情報を含むことができます. 蒸留に関する多くの研究があるにもかかわらず, 蒸留だけで高い圧縮率を達成することは大きな課題です. 量子化やプルーニングと比べて, 知識蒸留の手法は積極的な圧縮では無視できない精度の低下が見られます. しかし, 知識蒸留を既存の方法（すなわち, 量子化およびプルーニング）と組み合わせることで大きな成功を収めています [195]. 

e) 量子化：最後に, 量子化はNNモデルのトレーニングと推論の両方で大きな一貫した成功を収めているアプローチです. 数値表現と量子化の問題はデジタルコンピューティングと同じくらい古いものですが, ニューラルネットワークは改善のためのユニークな機会を提供します. この量子化に関する調査は主に推論に焦点を当てていますが, 量子化の重要な成功はNNトレーニングにあることを強調すべきです [10, 35, 57, 130, 247]. 特に, 半精度と混合精度のトレーニングの突破口 [41, 72, 79, 175] が, AIアクセラレータで桁違いに高いスループットを可能にした主な推進力です. しかし, 半精度以下に下げることは大幅な調整なしには非常に難しいことが証明されており, 最近の量子化研究のほとんどは推論に焦点を当てています. この推論のための量子化がこの記事の焦点です. 

f) 量子化と神経科学：NN量子化に緩やかに関連する（および一部の人にとっては動機となる）神経科学の研究には, 人間の脳が情報を連続的な形式ではなく, 離散的/量子化された形式で保存することを示唆するものがあります [171, 236, 240]. この考えの一般的な理由は, 連続的な形式で保存された情報は, （私たちの脳を含む物理環境に常に存在し, 熱, 感覚, 外部, シナプスのノイズなどによって引き起こされる）ノイズによって必然的に破損するというものです [27, 58]. しかし, 離散的な信号表現はそのような低レベルのノイズに対してよりロバストである可能性があります. 他にも, 離散的表現の高い一般化力 [128, 138, 242] や限られたリソース下での高効率 [241] などの理由が提案されています. 神経科学の文献における関連研究の詳細なレビューについては [228] を参照してください. この研究の目的は, 量子化で使用されている現在の方法と概念を紹介し, この研究分野における現在の課題と機会を議論することです. そのために, 最も関連性のある研究について議論しようとしました. ニューラルネットワーク量子化のように広範な分野のすべての研究を短い調査のページ制限内で議論することは不可能であり, 関連する論文のいくつかを見逃したことは間違いありません. 読者および私たちが見落としたかもしれない論文の著者に事前にお詫び申し上げます. 

この調査の構成に関しては, まずセクションIIで量子化の簡単な歴史を提供し, その後セクションIIIで量子化の基本的な概念を紹介します. これらの基本的な概念はほとんどの量子化アルゴリズムと共有されており, 既存の方法を理解し展開するために必要です. 次に, セクションIVでより高度なトピックについて議論します. これらは主に最新の最先端の方法, 特に低精度/混合精度量子化に関するものです. 次に, セクションVでハードウェアアクセラレータにおける量子化の影響について, 特にエッジプロセッサに焦点を当てて議論します. 最後に, セクションVIIで要約と結論を提供します. 