{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前回の学習済みモデルから, カテゴリーに分けられた際にどの単語に注目したのかというものを見ていく. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 環境準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/master/.pyenv/versions/3.12.2/lib/python3.12/site-packages (4.42.3)\n",
      "Requirement already satisfied: fugashi in /Users/master/.pyenv/versions/3.12.2/lib/python3.12/site-packages (1.3.2)\n",
      "Requirement already satisfied: ipadic in /Users/master/.pyenv/versions/3.12.2/lib/python3.12/site-packages (1.0.0)\n",
      "Requirement already satisfied: filelock in /Users/master/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from transformers) (3.15.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /Users/master/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in /Users/master/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/master/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/master/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/master/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /Users/master/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/master/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/master/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/master/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/master/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/master/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/master/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/master/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/master/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/master/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from requests->transformers) (2024.6.2)\n",
      "Requirement already satisfied: demoji in /Users/master/.pyenv/versions/3.12.2/lib/python3.12/site-packages (1.1.0)\n",
      "Requirement already satisfied: neologdn in /Users/master/.pyenv/versions/3.12.2/lib/python3.12/site-packages (0.5.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers fugashi ipadic\n",
    "!pip install demoji\n",
    "!pip install neologdn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-07-05 12:53:52--  https://www.rondhuit.com/download/ldcc-20140209.tar.gz\n",
      "www.rondhuit.com (www.rondhuit.com) をDNSに問いあわせています... 59.106.19.174\n",
      "www.rondhuit.com (www.rondhuit.com)|59.106.19.174|:443 に接続しています... 接続しました。\n",
      "HTTP による接続要求を送信しました、応答を待っています... 200 OK\n",
      "長さ: 8855190 (8.4M) [application/x-gzip]\n",
      "`ldcc-20140209.tar.gz.2' に保存中\n",
      "\n",
      "ldcc-20140209.tar.g 100%[===================>]   8.44M  2.54MB/s 時間 3.3s       \n",
      "\n",
      "2024-07-05 12:53:56 (2.54 MB/s) - `ldcc-20140209.tar.gz.2' へ保存完了 [8855190/8855190]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget \"https://www.rondhuit.com/download/ldcc-20140209.tar.gz\"\n",
    "!tar -zxf ldcc-20140209.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 データの準備(jsonファイルの作成)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import demoji\n",
    "import neologdn\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **`glob`**: ファイルパスのパターンマッチングを行うライブラリです. \n",
    "* **`os`**: オペレーティングシステムとのインタラクションを提供するライブラリです. \n",
    "* **`json`**: JSON形式のデータの読み書きを行うライブラリです. \n",
    "* **`re`**: 正規表現処理を行うライブラリです. \n",
    "* **`demoji`**: 絵文字の処理を行うライブラリです. \n",
    "* **`neologdn`**: 現代日本語の表記ゆらぎの処理を行うライブラリです. \n",
    "* **`string`**: 文字列処理に関わる定数や関数を提供するライブラリです. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['movie-enter', 'it-life-hack', 'kaden-channel', 'topic-news', 'livedoor-homme', 'peachy', 'sports-watch', 'dokujo-tsushin', 'smax']\n"
     ]
    }
   ],
   "source": [
    "path = \"./text\"\n",
    "text_dir = os.listdir(path)\n",
    "category_list = [f for f in text_dir if os.path.isdir(os.path.join(path, f))]\n",
    "print(category_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 0, 'category': 'movie-enter'}, {'id': 1, 'category': 'it-life-hack'}, {'id': 2, 'category': 'kaden-channel'}, {'id': 3, 'category': 'topic-news'}, {'id': 4, 'category': 'livedoor-homme'}, {'id': 5, 'category': 'peachy'}, {'id': 6, 'category': 'sports-watch'}, {'id': 7, 'category': 'dokujo-tsushin'}, {'id': 8, 'category': 'smax'}]\n"
     ]
    }
   ],
   "source": [
    "id_category_list = []\n",
    "for index, category in enumerate(category_list):\n",
    "    category_dict = {\"id\": index, \"category\": category}\n",
    "    id_category_list.append(category_dict)\n",
    "print(id_category_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'file_name': 'movie-enter-6361791 3.txt', 'label': 0, 'category_name': 'movie-enter'}, {'file_name': 'movie-enter-5978741.txt', 'label': 0, 'category_name': 'movie-enter'}, {'file_name': 'movie-enter-6322901.txt', 'label': 0, 'category_name': 'movie-enter'}, {'file_name': 'movie-enter-6316535 2.txt', 'label': 0, 'category_name': 'movie-enter'}]\n"
     ]
    }
   ],
   "source": [
    "annotations_list = []\n",
    "for item in id_category_list:\n",
    "    file_list = glob.glob(f'text/{item[\"category\"]}/{item[\"category\"]}*.txt')\n",
    "    for file in file_list:\n",
    "        annotation_dict = {\"file_name\": os.path.basename(file), \"label\": item[\"id\"], \"category_name\": item[\"category\"]}\n",
    "        annotations_list.append(annotation_dict)\n",
    "print(annotations_list[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_dict = {\"category\": id_category_list, \"annotations\": annotations_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_save_path = \"./text/dataset.json\"\n",
    "with open(json_save_path, mode=\"wt\", encoding=\"utf-8\") as f:\n",
    "    json.dump(json_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Dataloader作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1182a2f70>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertJapaneseTokenizer\n",
    "torch.manual_seed(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"cl-tohoku/bert-base-japanese-whole-word-masking\"\n",
    "tokenizer = BertJapaneseTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LivedoorDataset(Dataset):\n",
    "    def __init__(self, tokenizer, text_dir=None):\n",
    "        self.text_dir = text_dir\n",
    "        self._load_json()\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self._get_text(self.annotations_list[idx][\"category_name\"], \n",
    "                              self.annotations_list[idx][\"file_name\"])\n",
    "        encoding = self.tokenizer(text, return_tensors=\"pt\", max_length=512, padding=\"max_length\", truncation=True)\n",
    "        encoding = {key: torch.squeeze(value) for key, value in encoding.items()}\n",
    "        encoding[\"labels\"] = self.annotations_list[idx][\"label\"]\n",
    "\n",
    "        return encoding\n",
    "    \n",
    "    def _load_json(self):\n",
    "        with open(os.path.join(self.text_dir, 'dataset.json')) as f:\n",
    "            self.text_json = json.load(f)\n",
    "        self.annotations_list = self.text_json[\"annotations\"]\n",
    "        \n",
    "    def _get_text(self, category_name, file_name):\n",
    "        file_path = os.path.join(self.text_dir, category_name, file_name)\n",
    "        lines = open(file_path).read().splitlines()\n",
    "        text = '\\n'.join(lines[3:]) # ファイルの4行目からを抜き出す. \n",
    "        text_preprocessed = self._text_preprocess(text)\n",
    "        return text_preprocessed\n",
    "        \n",
    "    def _text_preprocess(self, text):\n",
    "        # タブの消去\n",
    "        text = text.translate(str.maketrans({'\\n': '', '\\t': '', '\\r': '', '\\u3000': ''}))\n",
    "\n",
    "        # URLの消去\n",
    "        text = re.sub(r'http?://[\\w/:%#$&\\?~\\.=\\+\\-]+', '', text)\n",
    "        text = re.sub(r'https?://[\\w/:%#$&\\?~\\.=\\+\\-]+', '', text)\n",
    "\n",
    "        # 絵文字の消去\n",
    "        text = demoji.replace(string=text, repl='')\n",
    "\n",
    "        # 文字の正規化\n",
    "        text = neologdn.normalize(text)\n",
    "\n",
    "        # 数字をすべて0に\n",
    "        text = re.sub(r'\\d+', '0', text)\n",
    "\n",
    "        # 大文字を小文字に\n",
    "        text = text.lower()\n",
    "\n",
    "        # 【関連記事, 関連サイト, 関連リンク】以降の消去\n",
    "        target_list = ['関連記事', '関連サイト', '関連リンク']\n",
    "        for target in target_list:\n",
    "          idx = text.find(target)\n",
    "          text = text[:(idx-1)]\n",
    "\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 26933\n",
      "Train dataset size: 7000\n",
      "Validation dataset size: 19933\n"
     ]
    }
   ],
   "source": [
    "dataset = LivedoorDataset(tokenizer, \"./text\")\n",
    "print(f\"Dataset size: {len(dataset)}\")\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [7000, len(dataset)-7000])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8)\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 モデルのLoad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "  device = torch.device('mps')\n",
    "else:\n",
    "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=9).to(device)\n",
    "model = torch.load(\"./model.pth\").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このコードは, Transformerライブラリを使用して事前学習済みのモデルをインポートし, デバイスに設定するものです. このコードは, 自然言語処理タスク, 特にBERTモデルを使用したテキスト分類タスクによく使用されます. \n",
    "\n",
    "**コード解説**\n",
    "\n",
    "```python\n",
    "from transformers import BertForSequenceClassification\n",
    "```\n",
    "\n",
    "この行は, Transformerライブラリから`BertForSequenceClassification`クラスをインポートします. このクラスは, BERTモデルを使用してテキスト分類タスクを実行するために使用されます. \n",
    "\n",
    "```python\n",
    "if torch.backends.mps.is_available():\n",
    "  device = torch.device('mps')\n",
    "else:\n",
    "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "```\n",
    "\n",
    "この部分は, 計算に使用するデバイスを決定します. まず, `torch.backends.mps.is_available()`を使用して, AppleのMetal Performance Shaders (MPS) が利用可能かどうかを確認します. もし利用可能であれば, `device` を 'mps' に設定します. \n",
    "\n",
    "もしMPSが利用できない場合は, `torch.cuda.is_available()`を使用してCUDAが利用可能かどうかを確認します. CUDAが利用可能であれば, `device` を 'cuda' に設定します. \n",
    "\n",
    "いずれも利用できない場合は, `device` を 'cpu' に設定します. \n",
    "\n",
    "```python\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=9).to(device)\n",
    "```\n",
    "\n",
    "この行は, 事前学習済みのBERTモデルをインポートし, 設定します. \n",
    "\n",
    "- `BertForSequenceClassification.from_pretrained(model_name)`: この部分は, 指定されたモデル名 (例: \"bert-base-uncased\") の事前学習済みのBERTモデルをインポートします. \n",
    "- `num_labels=9`: この部分は, モデルの出力ラベルの数を9に設定します. これは, 分類タスクにおけるカテゴリの数を表します. \n",
    "- `.to(device)`: この部分は, モデルを `device` に設定します. これは, モデルの計算をCPUまたはGPUで行うことを指定します. \n",
    "\n",
    "```python\n",
    "model = torch.load(\"./model.pth\").to(device)\n",
    "```\n",
    "\n",
    "この行は, 保存されたモデルファイルをロードし, 設定します. \n",
    "\n",
    "- `torch.load(\"./model.pth\")`: この部分は, \"./model.pth\" ファイルに保存されたモデルをロードします. このファイルは, 以前にトレーニングされたモデルを保存したものです. \n",
    "- `.to(device)`: この部分は, モデルを `device` に設定します. これは, モデルの計算をCPUまたはGPUで行うことを指定します. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2aa153bce554469b01a9434777a66e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2492 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 94.9% 18910/19933\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "model.eval()\n",
    "labels_list, outputs_list = [], []\n",
    "\n",
    "with tqdm(val_dataloader, unit=\"batch\") as progress_bar:\n",
    "  for i, batch in enumerate(progress_bar):\n",
    "      batch = {key: value.to(device) for key, value in batch.items()}\n",
    "      labels_list = np.concatenate([labels_list, batch[\"labels\"].cpu().detach().numpy()])\n",
    "      output = model(**batch)\n",
    "      output = output.logits.argmax(axis=1).cpu().detach().numpy()\n",
    "      outputs_list = np.concatenate([outputs_list, output])\n",
    "\n",
    "accuracy = sum(outputs_list == labels_list) / len(outputs_list) * 100\n",
    "print(f\"accuracy: {round(accuracy, 1)}% {sum(outputs_list == labels_list)}/{len(outputs_list)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このコードは, バリデーションデータセットを使用してモデルの精度を評価し, 結果を出力するものです. このコードは, ニューラルネットワークモデルを評価する一般的な手法であり, 特に自然言語処理タスクにおいてよく用いられます. \n",
    "\n",
    "**コード解説**\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "```\n",
    "\n",
    "この行は, NumPyライブラリをインポートします. NumPyライブラリは, 数値計算やデータ操作に役立つライブラリです. \n",
    "\n",
    "```python\n",
    "model.eval()\n",
    "```\n",
    "\n",
    "この行は, モデルを評価モードに設定します. 評価モードでは, モデルはドロップアウトなどの学習時に行われる処理を行わず, 推論のみを行います. \n",
    "\n",
    "```python\n",
    "labels_list, outputs_list = [], []\n",
    "```\n",
    "\n",
    "この行は, 空のリスト `labels_list` と `outputs_list` を作成します. これらのリストは, それぞれバリデーションデータセットの正解ラベルとモデルの予測ラベルを格納するために使用されます. \n",
    "\n",
    "```python\n",
    "for i, batch in enumerate(val_dataloader):\n",
    "```\n",
    "\n",
    "この `for` ループは, バリデーションデータセットの各バッチを処理します. \n",
    "\n",
    "- `i`: バッチのインデックス\n",
    "- `batch`: バッチデータ\n",
    "\n",
    "```python\n",
    "batch = {key: value.to(device) for key, value in batch.items()}\n",
    "```\n",
    "\n",
    "この行は, バッチ内のすべてのキーと値を `device` に転送します. これは, モデルが計算を実行するデバイス (CPU または GPU) にデータを移動することを意味します. \n",
    "\n",
    "```python\n",
    "labels_list = np.concatenate([labels_list, batch[\"labels\"].cpu().detach().numpy()])\n",
    "```\n",
    "\n",
    "この行は, バッチの正解ラベル (`batch[\"labels\"]`) を `labels_list` に追加します. \n",
    "\n",
    "- `np.concatenate()`: NumPyライブラリの関数で, リストを連結するために使用されます. \n",
    "- `.cpu().detach().numpy()`: テンソルをCPUメモリに移動し, NumPy配列に変換します. \n",
    "\n",
    "```python\n",
    "output = model(**batch)\n",
    "```\n",
    "\n",
    "この行は, モデルにバッチデータを入力し, モデルの出力を取得します. \n",
    "\n",
    "- `model(**batch)`: モデルを呼び出し, バッチデータを引数として渡します. `**` は, 辞書のキーと値をアンパックするために使用されます. \n",
    "\n",
    "```python\n",
    "output = output.logits.argmax(axis=1).cpu().detach().numpy()\n",
    "```\n",
    "\n",
    "この行は, モデルの出力を処理し, 各サンプルに対する予測ラベルを取得します. \n",
    "\n",
    "- `output.logits`: モデルの出力を確率分布として表すテンソルを取得します. \n",
    "- `.argmax(axis=1)`: 各サンプルにおける確率分布の中で最も高い確率を持つインデックスを取得します (つまり, 予測ラベルを取得します). \n",
    "- `.cpu().detach().numpy()`: テンソルをCPUメモリに移動し, NumPy配列に変換します. \n",
    "\n",
    "```python\n",
    "outputs_list = np.concatenate([outputs_list, output])\n",
    "```\n",
    "\n",
    "この行は, バッチの予測ラベル (`output`) を `outputs_list` に追加します. \n",
    "\n",
    "```python\n",
    "accuracy = sum(outputs_list == labels_list) / len(outputs_list) * 100\n",
    "```\n",
    "\n",
    "この行は, モデルの精度を計算します. \n",
    "\n",
    "- `sum(outputs_list == labels_list)`: 予測ラベルと正解ラベルが一致するサンプルの数を数えます. \n",
    "- `/ len(outputs_list)`: 正解ラベルと予測ラベルのペアの総数で割ります. \n",
    "- `* 100`: 100倍して, 精度をパーセンテージで表します. \n",
    "\n",
    "```python\n",
    "print(f\"accuracy: {round(accuracy, 1)}% {sum(outputs_list == labels_list)}/{len(outputs_list)}\")\n",
    "```\n",
    "\n",
    "この行は, モデルの精度をコンソールに出力します. \n",
    "\n",
    "- `f\"accuracy: {round(accuracy, 1)}%\"`: 精度を小数点第1位まで丸めてフォーマットされた文字列を出力します. \n",
    "- `{sum(outputs_list == labels_list)}/{len(outputs_list)}`: 正解ラベルと予測ラベルが一致するサンプル数とサンプルの総数をスラッシュで区切った文字列を出力します. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertSdpaSelfAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support non-absolute `position_embedding_type` or `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [8 8 1 5 6 3 5 2]\n",
      "True labels: [8 8 1 5 6 3 5 2]\n",
      "Attention outputs type: <class 'tuple'>\n",
      "Number of attention layers: 12\n",
      "Last attention layer shape: torch.Size([8, 12, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "sample_data = next(iter(val_dataloader))\n",
    "sample_data = {key: value.to(device) for key, value in sample_data.items()}\n",
    "\n",
    "labels = sample_data[\"labels\"]\n",
    "output = model(**sample_data, output_attentions=True)\n",
    "pred = output[1].argmax(axis=1)\n",
    "attentions = output[2]\n",
    "\n",
    "print(f\"Predicted labels: {pred.cpu().numpy()}\")  # convert to numpy array for printing\n",
    "print(f\"True labels: {labels.cpu().numpy()}\")   # convert to numpy array for printing\n",
    "print(f\"Attention outputs type: {type(attentions)}\")\n",
    "print(f\"Number of attention layers: {len(attentions)}\")\n",
    "print(f\"Last attention layer shape: {attentions[-1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    2,  1751,  8810,  ..., 28550,   518,     3],\n",
      "        [    2, 14486, 28548,  ...,  2161,  7686,     3],\n",
      "        [    2,  4041, 28579,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    2,   518,    32,  ...,     0,     0,     0],\n",
      "        [    2,  1410,   633,  ..., 15388,    16,     3],\n",
      "        [    2, 25035,  3030,  ...,     0,     0,     0]], device='mps:0'), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='mps:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='mps:0'), 'labels': tensor([8, 8, 1, 5, 6, 3, 5, 2], device='mps:0')}\n"
     ]
    }
   ],
   "source": [
    "print(sample_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このコードは, バリデーションデータセットからランダムに1つのサンプルデータを取得し, モデルによる予測と注意力解析を行います. このコードは, ニューラルネットワークモデルの動作を理解する上で役立ちます. \n",
    "\n",
    "**コード解説**\n",
    "\n",
    "```python\n",
    "sample_data = next(iter(val_dataloader))\n",
    "```\n",
    "\n",
    "この行は, バリデーションデータセットからランダムに1つのサンプルデータを取得します.  \n",
    "厳密には, データを $8$ 個分とってくる.  \n",
    "\n",
    "- `next(iter(val_dataloader))`: `val_dataloader` のイテレータから次のサンプルデータを取得します. \n",
    "\n",
    "```python\n",
    "sample_data = {key: value.to(device) for key, value in sample_data.items()}\n",
    "```\n",
    "\n",
    "この行は, 取得したサンプルデータを `device` に転送します. これは, モデルが計算を実行するデバイス (CPU または GPU) にデータを移動することを意味します. \n",
    "\n",
    "```python\n",
    "labels = sample_data[\"labels\"]\n",
    "```\n",
    "\n",
    "この行は, サンプルデータの正解ラベル (`labels`) を `labels` 変数に格納します. \n",
    "\n",
    "```python\n",
    "output = model(**sample_data, output_attentions=True)\n",
    "```\n",
    "\n",
    "この行は, モデルにサンプルデータを入力し, モデルの出力を取得します. \n",
    "\n",
    "- `model(**sample_data)`: モデルを呼び出し, サンプルデータを引数として渡します. `**` は, 辞書のキーと値をアンパックするために使用されます. \n",
    "- `output_attentions=True`: モデルに `output_attentions=True` オプションを渡すことで, 注意力情報も出力するように設定します. \n",
    "\n",
    "```python\n",
    "pred = output[1].argmax(axis=1)\n",
    "```\n",
    "\n",
    "この行は, モデルの出力を処理し, 各サンプルに対する予測ラベルを取得します. \n",
    "\n",
    "- `output[1]`: モデルの出力の2番目の要素を取得します. これは, 通常, クラス確率分布を表します. \n",
    "- `.argmax(axis=1)`: 各サンプルにおける確率分布の中で最も高い確率を持つインデックスを取得します (つまり, 予測ラベルを取得します). \n",
    "\n",
    "```python\n",
    "attentions = output[2]\n",
    "```\n",
    "\n",
    "この行は, モデルの出力を処理し, 注意力情報 (`attentions`) を取得します. \n",
    "\n",
    "- `output[2]`: モデルの出力の3番目の要素を取得します. これは, 注意力情報 (各単語に対する各ヘッドの重要度) を表します. \n",
    "\n",
    "```python\n",
    "print(f\"Predicted labels: {pred.cpu().numpy()}\")\n",
    "```\n",
    "\n",
    "この行は, 予測ラベル (`pred`) をコンソールに出力します. \n",
    "\n",
    "- `.cpu().numpy()`: テンソルをCPUメモリに移動し, NumPy配列に変換します. \n",
    "- `f\"Predicted labels: {pred.cpu().numpy()}\"`: f-string を使用して, フォーマットされた文字列を出力します. \n",
    "\n",
    "```python\n",
    "print(f\"True labels: {labels.cpu().numpy()}\")\n",
    "```\n",
    "\n",
    "この行は, 正解ラベル (`labels`) をコンソールに出力します. \n",
    "\n",
    "- `.cpu().numpy()`: テンソルをCPUメモリに移動し, NumPy配列に変換します. \n",
    "- `f\"True labels: {labels.cpu().numpy()}\"`: f-string を使用して, フォーマットされた文字列を出力します. \n",
    "\n",
    "```python\n",
    "print(f\"Attention outputs type: {type(attentions)}\")\n",
    "```\n",
    "\n",
    "この行は, 注意力情報 (`attentions`) の型をコンソールに出力します. \n",
    "\n",
    "- `type(attentions)`: `attentions` の型を取得します. \n",
    "- `f\"Attention outputs type: {type(attentions)}\"`: f-string を使用して, フォーマットされた文字列を出力します. \n",
    "\n",
    "```python\n",
    "print(f\"Number of attention layers: {len(attentions)}\")\n",
    "```\n",
    "\n",
    "この行は, 注意力情報 (`attentions`) の層数をコンソールに出力します. \n",
    "\n",
    "- `len(attentions)`: `attentions` のリストの長さを取得します. これは, モデルのエンコーダーの層数に相当します. \n",
    "- `f\"Number of attention layers: {len(attentions)}\"`: f-string を使用して, フォーマットされた文字列を出力します. \n",
    "\n",
    "```python\n",
    "print(f\"Last attention layer shape: {attentions[-1].shape}\")\n",
    "```\n",
    "\n",
    "この行は, 最後の注意力情報 (`attentions[-1]`) の形状をコンソールに出力します. \n",
    "\n",
    "- `[8, 12, 512, 512]` は $8$ 個の記事, $12$ はヘッドの数, $512*512$ は単語のサイズ. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tensor**と**Tuple**は, どちらもデータ構造を表すために用いられるプログラミング用語ですが, それぞれ異なる特徴と用途を持っています. \n",
    "\n",
    "### Tensor\n",
    "\n",
    "**Tensor**は, 多次元配列を表すデータ構造です. 行列やテンソルなど, 複数の次元を持つデータを効率的に表現するために使用されます. \n",
    "\n",
    "**特徴:**\n",
    "\n",
    "* 数値データだけでなく, 文字列やブール値などの非数値データも格納できます. \n",
    "* 複数の次元を持つことができ, データの形状を柔軟に定義できます. \n",
    "* 数学的な演算を効率的に実行できます. \n",
    "\n",
    "**主な用途:**\n",
    "\n",
    "* 機械学習：ニューラルネットワークの入力データやモデルのパラメータなどを表すために使用されます. \n",
    "* 科学計算：物理シミュレーションや画像処理などの計算において, 多次元データを扱うために使用されます. \n",
    "* データ分析：統計分析や可視化などのデータ処理において, 多変量データを扱うために使用されます. \n",
    "\n",
    "**Tensorを扱うためのライブラリ:**\n",
    "\n",
    "* NumPy：Pythonで最も一般的な数値計算ライブラリの一つであり, Tensorを扱うための基本的な機能を提供します. \n",
    "* PyTorch：機械学習に特化したPythonライブラリであり, Tensorを効率的に扱うための様々な機能を提供します. \n",
    "* TensorFlow：機械学習に特化したもう一つのPythonライブラリであり, PyTorchと同様にTensorを扱うための様々な機能を提供します. \n",
    "\n",
    "### Tuple\n",
    "\n",
    "**Tuple**は, 固定長の順序付きデータ集合を表すデータ構造です. リストと似ていますが, 要素の追加や削除ができない点が異なります. \n",
    "\n",
    "**特徴:**\n",
    "\n",
    "* 複数の要素を格納できますが, 要素の追加や削除はできません. \n",
    "* 要素の型は異なっていても構いません. \n",
    "* ハッシュ化可能で, キーとして使用できます. \n",
    "\n",
    "**主な用途:**\n",
    "\n",
    "* 不変データの表現：変更できないデータ (設定値など) を表すために使用されます. \n",
    "* 関数の戻り値：複数の値を返す関数の戻り値として使用されます. \n",
    "* データのグループ化：関連するデータをまとめて格納するために使用されます. \n",
    "\n",
    "**Tupleを扱うためのライブラリ:**\n",
    "\n",
    "* Python標準ライブラリ：Tupleを扱うための基本的な機能は, Python標準ライブラリに含まれています. \n",
    "\n",
    "### TensorとTupleの比較\n",
    "\n",
    "| 項目 | Tensor | Tuple |\n",
    "|---|---|---|\n",
    "| データ構造 | 多次元配列 | 固定長の順序付きデータ集合 |\n",
    "| 可変性 | 可変 | 不可変 |\n",
    "| 要素型 | 数値データ, 文字列, ブール値など | 任意 |\n",
    "| 主な用途 | 機械学習, 科学計算, データ分析 | 不変データの表現, 関数の戻り値, データのグループ化 |\n",
    "| 扱うライブラリ | NumPy, PyTorch, TensorFlow | Python標準ライブラリ |\n",
    "\n",
    "**まとめ**\n",
    "\n",
    "* Tensorは, 多次元データを効率的に表現し, 数学的な演算を実行するために適しています. \n",
    "* Tupleは, 不変データを表現し, 複数の値を返す関数の戻り値として使用するために適しています. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category: smax\n",
      "\u001b[34m[CLS]\u001b[0m\u001b[34mn\u001b[0m\u001b[34m##tt\u001b[0m\u001b[34mドコモ\u001b[0mは0日、公式オンラインショップ「ドコモ##オン##ライン##ショップ」において端末を複数台同時購入した\n",
      "場合に0台当たり最大0,0円を割り##引##く「web限定家族でキャッシュ##バック##キャン##ペーン」を0年0月0日(土)から開始することをお##知##らせしてい\u001b[34mます\u001b[0m。キャンペー\n",
      "ン期間は0年0月0日(日)まで。web限定家族でキャッシュ##バック##キャン##ペーンは、現在、\u001b[34mドコモ\u001b[0mショップにおいて同一店舗でファミリー割引を提供している複数回線において複数台を\n",
      "同時購入する際に0台当たり最大0,0円を値引く「ドコモの家族セット割」を実施してい\u001b[34mます\u001b[0mが、これのドコモ##オン##ライン##ショップ版となり\u001b[34mます\u001b[0m。キャンペーン内容は\n",
      "、同一ファミリー割引適用内の0回線以上で対象機種に機種変更をすると、0台当たり最大0,0円が毎月の請求額からキャッシュバックされ\u001b[34mます\u001b[0m。請求額がキャッシュバック金額に満たない場合は、差\n",
      "##額分をその翌月以降に繰り##越してキャッシュバックされるということ\u001b[34mです\u001b[0m。対象機種はドコモのスマートフォンやiモード##ケー##タイで、タブレットやデータカード、ルー##ター、フォ\n",
      "トパネル以外の全機種となってい\u001b[34mます\u001b[0m\u001b[34m。\u001b[0mなお、ドコモ##オン##ライン##ショップ割対象機種については、対象外となるそう\u001b[34mです\u001b[0m。その他の条件として、以下\n",
      "のいずれかの割引サービスまたは料金プランに加入する必要があり\u001b[34mます\u001b[0m。■f##om##aからf##om##aへの機種変の場合ファミ割m##ax0定額データスタンダード割定額データスタンダ\n",
      "ード割0定額データ0k割■f##om##aからx##iへの機種変更、またはx##iからx##iへの機種変更の場合タイプx##iにねんx##iデータ##プラン##フラ##ットにねんx##iデータプランに\n",
      "ねんx##iデータプラン0にねん※新規契約については、オンラインショップでお手続きと同時のファミリー割引申##込ができないため対象外となります。ご了承\u001b[34mください\u001b[0m。キャンペーンを適用する\n",
      "場合には、ドコモ##オン##ライン##ショップで購入時に対象条件を満たした場合に自動エントリーされるというこどで、条件さえ満た##せば自動的に適用されます。試していないので不明ですが、きちんと対象にな\n",
      "る場合には購入時に明記されるといいのですが、どうでしょうね......。\u001b[34m記事\u001b[0m\u001b[34m執筆\u001b[0m\u001b[34m:\u001b[0m\u001b[34mme\u001b[0m##m##n\u001b[34m0\u001b[0m[SEP] \n",
      "\n",
      "category: smax\n",
      "[CLS]u##r##ba##n##opro##gr##ess##o\u001b[34mの\u001b[0mイメージ\u001b[34mキャラクター\u001b[0m\u001b[34mは\u001b[0m\u001b[34mルパン\u001b[0m\u001b[34mだ\u001b[0m\u001b[34m\n",
      "!\u001b[0m京セラは0\u001b[34m日\u001b[0m、0月0日に発売したばかりの同社製au向け夏モデルの「u##r##ba##n##opro##gr##ess##o(アルバ##ーノ##・##プロ##グレ##ッソ\u001b\n",
      "[34m)」\u001b[0mのcmを同日より放映開始することを発表し、同社のサイトでもcmを公開した。イメージキャラクターにはルパン三世を起用した。u##r##ba##n##opro##gr##ess##o\u001b\n",
      "[34mは\u001b[0m、受##話口用のスピーカーを搭載せず、ディスプレイ面のどこに耳を当てても相手の声が聞こえる「スマート##ソニック##レ##シー##バー」を世界初搭載し、有機e##lで鮮やかな表示をす\n",
      "る「ル##ミナ##ス##ディス##プレイ」、高速通信のw##ima##xにも対応したモデル\u001b[34m。\u001b[0m同社では、上##質なデザインと充実した機能を兼ね備えたu##r##ba##n##op##r\n",
      "o##gr##ess##oの世界観に、おしゃ##れでかっ##こ##よ##くスマートなイメージが重なることからcmキャラクターとして、ルパン三世を起用したのだ\u001b[34mと\u001b[0m\u001b[34mいう\u001b[0m。\n",
      "実際のcmは、お馴染みのルパンのテーマソングをb##g##mに「s##ma##r##ts##onicrec##e##iver」「allinone」「e##leg##antst##yle」をキーワードに\n",
      "cmテーマである「すべてをかな##える相棒」で締めく##くられ高機能でお##洒落な機種であることがアピールされている。cmの詳細は以下の通りcm:「すべてをかな##える相棒」篇(0秒)放映期間:0年0\n",
      "月0日(金)0月0日(日)放映エリア:北海道、宮城、福島、東京、神奈川、埼玉、千葉、茨城、栃木、群馬、長野、静岡、愛知、岐阜、三重、石川、滋賀、京都、大阪、兵庫、奈良、和歌山、徳島、岡山、香川、広島、\n",
      "福岡、鹿児島、沖縄また、u##r##ba##n##op##ro##gr##ess##oは同社が国内向けに展開するスマートフォンのブランド「di##g##n##o(ディ##グ##ノ)」のライナ##ップで\n",
      "もあり、前モデルの「di##g##n##ois##w0\u001b[34mk\u001b[0m」ではドラえもんをイメージキャラクターに起用していた。それぞれのcmは同社のサイトで視聴できるのでチェックしてみよう\u001b[34m\n",
      "。\u001b[0m\u001b[34m・\u001b[0mルパン\u001b[34m三\u001b[0m\u001b[34m世\u001b[0m|u##r##ba##n##opro##gr##ess##o|\u001b[34m京セラ\u001b[0m・テレビcm\u001b[34m|\u001b[0m\u001b[3\n",
      "4m[SEP]\u001b[0m \n",
      "\n",
      "category: it-life-hack\n",
      "[CLS]筆##者が大学生の時代、学食といったら、チケット販売用の自##販##機にaからdくらいまでのラン##チ、ラーメンやそば、うどん、そしてカレー##ライスというお##決##まりのパターンで、厨#\n",
      "#房にいるおばちゃんに「ご##はん超大##盛りで!」などと叫んで雑##然とした中でド##カ食いするというのがお##決##まりだった。本部からちょっと離れた理##系の学部が集まっている校舎には、カフェ#\n",
      "#テリアが設置されていて「ちょっとオシ##ャン##ティじゃね?」なんて思っていたものである。いまではそういった学食を探すほうが珍しいのかはよく知らない\u001b[34mが\u001b[0m\u001b[34mツイッター\u001b[0mで\n",
      "は、筆##者の学生時代のような“ベ##タな学食\"というイメージから大きく離れ「え?ホン##トに学食なの?」と疑いたくなるような豪華なメニュー、また、ど##っかのレストランじゃないの?といったおい##し\n",
      "そうなメニューの写真付き\u001b[34mツイート\u001b[0mが話題になっ\u001b[34mて\u001b[0m\u001b[34mいる\u001b[0m。サー##ロイ##ンステ##ーキや渡り蟹のパス##タといったレストランと見間違え##るほどの豪華\n",
      "でおい##しそうなメニューを見ると、いまの大学生がうら##やま##しく思え##る。学校によっては学食を一般にも開放している大学があるので、職場から近いのであれば利用してみるのはどうだろうか\u001b[34m?\n",
      "\u001b[0m\u001b[34mto\u001b[0m\u001b[34m##get\u001b[0m\u001b[34m##ter\u001b[0m\u001b[34m:\u001b[0m##【コレが学食!?\u001b[34m##】\u001b[0mび##っくりするくらい美味##しそうな学食\u001b[34\n",
      "m写真\u001b[0m\u001b[34mまとめ\u001b[0m\u001b[34mto\u001b[0m##w\u001b[34m##n\u001b[0m##n\u001b[34m##ote\u001b[0m\u001b[34m:\u001b[0m一般人にも学食を開放している大学\u001b[34m■\u001b[0mit\n",
      "ライフ##ハ\u001b[34m##ック\u001b[0m\u001b[34mt\u001b[0m[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][\n",
      "PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][\n",
      "PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][\n",
      "PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][\n",
      "PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][\n",
      "PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][\n",
      "PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][\n",
      "PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][\n",
      "PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD] \n",
      "\n",
      "category: peachy\n",
      "[CLS]ニューヨークを舞台に0人の洗練されたファッションと、セン##セー##ショナルなガールズ##トー##クが人気の海外ドラマ「セックス##・##アンド##・##ザ##・##シティ\u001b[34m」\u001b[0\n",
      "m\u001b[34m。\u001b[0m劇場版第0弾である「セックス##・##アンド##・##ザ##・##シティ\u001b[34m0\u001b[0m」は、全世界で興行収入を0億ドルを記録して大ヒットを記録し\u001b[34mまし\u001b[0m\u001b[3\n",
      "4mた\u001b[0m\u001b[34m。\u001b[0m主演の0人であるサラ・ジェシカ・パーカー、キム・キャ##トラ##ル、クリスティ##ン・デイヴィス、シン##シア##・##ニク##ソンが揃っての初来日を果たし、“s##\n",
      "at##c旋##風\"が巻き起こったのは記憶に新しい\u001b[34mです\u001b[0m\u001b[34mよ\u001b[0m\u001b[34mね\u001b[0m\u001b[34m。\u001b[0mファン待##望のブルーレイ&d##v##dセットは0月0日にリリース\n",
      "、それを記念したガールズ##パー##ティが0日都内で開催され\u001b[34mまし\u001b[0mた\u001b[34m。\u001b[0mイベントには、限定0名のs##at##cファンの一般女性が招待され、ゲストにはモデルの森##泉さ\n",
      "ん、m##cにはl##il##icoさんと“s##at##cフリー##ク\u001b[34m\"\u001b[0mの0名が登場し\u001b[34mまし\u001b[0mた。一般招待##客が入場すると、ウェル##カム##ドリ##ンクとしてモ#\n",
      "#エ##・##エ##・##シャン##ドンが振る舞##われ、イベント開始前から会場は華やかなムードに包まれ\u001b[34mまし\u001b[0mた。「芸能界0s##at##cが好きといっても過##言じゃない」と話す森さ\n",
      "んは、「今日のファッションポイントは...キャリー風にしてきた。色がかわい##いし、意外##とセクシー\u001b[34mでしょ\u001b[0m。靴もキラ##キラなの」と、ゴールドのj##im##mych##oo(ジミ\n",
      "ー##チュウ)のハイ##ヒー##ルに、メー##ガンのピンク&スパ##ン##コール##ミニ##ドレスを披露してくれ\u001b[34mまし\u001b[0mた。s##at##c\u001b[34m0\u001b[0mに登場するファッションが、\n",
      "実は日本の影響を受けているというエピソードを知ると、「とても誇りに思います。一番のお気に入りは、キャリーがスー##クで着ているファッションかな。ピ##チ##ピ##チのtシャツにふん##わりしたスカート\n",
      "で。意外な組み合わせだけど、すご##くマッチしてる。s##at##cは本当にファッションが参考になる」とd##v##dを見ながら一時停止して、自分のワードローブを探して真似できないか研究している、とい\n",
      "うエピソードも披露し、本作もブルーレイ&d##v##dで何度も観##ることを宣言してい\u001b[34mまし\u001b[0mた\u001b[34m。\u001b[0ms##at##cといえば、[SEP] \n",
      "\n",
      "category: sports-watch\n",
      "[CLS]ロンドン五輪開幕まで0ヶ月強\u001b[34m。\u001b[0m各競技で熾##烈な出場権獲得レースが繰り広げられ\u001b[34mて\u001b[0m\u001b[34mいる\u001b[0m\u001b[34m。\u001b[0mバドミントン日本代表の松##友美\n",
      "佐##紀\u001b[34mも\u001b[0m\u001b[34mその\u001b[0m\u001b[34m一\u001b[0m\u001b[34m人\u001b[0m\u001b[34m。\u001b[0mバルセロナ五輪が行われた0年に生まれた松##友\u001b[34mは\u001b[0m\u001b[34m、\u001b[0mまだ\n",
      "二十歳になったばかりの期待の若手\u001b[34m。\u001b[0m全国小学生大会、全国中学生大会それぞれでシングルスの頂点に立つと、高校に進学してからもインターハイでシングルス、ダブルスを制覇と、まさにエリート街道\n",
      "をまい##進してきた\u001b[34m。\u001b[0m類稀なバドミントンセンスもさることながら、その美しい容姿で、若手美女アスリートとして注目度も急##上##昇\u001b[34m中\u001b[0m。透##き##通##るような白い肌\n",
      "に大きな黒##目はさし##ず##め清##純派アイドルの\u001b[34mよう\u001b[0m\u001b[34m。\u001b[0m現在は、日本代表のダブルスメンバーで高校の先輩の高橋礼華とペアを組み、ロンドン五輪出場を目指して奮闘して\n",
      "いる\u001b[34m。\u001b[0mダブルスの国別出場枠は最大0つで、現状、藤井端希&垣岩令佳ペア、末綱聡##子&前田美順ペア、松尾静##香&内藤真##美ペアに次ぐ四番手と道##のりは厳しいが、その先のリオデジャ\n",
      "ネイロ五輪も含め、第二の潮##田玲##子として今後も女子バドミントン界の注目の的となり\u001b[34mそう\u001b[0m\u001b[34mだ\u001b[0m。・松##友美佐##紀フォト・潮\u001b[34m[SEP]\u001b[0m[PAD][\n",
      "PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][\n",
      "PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][\n",
      "PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][\n",
      "PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][\n",
      "PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][\n",
      "PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][\n",
      "PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][\n",
      "PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][\n",
      "PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][\n",
      "PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][\n",
      "PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][\n",
      "PAD][PAD][PAD][PAD][PAD][PAD] \n",
      "\n",
      "category: topic-news\n",
      "[CLS]\u001b[34m0\u001b[0m\u001b[34m日\u001b[0mに放送された「マツ##コ&有##吉の怒り新党」(テレビ朝日系)番組内で\u001b[34mは\u001b[0m\u001b[34m、\u001b[0m芸人・有##吉弘##行がマツ##コの指摘\n",
      "をけん##か##腰で否定するという\u001b[34m場面\u001b[0mが\u001b[34mあっ\u001b[0m\u001b[34mた\u001b[0m。\u001b[34m同\u001b[0m番組には、読者から寄せられた怒りの投稿を夏目三久が読みあげ、有##吉とマツ##\n",
      "コがその内容をジャッジするコーナーが\u001b[34mある\u001b[0m。\u001b[34mこの\u001b[0m\u001b[34m日\u001b[0mの放送で\u001b[34mは\u001b[0m、コーナーの趣旨から外れ、有##吉やマツ##コが夏目の左右非対称なヘア\n",
      "##スタイルをネタにするや、夏目はそのお##返しに有##吉のぼ##さ##ぼ##さな髪型に言及。すると有##吉は「俺をいじ##るなよ」と芸人らしか##らぬ発言をしたの\u001b[34mだ\u001b[0m。その後、夏目が\n",
      "「自分に対して揺##る##ぎ##ない自信を持っている人に怒りを感じます。自分のことを少しでもいじ##られると怒り##狂##うくせして、他人に対して傍##若##無##人に振る舞##う人は本当に面倒です」\n",
      "という読者からの投稿を紹介\u001b[34mする\u001b[0m\u001b[34mと\u001b[0m\u001b[34m、\u001b[0mマツ##コは、投稿者のいう“怒りを感じる人物像\"こそ有##吉だと\u001b[34m指摘\u001b[0m\u001b[34mし\u001b[0m\u001b[3\n",
      "4mた\u001b[0m。少し前に「俺をいじ##るな」といったことをやり##玉に挙げると、ここで有##吉は、マツ##コが「すごい剣##幕で言わなくてもいいじゃない」と驚くほど語##気荒##く否定し、その言動は夏\n",
      "目が「有##吉さん、怖##い...」と漏##らすほど。次に気を取り##直した有##吉が、改めて夏目に「自分とマツ##コ、ど##っちがいじ##りにくい?」と質問を投げたが、夏目は「有##吉さん」と返答。\n",
      "「たまに本気で怒ってることがある」と切り##出すと、追い##打ちをかけるように「プロなのに」「家に帰ってもネ##チネ##チ思い出してるんじゃないかって」と続け、ここぞとばかりに有##吉をけ##なし\u001b[\n",
      "34mた\u001b[0m。■夏目三久の写真ギ[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][P\n",
      "AD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][P\n",
      "AD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][P\n",
      "AD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][P\n",
      "AD][PAD][PAD][PAD] \n",
      "\n",
      "category: peachy\n",
      "[CLS]人間関係をスムーズにするヒントやライフ##ハ##ック、節約ネタなど、今すぐ役立つ情報が詰##まったp##e##ach##yの「ライフ##スタイル」\u001b[34mカテゴリ\u001b[0m\u001b[34m。\u001b[0\n",
      "mこのカテゴリのなかから、\u001b[34m0\u001b[0m年0月0日0月0日の間に最も多く読まれた記事to##p0をご紹介し\u001b[34mます\u001b[0m\u001b[34m!\u001b[0m第0位\u001b[34m:\u001b[0ml##ineで友##\n",
      "だちをブロックすると...l##ineでは、友##だちを「削除」することはできませんが、「ブロック」することはできます。じゃ##あ、ブロックするとどうなるの...##?相手にわかっちゃ##うの?という\n",
      "ことで、実際にやってみ\u001b[34mまし\u001b[0mた\u001b[34m!\u001b[0m第0位:付き##合ってもすぐに飽きられてしまう女性とは?##【前##編】せっ##かく彼ができたのに、付き##合って半年もしないうちに振\n",
      "られてしまったという女性は意外##と少なくありません。男性が女性に飽きてしまう理由のひとつに「重く感じてしまう」という声があり\u001b[34mます\u001b[0m。では男性が重いと感じる言動は何なのでしょうか\u001b[3\n",
      "4m?\u001b[0m第0位:初めての妊娠!用意してしまいがちな不要品って?初めての妊娠、嬉##しく##ってド##キ##ドキして、不安で、いろ##んな気持ちで胸がいっぱいになってしまいますね。自分のことのよう\n",
      "なそうでないような、妊娠中の買い物は不思議です。赤ちゃんのためと思うとつい##つい色々揃えたくなって、散##財してしまいがちですね\u001b[34m。\u001b[0m第0位\u001b[34m:\u001b[0m男ウ##ケ抜群\u001b[34m\n",
      "!\u001b[0m後##れ##毛ポニー##テールの\u001b[34mやり方\u001b[0m女性は髪##形やメイクで印象をグ##ッと変えることができますよね。これは女性の特権\u001b[34mです\u001b[0m。髪型・メイクには、男ウ##ケ\n",
      "を意識したものと同性から好印象を持ってもらうためのものがあります\u001b[34m。\u001b[0mそこで、筆##者が男ウ##ケを意識した時に実践しているヘアアレンジを紹介したいと思い\u001b[34mます\u001b[0m\u001b[34m\n",
      "。\u001b[0m第0位\u001b[34m:「\u001b[0mモ##テる女性の0つの習慣\u001b[34m」\u001b[0m小学校の頃から美人ではないがなぜか周りに人が集まるモ##テ子はいなかっただろうか。それは異性からも同性からもで、決し\n",
      "て見た目からだけでなく内側からオーラが放##たれている...。そういう人間が幸せを掴##むのだと思う。貴##方も気づいて[SEP] \n",
      "\n",
      "category: kaden-channel\n",
      "[CLS]\u001b[34m■\u001b[0mビデオs\u001b[34m##al\u001b[0m\u001b[34m##on\u001b[0m\u001b[34mイベント\u001b[0m・\u001b[34m製品\u001b[0m\u001b[34mレポート\u001b[0m最新\u001b[34m記事\u001b[0m\u001b[34\n",
      "m・\u001b[0mm\u001b[34m##ook\u001b[0m「デジタルムービー実践ガイド##ブック」映像リンク\u001b[34m情報\u001b[0m\u001b[34m・\u001b[0m第0\u001b[34m回\u001b[0m\u001b[34m上映\u001b[0m雨##宮真五監督作品\n",
      "『sh##oot##ingme##m##ori##es』\u001b[34m・\u001b[0m\u001b[34m連載\u001b[0m\u001b[34m●\u001b[0ma##ft##ere##ff##ect##s天国への階段第0回・魁!!ビデオ道場0\n",
      "年0月\u001b[34m号\u001b[0m\u001b[34m[UNK]\u001b[0mビデオ\u001b[34mサロン\u001b[0m\u001b[34m0\u001b[0m[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PA\n",
      "D][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PA\n",
      "D][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PA\n",
      "D][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PA\n",
      "D][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PA\n",
      "D][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PA\n",
      "D][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PA\n",
      "D][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PA\n",
      "D][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PA\n",
      "D][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PA\n",
      "D][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PA\n",
      "D][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PA\n",
      "D][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PA\n",
      "D][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PA\n",
      "D][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PA\n",
      "D][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PA\n",
      "D][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PA\n",
      "D][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PA\n",
      "D][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PA\n",
      "D][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PA\n",
      "D][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PA\n",
      "D][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PA\n",
      "D][PAD][PAD][PAD][PAD][PAD][PAD] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "for batch_number in range(len(labels)):\n",
    "  all_attens = attentions[-1][batch_number, :, 0, :].sum(axis=0)\n",
    "  input_ids_index_list = all_attens.topk(20).indices\n",
    "  text = tokenizer.convert_ids_to_tokens(sample_data[\"input_ids\"][batch_number])\n",
    "  for input_ids_index in input_ids_index_list:\n",
    "    word = text[input_ids_index]\n",
    "    text[input_ids_index] = '\\033[34m' + text[input_ids_index] + '\\033[0m'\n",
    "\n",
    "  s_wrap_list = textwrap.wrap(''.join(text), 100)\n",
    "  print(f\"category: {category_list[labels[batch_number]]}\")\n",
    "  print('\\n'.join(s_wrap_list), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このコードは, バリデーションデータセットの各バッチについて, モデルの予測カテゴリと, その予測に最も影響を与えた単語をハイライト表示します. これは, モデルがどのように各入力テキストを理解しているのかを可視化する方法として役立ちます. \n",
    "\n",
    "**コード解説**\n",
    "\n",
    "```python\n",
    "import textwrap\n",
    "```\n",
    "\n",
    "この行は, `textwrap` モジュールをインポートします. このモジュールは, 長い文字列を折り返して複数行に表示するために使用されます. \n",
    "\n",
    "```python\n",
    "for batch_number in range(len(labels)):\n",
    "```\n",
    "\n",
    "この `for` ループは, バリデーションデータセットの各バッチを処理します. \n",
    "\n",
    "- `batch_number`: バッチのインデックス\n",
    "- `len(labels)`: バリデーションデータセットのサンプル数\n",
    "\n",
    "```python\n",
    "all_attens = attentions[-1][batch_number, :, 0, :].sum(axis=0)\n",
    "```\n",
    "\n",
    "この行は, 最後の注意力情報 (`attentions[-1]`) のバッチ `batch_number` における各単語の重要度を合計します. \n",
    "\n",
    "- `attentions[-1]`: 最後の注意力情報 (各単語に対する各ヘッドの重要度) を取得します. \n",
    "- `[batch_number, :, 0, :]`: バッチ `batch_number` における各単語の重要度を取得します. \n",
    "- `.sum(axis=0)`: 各単語の重要度をヘッド間で合計します. \n",
    "\n",
    "```python\n",
    "input_ids_index_list = all_attens.topk(20).indices\n",
    "```\n",
    "\n",
    "この行は, 各単語の重要度の高い上位20個のインデックスを取得します. \n",
    "\n",
    "- `all_attens.topk(20)`: 各単語の重要度に基づいて上位20個の要素を取得します. \n",
    "- `.indices`: 上位20個の要素のインデックスを取得します. \n",
    "\n",
    "```python\n",
    "text = tokenizer.convert_ids_to_tokens(sample_data[\"input_ids\"][batch_number])\n",
    "```\n",
    "\n",
    "この行は, サンプルデータの入力テキスト (`sample_data[\"input_ids\"][batch_number]`) をトークンに変換します. \n",
    "\n",
    "- `tokenizer.convert_ids_to_tokens`: トークナイザーを使用して, トークンIDをトークンに変換します. \n",
    "\n",
    "```python\n",
    "for input_ids_index in input_ids_index_list:\n",
    "    word = text[input_ids_index]\n",
    "    text[input_ids_index] = '\\033[34m' + text[input_ids_index] + '\\033[0m'\n",
    "```\n",
    "\n",
    "この `for` ループは, 各バッチの入力テキストにおいて, 重要度の高い上位20個の単語を青色でハイライト表示します. \n",
    "\n",
    "- `input_ids_index`: 重要度の高い単語のインデックス\n",
    "- `word`: ハイライト表示する単語\n",
    "- `text[input_ids_index] = '\\033[34m' + text[input_ids_index] + '\\033[0m'`: ターミナルエスケープシーケンスを使用して, 単語を青色でハイライト表示します. \n",
    "\n",
    "```python\n",
    "s_wrap_list = textwrap.wrap(''.join(text), 100)\n",
    "```\n",
    "\n",
    "この行は, ハイライト表示された入力テキストを100文字ごとに区切ってリスト (`s_wrap_list`) に格納します. \n",
    "\n",
    "- `textwrap.wrap(''.join(text), 100)`: 入力テキストを100文字ごとに区切ってリストに変換します. \n",
    "\n",
    "```python\n",
    "print(f\"category: {category_list[labels[batch_number]]}\")\n",
    "```\n",
    "\n",
    "この行は, バッチの予測カテゴリ (`category_list[labels[batch_number]]`) をコンソールに出力します. \n",
    "\n",
    "```python\n",
    "print('\\n'.join(s_wrap_list), \"\\n\")\n",
    "```\n",
    "\n",
    "この行は, ハイライト表示された入力テキスト (`'\\n'.join(s_wrap_list)`) をコンソールに出力します. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
