{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `torch`: PyTorchライブラリをインポートします. これは, 深層学習モデルを構築するための主要なライブラリです. \n",
    "- `transformers`: Transformerライブラリをインポートします. このライブラリは, BERTやGPT-2などの最先端自然言語処理モデルを簡単に利用できるようにします. \n",
    "- `AdamW`: AdamWオプティマイザをインポートします. これは, 深層学習モデルの訓練に使用される手法です. \n",
    "- `get_linear_schedule_with_warmup`: 学習率を徐々に上げていくスケジュールを取得するための関数をインポートします. \n",
    "- `DataLoader`: PyTorch DataLoaderをインポートします. これは, データセットを効率的に読み込むためのツールです. \n",
    "- `Dataset`: PyTorch Datasetクラスをインポートします. これは, カスタムデータセットを作成するための基底クラスです. \n",
    "- `pandas`: データ分析ライブラリであるpandasをインポートします. \n",
    "- `re`: 正規表現ライブラリであるreをインポートします. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 口コミデータ\n",
    "reviews = [\n",
    "    \"鮨 さいとうに4回目の訪問. 今回はランチでディナー同様, 摘みありのコースを注文させて頂きました. タイトルにもありますが, 気付けば2年ぶりの訪問. 食べ歩きをしてると2.3年再訪してないお店が沢山出てきますが, 再訪してもそれほど月日が経ってないように感じるのは私だけでしょうか. . 笑さて, 本題のお料理ですが, 摘み握り共に何を食べても美味しく, 今回も流石の安定感です. 何一つとして気になるものはありません. また, この日は以前よりずっと飲んでみたかった黒龍酒造の『ESHIKOTO』を頂きました. 超入手困難なスパークリングの日本酒です. 当たりがとてもドライで食事の邪魔を一切しないテイスト. 香りはほのかに日本酒を感じさせます. こんな貴重なお酒を入るのはさすが齋藤さんですね. 次回はいつ来れるか分かりませんが, またぜひ伺いたいです. ご馳走様でした. \",\n",
    "    \"個人的に, 都内では大好きなお店の一つ. 3度目の訪問ですが, さいとうさんは時期が変わっても毎度ツマミも握りも安定感があり素晴らしいですね. この日, 初めて頂く「穴子の白焼き」は今まで食べた事ないくらい身がぷりぷりしており, 特に印象深い一品でした. さらに1人30,000円ちょっとと, 内容対してコスパの高さも嬉しいですね. また, 昼でも夜でも時期を変えて伺いたいです. ご馳走様でした. \",\n",
    "    \"今月2度目のさいとうさんへ. 今回はランチ利用です. 握り15貫のみのコースを頂きました. （人によっては少し量が少なく感じる方もいらっしゃるかもしれません. ）マグロ中心に今回も大変美味しく頂きました. 価格も1人16,500円と, とても良心的な価格でびっくりしました. この立地でこの価格だと, そりゃ中々予約取れないわかです. また伺います. ご馳走様でした. \",\n",
    "    \"言わずと知れた4年連続食べログゴールド, 2019年まで10年連続ミシュラン3つ星のお店です. 今回はお誘い頂き訪問してきました. その人気ぶりから現在では, 完全会員制を取っており, 一見での予約は不可になっております. さて, お寿司に関しては非常に素晴らしいです. できることなら会員になって通い続けたいお店です. ネタもシャリもとても個人的に好みでした. 特にシャリは酢と塩味が強く無く, 割と万人受けするかな, といった印象. 次いついけるか分かりませんが, ぜひまた伺いたいです. ご馳走様でした. \",\n",
    "    \"楽しい時間を過ごす事が出来ました. また是非伺いたいと思います. ご馳走様でした. \",\n",
    "    \"今回は個室で『鮨さいとう』二番手の沼尾さんの鮨を堪能しました. 仕事も所作も丁寧で, 安心して食に集中出来ました. 酢飯の酸度・塩味・硬さ等かなり好み. ネタも間違いのないものばかりでした！ご馳走様でした. \",\n",
    "    \"最高峰と言われるお鮨屋さんお鮨だけを楽しみに行くのではなく, 大将との会話, 雰囲気, 異空間を味わいながら食べるお鮨屋さん. お鮨は美味しい. 特にこれがというのはないが, 美味しい. 1番驚いたのは鮨屋とは思えない独特な雰囲気があるお店. 大将とお客さんの一体感のある空間でお鮨を楽しめます. 大将の人柄で人気なっているお店. お鮨だけを食べに行くには勿体無いいいお鮨屋さんでした. さいとうさんのにぎるお鮨を食べられたことに感謝. \",\n",
    "    \"念願の大将のお席!カツオのたたきはこれまで食べた1番の美味しさ. 熟成されたねっとり感で, 旨みがギュッ!パサつき全く無い仕上がり. 優しい, 鮑, たこ, など, おつまみも最高!握りはふわっと優しいシャリとの一体感が素晴らしい. 最初のあたたかめのシャリと白身が新鮮で美味. 甘すぎないツメもよく, 蛤や穴子も, 素材の美味しさか際立つ！来年ですが, また, 次回も楽しみ！\",\n",
    "    \"日本の鮨店, 最高峰の1つ. 超予約困難店です. 1度訪れてみたかったお店ですが, 常連様にお誘い頂き, 伺うことができました. こちらのお店は・10年連続ミシュラン3つ星も会員制にするために返上・食べログGOLD(全国で30店舗ほどのみ)連続獲得・世界のグルメガイド, フランスの「ラ・リスト2024」で99.5点の日本最高評価を獲得. また, 世界でも上位7位. ・新規予約は基本受付しておらず, 食オクでのオークションのみ・食オクでは1席40万円や70万円の値がつくこともお店は六本木一丁目駅直結のアークヒルズタワー1階にあります. やや分かりづらい場所です. 店内は個室が2つあり, 個室内はL字のカウンター8席ほど. この日は, 2番手の沼尾大将の貸切会でした. お鮨はもちろんですが蒸し鮑と蛸の桜煮の旨味が凄く, 鰹の皮目がパリッとした火入れと最初のつまみがとても美味しく感動しました. つまみも握りもハイクオリティですが会話も楽しく雰囲気づくりも抜群. 価格は高いですが, 他のお鮨やさんと一線を画すほど美味しく満足度は高いです. 純粋に美味しくて, また来たいなぁと思える素晴らしいお鮨でした！ご馳走様でした！\",\n",
    "    \"日本最高峰のお鮨のお店に, 幸運にもお誘いいただき, 訪問することができました. この日は, 個室の沼尾大将に握っていただきました. 貸切ということもあり, リラックスして, 美味しいお酒を飲みながら, 最高のお鮨を食べて, 幸せな時間を過ごすことができました. ご馳走様でした！！！\",\n",
    "    \"食べログお鮨ランキング1位にしてミシュラン3つ星, 泣く子もだまるさいとう, 2月に続いて3月もさいとうさんへ, ミシュラン3つ星を取ったのは随分前だが最近になっても美味しさが増している気がする. \",\n",
    "    \"日本最高峰のお寿司と聞いていたのですが, お値段に比べてあまり美味しいと思いませんでした. \",\n",
    "    \"イベントの際にお邪魔しました. 少し値段が高い気がします. \",\n",
    "    \"イカやタコが美味しかったですが, マグロは微妙でした.\",\n",
    "    \"お値段が高いので, もう少し美味しいものが食べたかったです.\",\n",
    "    \"雰囲気が少し怖く感じました.\",\n",
    "    \"味がイマイチだったので, また行くかは検討中です.\",\n",
    "    \"お値段が高いので, 期待していたほど美味しくなかったです.\",\n",
    "    \"電話対応が悪かったので, また行くかは検討中です.\",\n",
    "]\n",
    "\n",
    "# 感情ラベルの追加（手動で設定, ここでは全てポジティブと仮定）\n",
    "# labels = [1] * len(reviews)\n",
    "\n",
    "\n",
    "# 感情ラベルの追加（ポジティブ: 1, ネガティブ: 0）\n",
    "labels = [1] * 11 + [0] * 8\n",
    "\n",
    "output_dir = 'text'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "for i, (review, label) in enumerate(zip(reviews, labels)):\n",
    "    df = pd.DataFrame({'text': [review], 'label': [label]})\n",
    "    df.to_csv(os.path.join(output_dir, f'review_{i}.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. 口コミデータの準備**\n",
    "\n",
    "```python\n",
    "reviews = [\n",
    "    \"鮨 さいとうに4回目の訪問. 今回はランチでディナー同様, 摘みありのコースを注文させて頂きました. タイトルにもありますが, 気付けば2年ぶりの訪問. 食べ歩きをしてると2.3年再訪してないお店が沢山出てきますが, 再訪してもそれほど月日が経ってないように感じるのは私だけでしょうか. . 笑さて, 本題のお料理ですが, 摘み握り共に何を食べても美味しく, 今回も流石の安定感です. 何一つとして気になるものはありません. また, この日は以前よりずっと飲んでみたかった黒龍酒造の『ESHIKOTO』を頂きました. 超入手困難なスパークリングの日本酒です. 当たりがとてもドライで食事の邪魔を一切しないテイスト. 香りはほのかに日本酒を感じさせます. こんな貴重なお酒を入るのはさすが齋藤さんですね. 次回はいつ来れるか分かりませんが, またぜひ伺いたいです. ご馳走様でした. \",\n",
    "    # ... (9件の口コミデータ省略)\n",
    "]\n",
    "\n",
    "labels = [1] * len(reviews)\n",
    "```\n",
    "\n",
    "- `reviews`: リスト形式で, 12個の「鮨 さいとう」の口コミデータが格納されています. \n",
    "- `labels`: 各口コミデータに対応する感情ラベルをリスト形式で格納しています. **ここでは全て1（ポジティブ）に設定**されています. \n",
    "\n",
    "**2. 個別のCSVファイルへの保存**\n",
    "\n",
    "```python\n",
    "for i, (review, label) in enumerate(zip(reviews, labels)):\n",
    "    df = pd.DataFrame({'text': [review], 'label': [label]})\n",
    "    df.to_csv(f'review_{i}.csv', index=False)\n",
    "```\n",
    "\n",
    "- 上記の口コミデータと感情ラベルを, `review_0.csv`, `review_1.csv` ... のように個別のCSVファイルに保存します. \n",
    "    - `pd.DataFrame`: 口コミデータと感情ラベルをDataFrameに変換します. \n",
    "    - `to_csv`: DataFrameをCSVファイルに出力します. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_973d8_row0_col0, #T_973d8_row0_col1, #T_973d8_row1_col0, #T_973d8_row1_col1, #T_973d8_row2_col0, #T_973d8_row2_col1, #T_973d8_row3_col0, #T_973d8_row3_col1, #T_973d8_row4_col0, #T_973d8_row4_col1, #T_973d8_row5_col0, #T_973d8_row5_col1, #T_973d8_row6_col0, #T_973d8_row6_col1, #T_973d8_row7_col0, #T_973d8_row7_col1, #T_973d8_row8_col0, #T_973d8_row8_col1, #T_973d8_row9_col0, #T_973d8_row9_col1, #T_973d8_row10_col0, #T_973d8_row10_col1, #T_973d8_row11_col0, #T_973d8_row11_col1, #T_973d8_row12_col0, #T_973d8_row12_col1, #T_973d8_row13_col0, #T_973d8_row13_col1, #T_973d8_row14_col0, #T_973d8_row14_col1, #T_973d8_row15_col0, #T_973d8_row15_col1, #T_973d8_row16_col0, #T_973d8_row16_col1, #T_973d8_row17_col0, #T_973d8_row17_col1, #T_973d8_row18_col0, #T_973d8_row18_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_973d8\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_973d8_level0_col0\" class=\"col_heading level0 col0\" >口コミ内容</th>\n",
       "      <th id=\"T_973d8_level0_col1\" class=\"col_heading level0 col1\" >評価</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_973d8_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_973d8_row0_col0\" class=\"data row0 col0\" >鮨 さいとうに4回目の訪問. 今回はランチでディナー同様, 摘みありのコースを注文させて頂きました. タイトルにもありますが, 気付けば2年ぶりの訪問. 食べ歩きをしてると2.3年再訪してないお店が沢山出てきますが, 再訪してもそれほど月日が経ってないように感じるのは私だけでしょうか. . 笑さて, 本題のお料理ですが, 摘み握り共に何を食べても美味しく, 今回も流石の安定感です. 何一つとして気になるものはありません. また, この日は以前よりずっと飲んでみたかった黒龍酒造の『ESHIKOTO』を頂きました. 超入手困難なスパークリングの日本酒です. 当たりがとてもドライで食事の邪魔を一切しないテイスト. 香りはほのかに日本酒を感じさせます. こんな貴重なお酒を入るのはさすが齋藤さんですね. 次回はいつ来れるか分かりませんが, またぜひ伺いたいです. ご馳走様でした. </td>\n",
       "      <td id=\"T_973d8_row0_col1\" class=\"data row0 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_973d8_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_973d8_row1_col0\" class=\"data row1 col0\" >個人的に, 都内では大好きなお店の一つ. 3度目の訪問ですが, さいとうさんは時期が変わっても毎度ツマミも握りも安定感があり素晴らしいですね. この日, 初めて頂く「穴子の白焼き」は今まで食べた事ないくらい身がぷりぷりしており, 特に印象深い一品でした. さらに1人30,000円ちょっとと, 内容対してコスパの高さも嬉しいですね. また, 昼でも夜でも時期を変えて伺いたいです. ご馳走様でした. </td>\n",
       "      <td id=\"T_973d8_row1_col1\" class=\"data row1 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_973d8_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_973d8_row2_col0\" class=\"data row2 col0\" >今月2度目のさいとうさんへ. 今回はランチ利用です. 握り15貫のみのコースを頂きました. （人によっては少し量が少なく感じる方もいらっしゃるかもしれません. ）マグロ中心に今回も大変美味しく頂きました. 価格も1人16,500円と, とても良心的な価格でびっくりしました. この立地でこの価格だと, そりゃ中々予約取れないわかです. また伺います. ご馳走様でした. </td>\n",
       "      <td id=\"T_973d8_row2_col1\" class=\"data row2 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_973d8_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_973d8_row3_col0\" class=\"data row3 col0\" >言わずと知れた4年連続食べログゴールド, 2019年まで10年連続ミシュラン3つ星のお店です. 今回はお誘い頂き訪問してきました. その人気ぶりから現在では, 完全会員制を取っており, 一見での予約は不可になっております. さて, お寿司に関しては非常に素晴らしいです. できることなら会員になって通い続けたいお店です. ネタもシャリもとても個人的に好みでした. 特にシャリは酢と塩味が強く無く, 割と万人受けするかな, といった印象. 次いついけるか分かりませんが, ぜひまた伺いたいです. ご馳走様でした. </td>\n",
       "      <td id=\"T_973d8_row3_col1\" class=\"data row3 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_973d8_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_973d8_row4_col0\" class=\"data row4 col0\" >楽しい時間を過ごす事が出来ました. また是非伺いたいと思います. ご馳走様でした. </td>\n",
       "      <td id=\"T_973d8_row4_col1\" class=\"data row4 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_973d8_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_973d8_row5_col0\" class=\"data row5 col0\" >今回は個室で『鮨さいとう』二番手の沼尾さんの鮨を堪能しました. 仕事も所作も丁寧で, 安心して食に集中出来ました. 酢飯の酸度・塩味・硬さ等かなり好み. ネタも間違いのないものばかりでした！ご馳走様でした. </td>\n",
       "      <td id=\"T_973d8_row5_col1\" class=\"data row5 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_973d8_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_973d8_row6_col0\" class=\"data row6 col0\" >最高峰と言われるお鮨屋さんお鮨だけを楽しみに行くのではなく, 大将との会話, 雰囲気, 異空間を味わいながら食べるお鮨屋さん. お鮨は美味しい. 特にこれがというのはないが, 美味しい. 1番驚いたのは鮨屋とは思えない独特な雰囲気があるお店. 大将とお客さんの一体感のある空間でお鮨を楽しめます. 大将の人柄で人気なっているお店. お鮨だけを食べに行くには勿体無いいいお鮨屋さんでした. さいとうさんのにぎるお鮨を食べられたことに感謝. </td>\n",
       "      <td id=\"T_973d8_row6_col1\" class=\"data row6 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_973d8_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_973d8_row7_col0\" class=\"data row7 col0\" >念願の大将のお席!カツオのたたきはこれまで食べた1番の美味しさ. 熟成されたねっとり感で, 旨みがギュッ!パサつき全く無い仕上がり. 優しい, 鮑, たこ, など, おつまみも最高!握りはふわっと優しいシャリとの一体感が素晴らしい. 最初のあたたかめのシャリと白身が新鮮で美味. 甘すぎないツメもよく, 蛤や穴子も, 素材の美味しさか際立つ！来年ですが, また, 次回も楽しみ！</td>\n",
       "      <td id=\"T_973d8_row7_col1\" class=\"data row7 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_973d8_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_973d8_row8_col0\" class=\"data row8 col0\" >日本の鮨店, 最高峰の1つ. 超予約困難店です. 1度訪れてみたかったお店ですが, 常連様にお誘い頂き, 伺うことができました. こちらのお店は・10年連続ミシュラン3つ星も会員制にするために返上・食べログGOLD(全国で30店舗ほどのみ)連続獲得・世界のグルメガイド, フランスの「ラ・リスト2024」で99.5点の日本最高評価を獲得. また, 世界でも上位7位. ・新規予約は基本受付しておらず, 食オクでのオークションのみ・食オクでは1席40万円や70万円の値がつくこともお店は六本木一丁目駅直結のアークヒルズタワー1階にあります. やや分かりづらい場所です. 店内は個室が2つあり, 個室内はL字のカウンター8席ほど. この日は, 2番手の沼尾大将の貸切会でした. お鮨はもちろんですが蒸し鮑と蛸の桜煮の旨味が凄く, 鰹の皮目がパリッとした火入れと最初のつまみがとても美味しく感動しました. つまみも握りもハイクオリティですが会話も楽しく雰囲気づくりも抜群. 価格は高いですが, 他のお鮨やさんと一線を画すほど美味しく満足度は高いです. 純粋に美味しくて, また来たいなぁと思える素晴らしいお鮨でした！ご馳走様でした！</td>\n",
       "      <td id=\"T_973d8_row8_col1\" class=\"data row8 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_973d8_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_973d8_row9_col0\" class=\"data row9 col0\" >日本最高峰のお鮨のお店に, 幸運にもお誘いいただき, 訪問することができました. この日は, 個室の沼尾大将に握っていただきました. 貸切ということもあり, リラックスして, 美味しいお酒を飲みながら, 最高のお鮨を食べて, 幸せな時間を過ごすことができました. ご馳走様でした！！！</td>\n",
       "      <td id=\"T_973d8_row9_col1\" class=\"data row9 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_973d8_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_973d8_row10_col0\" class=\"data row10 col0\" >食べログお鮨ランキング1位にしてミシュラン3つ星, 泣く子もだまるさいとう, 2月に続いて3月もさいとうさんへ, ミシュラン3つ星を取ったのは随分前だが最近になっても美味しさが増している気がする. </td>\n",
       "      <td id=\"T_973d8_row10_col1\" class=\"data row10 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_973d8_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_973d8_row11_col0\" class=\"data row11 col0\" >日本最高峰のお寿司と聞いていたのですが, お値段に比べてあまり美味しいと思いませんでした. </td>\n",
       "      <td id=\"T_973d8_row11_col1\" class=\"data row11 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_973d8_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_973d8_row12_col0\" class=\"data row12 col0\" >イベントの際にお邪魔しました. 少し値段が高い気がします. </td>\n",
       "      <td id=\"T_973d8_row12_col1\" class=\"data row12 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_973d8_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_973d8_row13_col0\" class=\"data row13 col0\" >イカやタコが美味しかったですが, マグロは微妙でした.</td>\n",
       "      <td id=\"T_973d8_row13_col1\" class=\"data row13 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_973d8_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_973d8_row14_col0\" class=\"data row14 col0\" >お値段が高いので, もう少し美味しいものが食べたかったです.</td>\n",
       "      <td id=\"T_973d8_row14_col1\" class=\"data row14 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_973d8_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_973d8_row15_col0\" class=\"data row15 col0\" >雰囲気が少し怖く感じました.</td>\n",
       "      <td id=\"T_973d8_row15_col1\" class=\"data row15 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_973d8_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_973d8_row16_col0\" class=\"data row16 col0\" >味がイマイチだったので, また行くかは検討中です.</td>\n",
       "      <td id=\"T_973d8_row16_col1\" class=\"data row16 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_973d8_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_973d8_row17_col0\" class=\"data row17 col0\" >お値段が高いので, 期待していたほど美味しくなかったです.</td>\n",
       "      <td id=\"T_973d8_row17_col1\" class=\"data row17 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_973d8_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_973d8_row18_col0\" class=\"data row18 col0\" >電話対応が悪かったので, また行くかは検討中です.</td>\n",
       "      <td id=\"T_973d8_row18_col1\" class=\"data row18 col1\" >0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x168d01b80>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データフレームの作成\n",
    "all_data = pd.DataFrame({'text': reviews, 'label': labels})\n",
    "\n",
    "# 列名の変更\n",
    "all_data.rename(columns={'text': '口コミ内容', 'label': '評価'}, inplace=True)\n",
    "\n",
    "# インデックスを列に格納\n",
    "all_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# フレーム作成\n",
    "frame = all_data\n",
    "\n",
    "# 左揃え設定\n",
    "frame.style.set_properties(**{'text-align': 'left'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. データフレームの作成**\n",
    "\n",
    "```python\n",
    "all_data = pd.DataFrame({'text': reviews, 'label': labels})\n",
    "```\n",
    "\n",
    "- `pd.DataFrame`: リスト形式で格納された口コミデータ (`reviews`) と感情ラベル (`labels`) を, PandasのDataFrame形式に変換します. \n",
    "- `'text'`: 口コミ内容を格納する列を `'text'` と命名します. \n",
    "- `'label'`: 感情ラベルを格納する列を `'評価'` と命名します. \n",
    "\n",
    "**2. 列名の変更**\n",
    "\n",
    "```python\n",
    "all_data.rename(columns={'text': '口コミ内容', 'label': '評価'}, inplace=True)\n",
    "```\n",
    "\n",
    "- `rename(columns=...)`: 列名を変更します. \n",
    "    - `'text'`: 元の列名\n",
    "    - `'口コミ内容'`: 変更後の列名\n",
    "    - `inplace=True`: 変更を元のDataFrameに反映します. \n",
    "- 同様に, `'label'` 列名を `'評価'` に変更します. \n",
    "\n",
    "**3. インデックスを列に格納**\n",
    "\n",
    "```python\n",
    "all_data.reset_index(drop=True, inplace=True)\n",
    "```\n",
    "\n",
    "- `reset_index`: DataFrameの行インデックスを列として追加します. \n",
    "    - `drop=True`: 元の行インデックスを削除します. \n",
    "    - `inplace=True`: 変更を元のDataFrameに反映します. \n",
    "\n",
    "**4. フレーム作成**\n",
    "\n",
    "```python\n",
    "frame = all_data\n",
    "```\n",
    "\n",
    "- `frame = all_data`: 上記で加工したDataFrameを `frame` という変数に格納します. \n",
    "\n",
    "**5. 左揃え設定**\n",
    "\n",
    "```python\n",
    "frame.style.set_properties(**{'text-align': 'left'})\n",
    "```\n",
    "\n",
    "- `style.set_properties`: DataFrameの表示形式を設定します. \n",
    "    - `**{...}``: 辞書形式で, 設定したいプロパティとその値を指定します. \n",
    "    - `'text-align': 'left'`: '口コミ内容' 列の文字列を左揃えに設定します. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの作成\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, reviews, labels, tokenizer, max_len):\n",
    "        self.reviews = reviews\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        review = str(self.reviews[item])\n",
    "        label = self.labels[item]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            review,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'review_text': review,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. クラスの定義**\n",
    "\n",
    "```python\n",
    "class ReviewDataset(Dataset):\n",
    "```\n",
    "\n",
    "- `class ReviewDataset(Dataset)`: `Dataset` クラスを継承した `ReviewDataset` クラスを定義します. \n",
    "- `Dataset` クラスは, PyTorchでデータローダーと連携してデータ処理を行うための基底クラスです. \n",
    "\n",
    "**2. コンストラクタ (`__init__`)**\n",
    "\n",
    "```python\n",
    "def __init__(self, reviews, labels, tokenizer, max_len):\n",
    "    self.reviews = reviews\n",
    "    self.labels = labels\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_len = max_len\n",
    "```\n",
    "\n",
    "- `__init__(self, reviews, labels, tokenizer, max_len)`: コンストラクタは, データセットを作成する際に呼び出されるメソッドです. \n",
    "    - `reviews`: 口コミデータのリスト\n",
    "    - `labels`: 感情ラベルのリスト\n",
    "    - `tokenizer`: Transformerライブラリのトークナイザ\n",
    "    - `max_len`: 最大トークン長\n",
    "- 上記の引数を, クラスのインスタンス変数として保持します. \n",
    "\n",
    "**3. データ件数取得 (`__len__`)**\n",
    "\n",
    "```python\n",
    "def __len__(self):\n",
    "    return len(self.reviews)\n",
    "```\n",
    "\n",
    "- `__len__(self)`: データセットに含まれるデータ件数を返します. \n",
    "- `len(self.reviews)`: `reviews` リストの長さを返します. \n",
    "\n",
    "**4. データ取得 (`__getitem__`)**\n",
    "\n",
    "```python\n",
    "def __getitem__(self, item):\n",
    "    review = str(self.reviews[item])\n",
    "    label = self.labels[item]\n",
    "\n",
    "    encoding = self.tokenizer.encode_plus(\n",
    "        review,\n",
    "        add_special_tokens=True,\n",
    "        max_length=self.max_len,\n",
    "        return_token_type_ids=False,\n",
    "        padding='max_length',\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt',\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'review_text': review,\n",
    "        'input_ids': encoding['input_ids'].flatten(),\n",
    "        'attention_mask': encoding['attention_mask'].flatten(),\n",
    "        'label': torch.tensor(label, dtype=torch.long)\n",
    "    }\n",
    "```\n",
    "\n",
    "- `__getitem__(self, item)`: 特定のインデックス `item` に対応するデータを返します. \n",
    "    - `review`: `reviews` リストから `item` 番目の口コミデータを取得します. \n",
    "    - `label`: `labels` リストから `item` 番目の感情ラベルを取得します. \n",
    "    - `tokenizer.encode_plus`: Transformerライブラリの `encode_plus` 関数を使って, 口コミデータをモデルに入力できる形式に変換します. \n",
    "        - `review`: 変換する口コミデータ\n",
    "        - `add_special_tokens=True`: 特別トークンを追加します. \n",
    "        - `max_length=self.max_len`: 最大トークン長を `self.max_len` に設定します. \n",
    "        - `return_token_type_ids=False`: トークンタイプIDを返しません. \n",
    "        - `padding='max_length'`: 最大トークン長までパディングを行います. \n",
    "        - `return_attention_mask=True`: アテンションマスクを返します. \n",
    "        - `return_tensors='pt'`: PyTorchテンソルとして返します. \n",
    "    - 変換されたデータと感情ラベルを辞書形式でまとめ, 返します. \n",
    "        - `'review_text'`: 変換前の口コミデータ\n",
    "        - `'input_ids'`: トークンIDのテンソル\n",
    "        - `'attention_mask'`: アテンションマスクのテンソル\n",
    "        - `'label'`: 感情ラベルのテンソル（long型）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込みと前処理\n",
    "def load_and_preprocess_data(filepaths):\n",
    "    reviews = []\n",
    "    labels = []\n",
    "    \n",
    "    for filepath in filepaths:\n",
    "        df = pd.read_csv(filepath)\n",
    "        reviews.extend(df['text'].tolist())\n",
    "        labels.extend(df['label'].tolist())\n",
    "\n",
    "    return reviews, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. 関数定義**\n",
    "\n",
    "```python\n",
    "def load_and_preprocess_data(filepaths):\n",
    "    reviews = []\n",
    "    labels = []\n",
    "    \n",
    "    for filepath in filepaths:\n",
    "        df = pd.read_csv(filepath)\n",
    "        reviews.extend(df['text'].tolist())\n",
    "        labels.extend(df['label'].tolist())\n",
    "\n",
    "    return reviews, labels\n",
    "```\n",
    "\n",
    "- `def load_and_preprocess_data(filepaths)`: 関数名を `load_and_preprocess_data` と定義し, 引数として `filepaths` を受け取ります. \n",
    "    - `filepaths`: 読み込むCSVファイルのパスをリスト形式で渡します. \n",
    "\n",
    "**2. データ読み込み**\n",
    "\n",
    "```python\n",
    "for filepath in filepaths:\n",
    "    df = pd.read_csv(filepath)\n",
    "    reviews.extend(df['text'].tolist())\n",
    "    labels.extend(df['label'].tolist())\n",
    "```\n",
    "\n",
    "- `for filepath in filepaths`: `filepaths` リスト内の各ファイルパスに対して処理を繰り返します. \n",
    "- `df = pd.read_csv(filepath)`: 指定されたファイルパスからCSVデータを読み込み, DataFrame形式に変換します. \n",
    "- `reviews.extend(df['text'].tolist())`: DataFrameの `'text'` 列の値をすべてリスト `reviews` に追加します. \n",
    "- `labels.extend(df['label'].tolist())`: DataFrameの `'label'` 列の値をすべてリスト `labels` に追加します. \n",
    "\n",
    "**3. 処理結果の返却**\n",
    "\n",
    "```python\n",
    "return reviews, labels\n",
    "```\n",
    "\n",
    "- 処理が完了したら, `reviews` と `labels` のリストをタプル形式で返します. \n",
    "\n",
    "**この関数を実行すると**\n",
    "\n",
    "- `filepaths` で指定されたCSVファイルから口コミデータと感情ラベルが読み込まれ, リスト形式で返されます. \n",
    "- 返されたリストは, Transformerライブラリのデータセット作成などに利用できます. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0:\n",
      "Text: 鮨 さいとうに4回目の訪問. 今回はランチでディナー同様, 摘みありのコースを注文させて頂きました. タイトルにもありますが, 気付けば2年ぶりの訪問. 食べ歩きをしてると2.3年再訪してないお店が沢山出てきますが, 再訪してもそれほど月日が経ってないように感じるのは私だけでしょうか. . 笑さて, 本題のお料理ですが, 摘み握り共に何を食べても美味しく, 今回も流石の安定感です. 何一つとして気になるものはありません. また, この日は以前よりずっと飲んでみたかった黒龍酒造の『ESHIKOTO』を頂きました. 超入手困難なスパークリングの日本酒です. 当たりがとてもドライで食事の邪魔を一切しないテイスト. 香りはほのかに日本酒を感じさせます. こんな貴重なお酒を入るのはさすが齋藤さんですね. 次回はいつ来れるか分かりませんが, またぜひ伺いたいです. ご馳走様でした. \n",
      "Input IDs: tensor([  101,   100,  1656, 30173, 30192, 30174, 30194,  2549,   100,  1918,\n",
      "         1671,   100,   100,  1012,   100,   100,  1672, 30257, 30263, 30236,\n",
      "        30191, 30239, 30220, 30241, 30265,  1794,   100,  1010,   100,  1678,\n",
      "        30172, 30212, 30197, 30230, 30265, 30233, 30216,   100,  1861,  1656,\n",
      "        30185, 30191,   100,  1652, 30203, 30183, 30187,  1012,  1709, 30221,\n",
      "        30240, 30259, 30194, 30207, 30172, 30212, 30203, 30184, 30177,  1010,\n",
      "          100,   100,  1654, 30198,  2475,  1840,  1674, 30212, 30197,   100,\n",
      "          100,  1012,  1978,  1675,   100,  1652, 30216, 30183, 30191, 30213,\n",
      "        30192,  2475,  1012,  1017,  1840,   100,   100,  1657, 30191, 30193,\n",
      "        30173, 30176,   100,  1651,  1898,  1831,  1774,  1665, 30178, 30203,\n",
      "        30184, 30177,  1010,   100,   100,  1657, 30191, 30207, 30186, 30214,\n",
      "        30202, 30192,  1872,  1864,  1651,   100,  1663, 30191, 30193, 30173,\n",
      "        30210, 30174, 30194,   100,  1657, 30213, 30197, 30198,   100,   100,\n",
      "         1012,  1012,   100,  1656, 30191,  1010,  1876,   100,  1671, 30176,\n",
      "          100,   100,  1665, 30184, 30177,  1010,   100,  1678,   100,  1686,\n",
      "          100,  1668,   100,  1690,  1978,  1675, 30191, 30207,  1935,   100,\n",
      "         1657, 30179,  1010,   100,   100,  1681,   100,  1922,  1671,  1820,\n",
      "         1822,   100,  1665, 30184,  1012,   100,  1740,  1664, 30192, 30183,\n",
      "        30191,   100,  1668, 30193, 30213, 30207, 30197, 30198, 30172, 30212,\n",
      "        30203, 30185, 30217,  1012,  1677, 30187,  1010,  1655, 30197,  1864,\n",
      "         1672,   100,  1776,  1684, 30212, 30184, 30189, 30192,   100,  1691,\n",
      "        30191, 30204, 30187, 30177, 30189, 30187,   100,  1982,   100,   100,\n",
      "         1671,  1643,  9686, 22204,  3406,  1644,  1690,   100,  1652, 30203,\n",
      "        30183, 30187,  1012,   100,   100,  1858,   100,   100,  1667, 30233,\n",
      "        30244, 30265, 30228, 30258, 30263, 30228, 30197,  1864,  1876,   100,\n",
      "         1665, 30184,  1012,   100,  1661, 30212, 30177, 30192, 30191, 30207,\n",
      "        30240, 30257, 30221, 30191,  1978,  1751,  1671,   100,   100,  1690,\n",
      "         1740,   100,  1657, 30193, 30173, 30239, 30221, 30233, 30240,  1012,\n",
      "         1979,  1686, 30198, 30202, 30197, 30177, 30194,  1864,  1876,   100,\n",
      "         1690,   100,  1657, 30182, 30185, 30203, 30184,  1012,  1655, 30217,\n",
      "        30193,  1953,   100,  1667, 30176,   100,  1690,   100,  1687, 30197,\n",
      "        30198, 30182, 30184, 30177,   100,  1944,  1656, 30217, 30191, 30184,\n",
      "        30196,  1012,   100,   100,  1672, 30173, 30190,   100,  1688, 30213,\n",
      "        30177,  1775,  1651, 30212, 30203, 30185, 30217, 30177,  1010,  1677,\n",
      "        30187, 30185, 30199,   100,  1647, 30187, 30173, 30191, 30184,  1012,\n",
      "         1655,   100,   100,   100,  1665, 30183, 30187,  1012,   102,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Label: 1\n",
      "==================================================\n",
      "Review 1:\n",
      "Text: 個人的に, 都内では大好きなお店の一つ. 3度目の訪問ですが, さいとうさんは時期が変わっても毎度ツマミも握りも安定感があり素晴らしいですね. この日, 初めて頂く「穴子の白焼き」は今まで食べた事ないくらい身がぷりぷりしており, 特に印象深い一品でした. さらに1人30,000円ちょっとと, 内容対してコスパの高さも嬉しいですね. また, 昼でも夜でも時期を変えて伺いたいです. ご馳走様でした. \n",
      "Input IDs: tensor([  101,   100,  1756,  1916,  1668,  1010,  1961,  1773,  1665, 30198,\n",
      "         1810,   100,  1652, 30193, 30176,   100,  1671,  1740,  1664,  1012,\n",
      "         1017,   100,  1918,  1671,   100,   100,  1665, 30184, 30177,  1010,\n",
      "         1656, 30173, 30192, 30174, 30182, 30217, 30198,   100,   100,  1651,\n",
      "          100,   100,   100,   100,  1712, 30249, 30250, 30207,   100,  1686,\n",
      "        30207,  1820,  1822,   100,  1651, 30172, 30212,   100,   100,  1685,\n",
      "        30183, 30173, 30191, 30184, 30196,  1012,  1655, 30197,  1864,  1010,\n",
      "          100,  1680, 30191,   100,  1653,  1641,   100,  1816,  1671,  1915,\n",
      "          100,  1652,  1642,  1672,   100,  1677, 30191,  1978,  1675, 30187,\n",
      "         1751,  1667, 30173, 30179, 30211, 30173,   100,  1651, 30200, 30212,\n",
      "        30200, 30212, 30183, 30191, 30176, 30212,  1010,   100,  1668,   100,\n",
      "          100,   100,  1647,  1740,   100,  1665, 30183, 30187,  1012,  1656,\n",
      "        30211, 30194,  2487,  1756,  2382,  1010,  2199,   100,   100,  1010,\n",
      "         1773,   100,   100,  1657, 30191, 30230, 30233, 30244, 30197,  1981,\n",
      "         1656, 30207,   100,  1657, 30173, 30191, 30184, 30196,  1012,  1677,\n",
      "        30187,  1010,   100,  1665, 30207,   100,  1665, 30207,   100,   100,\n",
      "         1690,   100,  1649, 30191,   100,  1647, 30187, 30173, 30191, 30184,\n",
      "         1012,  1655,   100,   100,   100,  1665, 30183, 30187,  1012,   102,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Label: 1\n",
      "==================================================\n",
      "Review 2:\n",
      "Text: 今月2度目のさいとうさんへ. 今回はランチ利用です. 握り15貫のみのコースを頂きました. （人によっては少し量が少なく感じる方もいらっしゃるかもしれません. ）マグロ中心に今回も大変美味しく頂きました. 価格も1人16,500円と, とても良心的な価格でびっくりしました. この立地でこの価格だと, そりゃ中々予約取れないわかです. また伺います. ご馳走様でした. \n",
      "Input IDs: tensor([  101,   100,  1872,  1016,   100,  1918,  1671, 30182, 30173, 30192,\n",
      "        30174, 30182, 30217, 30201,  1012,   100,   100,  1672, 30257, 30263,\n",
      "        30236,   100,   100,  1665, 30184,  1012,   100,  1686, 16068,   100,\n",
      "         1671, 30204, 30197, 30230, 30265, 30233, 30216,   100,  1652, 30203,\n",
      "        30183, 30187,  1012,  1987,  1756,  1668, 30210, 30189, 30191, 30198,\n",
      "          100,  1657,   100,  1651,   100,  1667, 30179,   100,  1657, 30213,\n",
      "         1863,   100,  1012,  1988,  1723, 30228, 30261,  1746,  1849,  1668,\n",
      "          100,   100,  1681,  1810,   100,  1935,   100,  1657, 30179,   100,\n",
      "         1652, 30203, 30183, 30187,  1012,   100,   100,  1681,  2487,  1756,\n",
      "         2385,  1010,  3156,   100,  1666,  1010,  1666, 30191, 30207,  1938,\n",
      "         1849,  1916,  1667,   100,   100,  1665, 30199, 30189, 30179, 30212,\n",
      "        30183, 30203, 30183, 30187,  1012,  1655, 30197,  1931,  1802,  1665,\n",
      "        30181, 30197,   100,   100,  1661, 30192,  1010,   100,  1746,   100,\n",
      "          100,   100,   100,   100,  1012,  1677, 30187,   100,  1647, 30203,\n",
      "        30184,  1012,  1655,   100,   100,   100,  1665, 30183, 30187,  1012,\n",
      "          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Label: 1\n",
      "==================================================\n",
      "Review 3:\n",
      "Text: 言わずと知れた4年連続食べログゴールド, 2019年まで10年連続ミシュラン3つ星のお店です. 今回はお誘い頂き訪問してきました. その人気ぶりから現在では, 完全会員制を取っており, 一見での予約は不可になっております. さて, お寿司に関しては非常に素晴らしいです. できることなら会員になって通い続けたいお店です. ネタもシャリもとても個人的に好みでした. 特にシャリは酢と塩味が強く無く, 割と万人受けするかな, といった印象. 次いついけるか分かりませんが, ぜひまた伺いたいです. ご馳走様でした. \n",
      "Input IDs: tensor([  101,   100,   100,   100,  1688, 30187,  2549,  1840,   100,   100,\n",
      "         1978,  1675, 30261, 30228, 30230, 30265, 30259, 30240,  1010, 10476,\n",
      "         1840,  1677, 30191, 10790,  1840,   100,   100,  1724, 30232, 30255,\n",
      "        30257, 30263,  2509, 30190,  1866,  1671, 30176,   100,  1665, 30184,\n",
      "         1012,   100,   100,  1672, 30176,   100,  1647,   100,  1652,   100,\n",
      "          100,  1657, 30191, 30178, 30203, 30183, 30187,  1012,  1660, 30197,\n",
      "         1756,   100,  1674, 30212, 30177, 30211,   100,   100,  1665, 30198,\n",
      "         1010,   100,   100,  1763,   100,   100,  1690,   100,  1663, 30191,\n",
      "        30176, 30212,  1010,  1740,  1948,  1665, 30197,   100,   100,  1672,\n",
      "         1744,   100,  1668, 30193, 30189, 30191, 30176, 30212, 30203, 30184,\n",
      "         1012,  1656, 30191,  1010,  1650,   100,  1791,  1668,   100,  1657,\n",
      "        30191, 30198,   100,   100,  1668,   100,   100,  1685, 30183, 30173,\n",
      "        30191, 30184,  1012,  1665, 30178, 30213, 30181, 30192, 30193, 30211,\n",
      "         1763,   100,  1668, 30193, 30189, 30191,   100,  1647,   100,  1654,\n",
      "        30187, 30173, 30176,   100,  1665, 30184,  1012,   100,   100,  1756,\n",
      "         1916,  1668,   100,  1678, 30191, 30183, 30187,  1012,   100,  1668,\n",
      "        30232, 30254, 30258, 30198,   100,  1666,   100,   100,  1651,   100,\n",
      "         1653,   100,  1653,  1010,   100,  1666,   100,  1756,   100,  1654,\n",
      "        30184, 30213, 30177, 30193,  1010,  1666, 30173, 30189, 30187,   100,\n",
      "          100,  1012,   100,  1647, 30190, 30173, 30180, 30213, 30177,  1775,\n",
      "         1651, 30212, 30203, 30185, 30217, 30177,  1010,  1659, 30199, 30203,\n",
      "        30187,   100,  1647, 30187, 30173, 30191, 30184,  1012,  1655,   100,\n",
      "          100,   100,  1665, 30183, 30187,  1012,   102,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Label: 1\n",
      "==================================================\n",
      "Review 4:\n",
      "Text: 楽しい時間を過ごす事が出来ました. また是非伺いたいと思います. ご馳走様でした. \n",
      "Input IDs: tensor([  101,   100,  1657, 30173,   100,  1969,  1690,   100,  1655, 30184,\n",
      "         1751,  1651,  1774,   100,  1677, 30183, 30187,  1012,  1677, 30187,\n",
      "          100,   100,   100,  1647, 30187, 30173, 30192,   100,  1647, 30203,\n",
      "        30184,  1012,  1655,   100,   100,   100,  1665, 30183, 30187,  1012,\n",
      "          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Label: 1\n",
      "==================================================\n",
      "Review 5:\n",
      "Text: 今回は個室で『鮨さいとう』二番手の沼尾さんの鮨を堪能しました. 仕事も所作も丁寧で, 安心して食に集中出来ました. 酢飯の酸度・塩味・硬さ等かなり好み. ネタも間違いのないものばかりでした！ご馳走様でした. \n",
      "Input IDs: tensor([  101,   100,   100,  1672,   100,   100,  1665,  1643,   100,  1656,\n",
      "        30173, 30192, 30174,  1644,  1752,   100,  1858,  1671,   100,   100,\n",
      "         1656, 30217, 30197,   100,  1690,   100,   100,  1657, 30203, 30183,\n",
      "        30187,  1012,   100,  1751,  1681,   100,   100,  1681,   100,   100,\n",
      "         1665,  1010,  1820,  1849,  1657, 30191,  1978,  1668,   100,  1746,\n",
      "         1774,   100,  1677, 30183, 30187,  1012,   100,   100,  1671,   100,\n",
      "          100,  1738,   100,   100,  1738,   100,  1656,   100,  1651, 30193,\n",
      "        30212,   100,  1678,  1012,   100,  1969,   100,  1647, 30197, 30193,\n",
      "        30173, 30207, 30197, 30198, 30177, 30212, 30191, 30183, 30187,  1986,\n",
      "         1655,   100,   100,   100,  1665, 30183, 30187,  1012,   102,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Label: 1\n",
      "==================================================\n",
      "Review 6:\n",
      "Text: 最高峰と言われるお鮨屋さんお鮨だけを楽しみに行くのではなく, 大将との会話, 雰囲気, 異空間を味わいながら食べるお鮨屋さん. お鮨は美味しい. 特にこれがというのはないが, 美味しい. 1番驚いたのは鮨屋とは思えない独特な雰囲気があるお店. 大将とお客さんの一体感のある空間でお鮨を楽しめます. 大将の人柄で人気なっているお店. お鮨だけを食べに行くには勿体無いいいお鮨屋さんでした. さいとうさんのにぎるお鮨を食べられたことに感謝. \n",
      "Input IDs: tensor([  101,   100,  1981,   100,  1666,   100,   100,   100,   100,  1656,\n",
      "        30217, 30176,   100,  1661, 30180, 30216,   100,  1657, 30204, 30194,\n",
      "         1945,  1653, 30197, 30191, 30198, 30193, 30179,  1010,  1810,   100,\n",
      "         1666, 30197,  1763,   100,  1010,   100,   100,   100,  1010,   100,\n",
      "         1930,  1969,  1690,   100,   100,  1978,  1675, 30213, 30176,   100,\n",
      "          100,  1656, 30217,  1012,  1650,   100,  1672,  1935,   100,  1657,\n",
      "        30173,  1012,   100,  1668, 30181, 30214, 30177, 30192, 30173, 30174,\n",
      "        30197, 30198, 30193, 30173, 30177,  1010,  1935,   100,  1657, 30173,\n",
      "         1012,  1015,   100,   100,  1647, 30187, 30197, 30198,   100,   100,\n",
      "         1666, 30198,   100,  1649, 30193, 30173,   100,   100,  1667,   100,\n",
      "          100,   100,  1651, 30172, 30213, 30176,   100,  1012,  1810,   100,\n",
      "         1666, 30176,   100,  1656, 30217, 30197,  1740,   100,   100,  1671,\n",
      "        30172, 30213,  1930,  1969,  1665, 30176,   100,  1690,   100,  1657,\n",
      "        30206, 30203, 30184,  1012,  1810,   100,  1671,  1756,   100,  1665,\n",
      "         1756,   100,  1667, 30189, 30191, 30173, 30213, 30176,   100,  1012,\n",
      "         1650,   100,  1661, 30180, 30216,  1978,  1675, 30194,  1945,  1653,\n",
      "        30194, 30198,   100,   100,   100,  1647, 30173, 30173, 30176,   100,\n",
      "          100,  1656, 30217, 30191, 30183, 30187,  1012,  1656, 30173, 30192,\n",
      "        30174, 30182, 30217, 30197, 30194, 30178, 30213, 30176,   100,  1690,\n",
      "         1978,  1675, 30211, 30214, 30187, 30181, 30192, 30194,   100,   100,\n",
      "         1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Label: 1\n",
      "==================================================\n",
      "Review 7:\n",
      "Text: 念願の大将のお席!カツオのたたきはこれまで食べた1番の美味しさ. 熟成されたねっとり感で, 旨みがギュッ!パサつき全く無い仕上がり. 優しい, 鮑, たこ, など, おつまみも最高!握りはふわっと優しいシャリとの一体感が素晴らしい. 最初のあたたかめのシャリと白身が新鮮で美味. 甘すぎないツメもよく, 蛤や穴子も, 素材の美味しさか際立つ！来年ですが, また, 次回も楽しみ！\n",
      "Input IDs: tensor([  101,   100,   100,  1671,  1810,   100,  1671, 30176,   100,   999,\n",
      "         1700, 30238, 30225, 30197, 30187, 30187, 30178, 30198, 30181, 30214,\n",
      "        30203, 30191,  1978,  1675, 30187,  2487,   100,  1671,  1935,   100,\n",
      "         1657, 30182,  1012,   100,  1854,  1656, 30214, 30187, 30196, 30189,\n",
      "        30192, 30212,   100,  1665,  1010,   100,  1678, 30177, 30227, 30255,\n",
      "        30237,   999,  1718, 30231, 30190, 30178,   100,  1653,   100,  1647,\n",
      "          100,  1742,  1651, 30212,  1012,   100,  1657, 30173,  1010,   100,\n",
      "         1010,  1661, 30181,  1010,  1667, 30192,  1010,  1650, 30190, 30203,\n",
      "        30204, 30207,   100,  1981,   999,   100,   100,   100,  1657, 30173,\n",
      "        30232, 30254, 30258, 30192, 30197,  1740,   100,   100,  1651,   100,\n",
      "          100,  1685, 30183, 30173,  1012,   100,   100,  1671, 30172, 30187,\n",
      "        30187, 30177, 30206, 30197, 30232, 30254, 30258, 30192,  1915,   100,\n",
      "         1651,  1862,   100,  1665,  1935,   100,  1012,   100,  1658, 30178,\n",
      "        30193, 30173, 30238, 30252, 30207, 30210, 30179,  1010,   100,  1682,\n",
      "          100,  1816,  1681,  1010,   100,   100,  1671,  1935,   100,  1657,\n",
      "        30182, 30177,   100,  1931,  1664,  1986,   100,  1840,  1665, 30184,\n",
      "        30177,  1010,  1677, 30187,  1010,   100,   100,  1681,   100,  1657,\n",
      "        30204,  1986,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Label: 1\n",
      "==================================================\n",
      "Review 8:\n",
      "Text: 日本の鮨店, 最高峰の1つ. 超予約困難店です. 1度訪れてみたかったお店ですが, 常連様にお誘い頂き, 伺うことができました. こちらのお店は・10年連続ミシュラン3つ星も会員制にするために返上・食べログGOLD(全国で30店舗ほどのみ)連続獲得・世界のグルメガイド, フランスの「ラ・リスト2024」で99.5点の日本最高評価を獲得. また, 世界でも上位7位. ・新規予約は基本受付しておらず, 食オクでのオークションのみ・食オクでは1席40万円や70万円の値がつくこともお店は六本木一丁目駅直結のアークヒルズタワー1階にあります. やや分かりづらい場所です. 店内は個室が2つあり, 個室内はL字のカウンター8席ほど. この日は, 2番手の沼尾大将の貸切会でした. お鮨はもちろんですが蒸し鮑と蛸の桜煮の旨味が凄く, 鰹の皮目がパリッとした火入れと最初のつまみがとても美味しく感動しました. つまみも握りもハイクオリティですが会話も楽しく雰囲気づくりも抜群. 価格は高いですが, 他のお鮨やさんと一線を画すほど美味しく満足度は高いです. 純粋に美味しくて, また来たいなぁと思える素晴らしいお鮨でした！ご馳走様でした！\n",
      "Input IDs: tensor([  101,  1864,  1876,  1671,   100,   100,  1010,   100,  1981,   100,\n",
      "         1671,  2487, 30190,  1012,   100,   100,   100,   100,   100,   100,\n",
      "         1665, 30184,  1012,  1015,   100,   100,  1688, 30191, 30204, 30187,\n",
      "        30177, 30189, 30187, 30176,   100,  1665, 30184, 30177,  1010,   100,\n",
      "          100,   100,  1668, 30176,   100,  1647,   100,  1652,  1010,   100,\n",
      "         1648, 30181, 30192, 30177, 30191, 30178, 30203, 30183, 30187,  1012,\n",
      "         1655, 30188, 30211, 30197, 30176,   100,  1672,  1738,  2184,  1840,\n",
      "          100,   100,  1724, 30232, 30255, 30257, 30263,  2509, 30190,  1866,\n",
      "         1681,  1763,   100,   100,  1668, 30184, 30213, 30187, 30206, 30194,\n",
      "          100,  1742,  1738,  1978,  1675, 30261, 30228, 21270,  1006,   100,\n",
      "         1799,  1665, 14142,   100,   100,  1676, 30192, 30197, 30204,  1007,\n",
      "          100,   100,   100,   100,  1738,  1745,   100,  1671, 30228, 30259,\n",
      "        30252, 30226, 30221, 30240,  1010,  1720, 30257, 30263, 30233, 30197,\n",
      "         1641,  1731,  1738,  1732, 30233, 30240, 11387, 18827,  1642,  1665,\n",
      "         2683,  2683,  1012,  1019,   100,  1671,  1864,  1876,   100,  1981,\n",
      "          100,   100,  1690,   100,   100,  1012,  1677, 30187,  1010,  1745,\n",
      "          100,  1665, 30207,  1742,   100,  1021,   100,  1012,  1738,  1862,\n",
      "          100,   100,   100,  1672,   100,  1876,   100,   100,  1657, 30191,\n",
      "        30176, 30211, 30184,  1010,  1978,  1699, 30228, 30191, 30197, 30225,\n",
      "        30265, 30228, 30232, 30256, 30263, 30197, 30204,  1738,  1978,  1699,\n",
      "        30228, 30191, 30198,  2487,   100,  2871,   100,   100,  1682, 19841,\n",
      "          100,   100,  1671,   100,  1651, 30190, 30179, 30181, 30192, 30207,\n",
      "        30176,   100,  1672,   100,  1876,  1875,  1740,   100,  1918,   100,\n",
      "          100,   100,  1671, 30219, 30265, 30228, 30245, 30259, 30233, 30235,\n",
      "        30262, 30265,  2487,   100,  1668, 30172, 30212, 30203, 30184,  1012,\n",
      "         1682, 30208,  1775,  1651, 30212, 30190, 30211, 30173,  1806,   100,\n",
      "         1665, 30184,  1012,   100,  1773,  1672,   100,   100,  1651,  2475,\n",
      "        30190, 30172, 30212,  1010,   100,   100,  1773,  1672,  2140,   100,\n",
      "         1671, 30226, 30222, 30263, 30235, 30265,  2620,   100,  1676, 30192,\n",
      "         1012,  1655, 30197,  1864,  1672,  1010,  1016,   100,  1858,  1671,\n",
      "          100,   100,  1810,   100,  1671,   100,   100,  1763,  1665, 30183,\n",
      "        30187,  1012,  1650,   100,  1672, 30207, 30188, 30215, 30217, 30191,\n",
      "        30184, 30177,   100,  1657,   100,  1666,   100,  1671,   100,   100,\n",
      "         1671,   100,   100,  1651,   100,  1653,  1010,   100,  1671,   100,\n",
      "         1918,  1651, 30244, 30258, 30237, 30192, 30183, 30187,  1906,   100,\n",
      "         1688, 30192,   100,   100,  1671, 30190, 30203, 30204, 30177, 30192,\n",
      "        30191, 30207,  1935,   100,  1657, 30179,   100,   100,  1657, 30203,\n",
      "        30183, 30187,  1012,  1664, 30203, 30204, 30207,   100,  1686, 30207,\n",
      "        30244, 30221, 30228, 30225, 30258, 30239, 30220, 30191, 30184, 30177,\n",
      "         1763,   100,  1681,   100,  1657, 30179,   100,   100,   100,  1664,\n",
      "        30179, 30212, 30207,   100,   100,  1012,   100,   100,  1672,  1981,\n",
      "         1647, 30191, 30184, 30177,  1010,   100,  1671, 30176,   100,  1682,\n",
      "        30182, 30217, 30192,  1740,   100,  1690,   100,  1658, 30202, 30192,\n",
      "         1935,   100,  1657, 30179,   100,   100,   100,  1672,  1981,  1647,\n",
      "        30191, 30184,  1012,   100,   100,  1668,  1935,   100,  1657, 30179,\n",
      "        30191,  1010,  1677, 30187,   100,   100,   100,  1649, 30213,   100,\n",
      "          100,  1685, 30183, 30173, 30176,   100,  1665, 30183, 30187,  1986,\n",
      "         1655,   100,   100,   100,  1665, 30183, 30187,  1986,   102,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Label: 1\n",
      "==================================================\n",
      "Review 9:\n",
      "Text: 日本最高峰のお鮨のお店に, 幸運にもお誘いいただき, 訪問することができました. この日は, 個室の沼尾大将に握っていただきました. 貸切ということもあり, リラックスして, 美味しいお酒を飲みながら, 最高のお鮨を食べて, 幸せな時間を過ごすことができました. ご馳走様でした！！！\n",
      "Input IDs: tensor([  101,  1864,  1876,   100,  1981,   100,  1671, 30176,   100,  1671,\n",
      "        30176,   100,  1668,  1010,  1841,   100,  1668, 30207, 30176,   100,\n",
      "         1647, 30173, 30187, 30187, 30178,  1010,   100,   100,  1658, 30213,\n",
      "        30181, 30192, 30177, 30191, 30178, 30203, 30183, 30187,  1012,  1655,\n",
      "        30197,  1864,  1672,  1010,   100,   100,  1671,   100,   100,  1810,\n",
      "          100,  1668,   100,  1663, 30191, 30173, 30187, 30187, 30178, 30203,\n",
      "        30183, 30187,  1012,   100,   100,  1666, 30173, 30174, 30181, 30192,\n",
      "        30207, 30172, 30212,  1010,  1732, 30257, 30237, 30228, 30233, 30183,\n",
      "        30191,  1010,  1935,   100,  1657, 30173, 30176,   100,  1690,   100,\n",
      "         1678, 30193, 30177, 30211,  1010,   100,  1981,  1671, 30176,   100,\n",
      "         1690,  1978,  1675, 30191,  1010,  1841,  1659, 30193,   100,  1969,\n",
      "         1690,   100,  1655, 30184, 30181, 30192, 30177, 30191, 30178, 30203,\n",
      "        30183, 30187,  1012,  1655,   100,   100,   100,  1665, 30183, 30187,\n",
      "         1986,  1986,  1986,   102,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Label: 1\n",
      "==================================================\n",
      "Review 10:\n",
      "Text: 食べログお鮨ランキング1位にしてミシュラン3つ星, 泣く子もだまるさいとう, 2月に続いて3月もさいとうさんへ, ミシュラン3つ星を取ったのは随分前だが最近になっても美味しさが増している気がする. \n",
      "Input IDs: tensor([  101,  1978,  1675, 30261, 30228, 30176,   100,  1731, 30263, 30227,\n",
      "        30263, 30228,  2487,   100,  1668, 30183, 30191, 30250, 30232, 30255,\n",
      "        30257, 30263,  2509, 30190,  1866,  1010,   100,  1653,  1816,  1681,\n",
      "        30187, 30203, 30213, 30182, 30173, 30192, 30174,  1010,  1016,  1872,\n",
      "         1668,   100,  1647, 30191,  2509,  1872,  1681, 30182, 30173, 30192,\n",
      "        30174, 30182, 30217, 30201,  1010,  1724, 30232, 30255, 30257, 30263,\n",
      "         2509, 30190,  1866,  1690,   100,  1663, 30187, 30197, 30198,   100,\n",
      "         1775,  1776,  1661, 30177,   100,   100,  1668, 30193, 30189, 30191,\n",
      "        30207,  1935,   100,  1657, 30182, 30177,   100,  1657, 30191, 30173,\n",
      "        30213,   100,  1651, 30184, 30213,  1012,   102,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Label: 1\n",
      "==================================================\n",
      "Review 11:\n",
      "Text: 日本最高峰のお寿司と聞いていたのですが, お値段に比べてあまり美味しいと思いませんでした. \n",
      "Input IDs: tensor([  101,  1864,  1876,   100,  1981,   100,  1671, 30176,   100,  1791,\n",
      "         1666,   100,  1647, 30191, 30173, 30187, 30197, 30191, 30184, 30177,\n",
      "         1010,  1650,   100,   100,  1668,  1890,  1675, 30191, 30172, 30203,\n",
      "        30212,  1935,   100,  1657, 30173, 30192,   100,  1647, 30203, 30185,\n",
      "        30217, 30191, 30183, 30187,  1012,   102,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Label: 0\n",
      "==================================================\n",
      "Review 12:\n",
      "Text: イベントの際にお邪魔しました. 少し値段が高い気がします. \n",
      "Input IDs: tensor([  101,  1695, 30247, 30263, 30240, 30197,   100,  1668, 30176,   100,\n",
      "          100,  1657, 30203, 30183, 30187,  1012,   100,  1657,   100,   100,\n",
      "         1651,  1981,  1647,   100,  1651, 30183, 30203, 30184,  1012,   102,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Label: 0\n",
      "==================================================\n",
      "Review 13:\n",
      "Text: イカやタコが美味しかったですが, マグロは微妙でした.\n",
      "Input IDs: tensor([  101,  1695, 30226, 30208, 30235, 30230, 30177,  1935,   100,  1657,\n",
      "        30177, 30189, 30187, 30191, 30184, 30177,  1010,  1723, 30228, 30261,\n",
      "        30198,   100,   100,  1665, 30183, 30187,  1012,   102,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Label: 0\n",
      "==================================================\n",
      "Review 14:\n",
      "Text: お値段が高いので, もう少し美味しいものが食べたかったです.\n",
      "Input IDs: tensor([  101,  1650,   100,   100,  1651,  1981,  1647, 30197, 30191,  1010,\n",
      "         1681, 30174,   100,  1657,  1935,   100,  1657, 30173, 30207, 30197,\n",
      "        30177,  1978,  1675, 30187, 30177, 30189, 30187, 30191, 30184,  1012,\n",
      "          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Label: 0\n",
      "==================================================\n",
      "Review 15:\n",
      "Text: 雰囲気が少し怖く感じました.\n",
      "Input IDs: tensor([  101,   100,   100,   100,  1651,   100,  1657,   100,  1653,   100,\n",
      "         1657, 30203, 30183, 30187,  1012,   102,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Label: 0\n",
      "==================================================\n",
      "Review 16:\n",
      "Text: 味がイマイチだったので, また行くかは検討中です.\n",
      "Input IDs: tensor([  101,   100,  1651, 30221, 30249, 30221, 30236, 30187, 30189, 30187,\n",
      "        30197, 30191,  1010,  1677, 30187,  1945,  1653, 30177, 30198,   100,\n",
      "          100,  1746,  1665, 30184,  1012,   102,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Label: 0\n",
      "==================================================\n",
      "Review 17:\n",
      "Text: お値段が高いので, 期待していたほど美味しくなかったです.\n",
      "Input IDs: tensor([  101,  1650,   100,   100,  1651,  1981,  1647, 30197, 30191,  1010,\n",
      "          100,   100,  1657, 30191, 30173, 30187, 30202, 30192,  1935,   100,\n",
      "         1657, 30179, 30193, 30177, 30189, 30187, 30191, 30184,  1012,   102,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Label: 0\n",
      "==================================================\n",
      "Review 18:\n",
      "Text: 電話対応が悪かったので, また行くかは検討中です.\n",
      "Input IDs: tensor([  101,   100,   100,   100,   100,  1651,   100,  1651, 30189, 30187,\n",
      "        30197, 30191,  1010,  1677, 30187,  1945,  1653, 30177, 30198,   100,\n",
      "          100,  1746,  1665, 30184,  1012,   102,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Label: 0\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# CSVファイルのパスリストを作成\n",
    "filepaths = [os.path.join('text', f'review_{i}.csv') for i in range(19)]\n",
    "\n",
    "# データの読み込み\n",
    "reviews, labels = load_and_preprocess_data(filepaths)\n",
    "\n",
    "# トークナイザーの初期化\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# データセットの作成\n",
    "dataset = ReviewDataset(reviews, labels, tokenizer, max_len=500)\n",
    "data_loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# 前処理したデータを表示\n",
    "for i, data in enumerate(data_loader):\n",
    "    print(f\"Review {i}:\")\n",
    "    print(f\"Text: {data['review_text'][0]}\")\n",
    "    print(f\"Input IDs: {data['input_ids'][0]}\")\n",
    "    print(f\"Attention Mask: {data['attention_mask'][0]}\")\n",
    "    print(f\"Label: {data['label'][0]}\")\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. CSVファイルパスリストの作成**\n",
    "\n",
    "```python\n",
    "filepaths = [f'review_{i}.csv' for i in range(12)]\n",
    "```\n",
    "\n",
    "- `[f'review_{i}.csv' for i in range(12)]`: 0から11までのインデックスを持つリストを作成し, 各要素に `f'review_{i}.csv'` という形式の文字列を代入します. \n",
    "    - `f'review_{i}.csv'`: 文字列フォーマットを用いて, `i` を動的に文字列に埋め込みます. \n",
    "- 結果的に, `filepaths` リストには以下のファイルパスが含まれます. \n",
    "    - `review_0.csv`\n",
    "    - `review_1.csv`\n",
    "    - ...\n",
    "    - `review_10.csv`\n",
    "    - `review_11.csv`\n",
    "\n",
    "**2. データの読み込み**\n",
    "\n",
    "```python\n",
    "reviews, labels = load_and_preprocess_data(filepaths)\n",
    "```\n",
    "\n",
    "- `load_and_preprocess_data` 関数を呼び出し, `filepaths` リストを引数として渡します. \n",
    "- 関数から返された口コミデータと感情ラベルを, それぞれ `reviews` と `labels` 変数に格納します. \n",
    "\n",
    "**3. トークナイザーの初期化**\n",
    "\n",
    "```python\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "```\n",
    "\n",
    "- `BertTokenizer.from_pretrained('bert-base-uncased')`: 事前に学習済みのBERTトークナイザ `bert-base-uncased` をロードし, `tokenizer` 変数に格納します. \n",
    "- このトークナイザは, 日本語を含む様々な言語のテキストを, Transformerモデルで利用できる形式に変換するために使用されます. \n",
    "\n",
    "**4. データセットの作成**\n",
    "\n",
    "```python\n",
    "dataset = ReviewDataset(reviews, labels, tokenizer, max_len=160)\n",
    "```\n",
    "\n",
    "- `ReviewDataset` クラスを使って, `reviews`, `labels`, `tokenizer`, `max_len` を引数として `dataset` インスタンスを作成します. \n",
    "    - `reviews`: 前処理済みの口コミデータ\n",
    "    - `labels`: 感情ラベル\n",
    "    - `tokenizer`: トークナイザ\n",
    "    - `max_len`: 最大トークン長（160に設定）\n",
    "- `ReviewDataset` クラスは, Transformerライブラリで利用できる形式のデータセットを生成します. \n",
    "\n",
    "**5. データローダーの作成**\n",
    "\n",
    "```python\n",
    "data_loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "```\n",
    "\n",
    "- `DataLoader` クラスを使って, `dataset` インスタンスを基に `data_loader` インスタンスを作成します. \n",
    "    - `batch_size=1`: 1つのバッチに1つのデータのみを含めます. \n",
    "    - `shuffle=False`: データの順番をランダムにシャッフルしません. \n",
    "- `data_loader` は, ミニバッチ単位でデータを効率的に処理するためのツールです. \n",
    "\n",
    "**6. 前処理したデータの表示**\n",
    "\n",
    "```python\n",
    "for i, data in enumerate(data_loader):\n",
    "    print(f\"Review {i}:\")\n",
    "    print(f\"Text: {data['review_text'][0]}\")\n",
    "    print(f\"Input IDs: {data['input_ids'][0]}\")\n",
    "    print(f\"Attention Mask: {data['attention_mask'][0]}\")\n",
    "    print(f\"Label: {data['label'][0]}\")\n",
    "    print(\"=\"*50)\n",
    "```\n",
    "\n",
    "- `for i, data in enumerate(data_loader)`: `data_loader` からミニバッチ単位でデータをループ処理します. \n",
    "    - `i`: バッチのインデックス\n",
    "    - `data`: ミニバッチデータ\n",
    "- 各バッチについて, 以下の情報を表示します. \n",
    "    - `Review {i}`: バッチのインデックス\n",
    "    - `Text`: 元の口コミテキスト\n",
    "    - `Input IDs`: トークンIDのリスト\n",
    "    - `Attention Mask`: アテンションマスクのリスト\n",
    "    - `Label`: 感情ラベル\n",
    "    - `=` * 50: 区切り線\n",
    "- この処理により, 前処理された口コミデータがどのようにTransformerモデルに入力されるのかを確認することができます. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "# モデルの定義\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "  device = torch.device('mps')\n",
    "else:\n",
    "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. モデルの定義**\n",
    "\n",
    "```python\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "```\n",
    "\n",
    "- `BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)`: 事前に学習済みのBERTモデル `bert-base-uncased` をロードし, `model` 変数に格納します. \n",
    "    - `BertForSequenceClassification`: テキスト分類タスクに特化したBERTモデルクラス\n",
    "    - `'bert-base-uncased'`: 事前に学習済みのモデル名\n",
    "    - `num_labels=2`: 出力ラベルの数を2つに設定（ポジティブ/ネガティブの2クラス分類）\n",
    "- このモデルは, 2つの文章を比較したり, 文章の感情を分析したりするようなタスクに適しています. \n",
    "\n",
    "**2. デバイス設定**\n",
    "\n",
    "```python\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "  device = torch.device('mps')\n",
    "else:\n",
    "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "model = model.to(device)\n",
    "```\n",
    "\n",
    "- このコードは, モデルを実行するデバイスを設定します. \n",
    "    - `torch.device('cuda')`: GPUを利用する場合\n",
    "    - `torch.device('cpu')`: CPUを利用する場合\n",
    "- 処理速度向上のため, GPUが利用可能であれば優先的に利用するようにしています. \n",
    "- `model.to(device)`: モデルを指定されたデバイスに移動します. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.42105263157894735\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.42      1.00      0.59         8\n",
      "    Positive       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.42        19\n",
      "   macro avg       0.21      0.50      0.30        19\n",
      "weighted avg       0.18      0.42      0.25        19\n",
      "\n",
      "Review 1:\n",
      "Text: 鮨 さいとうに4回目の訪問. 今回はランチでディナー同様, 摘みありのコースを注文させて頂きました. タイトルにもありますが, 気付けば2年ぶりの訪問. 食べ歩きをしてると2.3年再訪してないお店が沢山出てきますが, 再訪してもそれほど月日が経ってないように感じるのは私だけでしょうか. . 笑さて, 本題のお料理ですが, 摘み握り共に何を食べても美味しく, 今回も流石の安定感です. 何一つとして気になるものはありません. また, この日は以前よりずっと飲んでみたかった黒龍酒造の『ESHIKOTO』を頂きました. 超入手困難なスパークリングの日本酒です. 当たりがとてもドライで食事の邪魔を一切しないテイスト. 香りはほのかに日本酒を感じさせます. こんな貴重なお酒を入るのはさすが齋藤さんですね. 次回はいつ来れるか分かりませんが, またぜひ伺いたいです. ご馳走様でした. \n",
      "True Label: Positive\n",
      "Predicted Label: Negative\n",
      "Probabilities: Positive - 0.3823, Negative - 0.6177\n",
      "==================================================\n",
      "Review 2:\n",
      "Text: 個人的に, 都内では大好きなお店の一つ. 3度目の訪問ですが, さいとうさんは時期が変わっても毎度ツマミも握りも安定感があり素晴らしいですね. この日, 初めて頂く「穴子の白焼き」は今まで食べた事ないくらい身がぷりぷりしており, 特に印象深い一品でした. さらに1人30,000円ちょっとと, 内容対してコスパの高さも嬉しいですね. また, 昼でも夜でも時期を変えて伺いたいです. ご馳走様でした. \n",
      "True Label: Positive\n",
      "Predicted Label: Negative\n",
      "Probabilities: Positive - 0.3815, Negative - 0.6185\n",
      "==================================================\n",
      "Review 3:\n",
      "Text: 今月2度目のさいとうさんへ. 今回はランチ利用です. 握り15貫のみのコースを頂きました. （人によっては少し量が少なく感じる方もいらっしゃるかもしれません. ）マグロ中心に今回も大変美味しく頂きました. 価格も1人16,500円と, とても良心的な価格でびっくりしました. この立地でこの価格だと, そりゃ中々予約取れないわかです. また伺います. ご馳走様でした. \n",
      "True Label: Positive\n",
      "Predicted Label: Negative\n",
      "Probabilities: Positive - 0.3872, Negative - 0.6128\n",
      "==================================================\n",
      "Review 4:\n",
      "Text: 言わずと知れた4年連続食べログゴールド, 2019年まで10年連続ミシュラン3つ星のお店です. 今回はお誘い頂き訪問してきました. その人気ぶりから現在では, 完全会員制を取っており, 一見での予約は不可になっております. さて, お寿司に関しては非常に素晴らしいです. できることなら会員になって通い続けたいお店です. ネタもシャリもとても個人的に好みでした. 特にシャリは酢と塩味が強く無く, 割と万人受けするかな, といった印象. 次いついけるか分かりませんが, ぜひまた伺いたいです. ご馳走様でした. \n",
      "True Label: Positive\n",
      "Predicted Label: Negative\n",
      "Probabilities: Positive - 0.3768, Negative - 0.6232\n",
      "==================================================\n",
      "Review 5:\n",
      "Text: 楽しい時間を過ごす事が出来ました. また是非伺いたいと思います. ご馳走様でした. \n",
      "True Label: Positive\n",
      "Predicted Label: Negative\n",
      "Probabilities: Positive - 0.4047, Negative - 0.5953\n",
      "==================================================\n",
      "Review 6:\n",
      "Text: 今回は個室で『鮨さいとう』二番手の沼尾さんの鮨を堪能しました. 仕事も所作も丁寧で, 安心して食に集中出来ました. 酢飯の酸度・塩味・硬さ等かなり好み. ネタも間違いのないものばかりでした！ご馳走様でした. \n",
      "True Label: Positive\n",
      "Predicted Label: Negative\n",
      "Probabilities: Positive - 0.3922, Negative - 0.6078\n",
      "==================================================\n",
      "Review 7:\n",
      "Text: 最高峰と言われるお鮨屋さんお鮨だけを楽しみに行くのではなく, 大将との会話, 雰囲気, 異空間を味わいながら食べるお鮨屋さん. お鮨は美味しい. 特にこれがというのはないが, 美味しい. 1番驚いたのは鮨屋とは思えない独特な雰囲気があるお店. 大将とお客さんの一体感のある空間でお鮨を楽しめます. 大将の人柄で人気なっているお店. お鮨だけを食べに行くには勿体無いいいお鮨屋さんでした. さいとうさんのにぎるお鮨を食べられたことに感謝. \n",
      "True Label: Positive\n",
      "Predicted Label: Negative\n",
      "Probabilities: Positive - 0.3780, Negative - 0.6220\n",
      "==================================================\n",
      "Review 8:\n",
      "Text: 念願の大将のお席!カツオのたたきはこれまで食べた1番の美味しさ. 熟成されたねっとり感で, 旨みがギュッ!パサつき全く無い仕上がり. 優しい, 鮑, たこ, など, おつまみも最高!握りはふわっと優しいシャリとの一体感が素晴らしい. 最初のあたたかめのシャリと白身が新鮮で美味. 甘すぎないツメもよく, 蛤や穴子も, 素材の美味しさか際立つ！来年ですが, また, 次回も楽しみ！\n",
      "True Label: Positive\n",
      "Predicted Label: Negative\n",
      "Probabilities: Positive - 0.3692, Negative - 0.6308\n",
      "==================================================\n",
      "Review 9:\n",
      "Text: 日本の鮨店, 最高峰の1つ. 超予約困難店です. 1度訪れてみたかったお店ですが, 常連様にお誘い頂き, 伺うことができました. こちらのお店は・10年連続ミシュラン3つ星も会員制にするために返上・食べログGOLD(全国で30店舗ほどのみ)連続獲得・世界のグルメガイド, フランスの「ラ・リスト2024」で99.5点の日本最高評価を獲得. また, 世界でも上位7位. ・新規予約は基本受付しておらず, 食オクでのオークションのみ・食オクでは1席40万円や70万円の値がつくこともお店は六本木一丁目駅直結のアークヒルズタワー1階にあります. やや分かりづらい場所です. 店内は個室が2つあり, 個室内はL字のカウンター8席ほど. この日は, 2番手の沼尾大将の貸切会でした. お鮨はもちろんですが蒸し鮑と蛸の桜煮の旨味が凄く, 鰹の皮目がパリッとした火入れと最初のつまみがとても美味しく感動しました. つまみも握りもハイクオリティですが会話も楽しく雰囲気づくりも抜群. 価格は高いですが, 他のお鮨やさんと一線を画すほど美味しく満足度は高いです. 純粋に美味しくて, また来たいなぁと思える素晴らしいお鮨でした！ご馳走様でした！\n",
      "True Label: Positive\n",
      "Predicted Label: Negative\n",
      "Probabilities: Positive - 0.4028, Negative - 0.5972\n",
      "==================================================\n",
      "Review 10:\n",
      "Text: 日本最高峰のお鮨のお店に, 幸運にもお誘いいただき, 訪問することができました. この日は, 個室の沼尾大将に握っていただきました. 貸切ということもあり, リラックスして, 美味しいお酒を飲みながら, 最高のお鮨を食べて, 幸せな時間を過ごすことができました. ご馳走様でした！！！\n",
      "True Label: Positive\n",
      "Predicted Label: Negative\n",
      "Probabilities: Positive - 0.3710, Negative - 0.6290\n",
      "==================================================\n",
      "Review 11:\n",
      "Text: 食べログお鮨ランキング1位にしてミシュラン3つ星, 泣く子もだまるさいとう, 2月に続いて3月もさいとうさんへ, ミシュラン3つ星を取ったのは随分前だが最近になっても美味しさが増している気がする. \n",
      "True Label: Positive\n",
      "Predicted Label: Negative\n",
      "Probabilities: Positive - 0.3809, Negative - 0.6191\n",
      "==================================================\n",
      "Review 12:\n",
      "Text: 日本最高峰のお寿司と聞いていたのですが, お値段に比べてあまり美味しいと思いませんでした. \n",
      "True Label: Negative\n",
      "Predicted Label: Negative\n",
      "Probabilities: Positive - 0.3909, Negative - 0.6091\n",
      "==================================================\n",
      "Review 13:\n",
      "Text: イベントの際にお邪魔しました. 少し値段が高い気がします. \n",
      "True Label: Negative\n",
      "Predicted Label: Negative\n",
      "Probabilities: Positive - 0.4003, Negative - 0.5997\n",
      "==================================================\n",
      "Review 14:\n",
      "Text: イカやタコが美味しかったですが, マグロは微妙でした.\n",
      "True Label: Negative\n",
      "Predicted Label: Negative\n",
      "Probabilities: Positive - 0.4056, Negative - 0.5944\n",
      "==================================================\n",
      "Review 15:\n",
      "Text: お値段が高いので, もう少し美味しいものが食べたかったです.\n",
      "True Label: Negative\n",
      "Predicted Label: Negative\n",
      "Probabilities: Positive - 0.4012, Negative - 0.5988\n",
      "==================================================\n",
      "Review 16:\n",
      "Text: 雰囲気が少し怖く感じました.\n",
      "True Label: Negative\n",
      "Predicted Label: Negative\n",
      "Probabilities: Positive - 0.3968, Negative - 0.6032\n",
      "==================================================\n",
      "Review 17:\n",
      "Text: 味がイマイチだったので, また行くかは検討中です.\n",
      "True Label: Negative\n",
      "Predicted Label: Negative\n",
      "Probabilities: Positive - 0.4082, Negative - 0.5918\n",
      "==================================================\n",
      "Review 18:\n",
      "Text: お値段が高いので, 期待していたほど美味しくなかったです.\n",
      "True Label: Negative\n",
      "Predicted Label: Negative\n",
      "Probabilities: Positive - 0.4024, Negative - 0.5976\n",
      "==================================================\n",
      "Review 19:\n",
      "Text: 電話対応が悪かったので, また行くかは検討中です.\n",
      "True Label: Negative\n",
      "Predicted Label: Negative\n",
      "Probabilities: Positive - 0.3986, Negative - 0.6014\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/master/.pyenv/versions/3.12.2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/master/.pyenv/versions/3.12.2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/master/.pyenv/versions/3.12.2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# モデルの評価\n",
    "def evaluate_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    probabilities = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            input_ids = data['input_ids'].to(device)\n",
    "            attention_mask = data['attention_mask'].to(device)\n",
    "            labels = data['label'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            probs = torch.nn.functional.softmax(logits, dim=1)\n",
    "\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            predictions.extend(preds.cpu().numpy())  # CPUに移動してからnumpyに変換\n",
    "            true_labels.extend(labels.cpu().numpy())  # CPUに移動してからnumpyに変換\n",
    "            probabilities.extend(probs.cpu().numpy())  # CPUに移動してからnumpyに変換\n",
    "\n",
    "    return predictions, true_labels, probabilities\n",
    "\n",
    "# モデルの評価\n",
    "predictions, true_labels, probabilities = evaluate_model(model, data_loader, device)\n",
    "\n",
    "# 評価結果の表示\n",
    "accuracy = sum([1 if pred == true else 0 for pred, true in zip(predictions, true_labels)]) / len(true_labels)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(classification_report(true_labels, predictions, target_names=['Negative', 'Positive']))\n",
    "\n",
    "# 各データの予測結果を表示\n",
    "for i, (review, true_label, pred_label, prob) in enumerate(zip(reviews, true_labels, predictions, probabilities)):\n",
    "    print(f\"Review {i+1}:\")\n",
    "    print(f\"Text: {review}\")\n",
    "    print(f\"True Label: {'Positive' if true_label == 1 else 'Negative'}\")\n",
    "    print(f\"Predicted Label: {'Positive' if pred_label == 1 else 'Negative'}\")\n",
    "    print(f\"Probabilities: Positive - {prob[1]:.4f}, Negative - {prob[0]:.4f}\")\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/master/.pyenv/versions/3.12.2/lib/python3.12/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n",
      "Train loss 1.0304685235023499 accuracy 0.6666666865348816\n",
      "Val   loss 0.3965409994125366 accuracy 1.0\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n",
      "Train loss 0.40633469820022583 accuracy 0.8888888955116272\n",
      "Val   loss 0.3124300241470337 accuracy 1.0\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n",
      "Train loss 0.3297441452741623 accuracy 0.8888888955116272\n",
      "Val   loss 0.19672556221485138 accuracy 1.0\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n",
      "Train loss 0.27607132494449615 accuracy 0.8888888955116272\n",
      "Val   loss 0.11254560947418213 accuracy 1.0\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n",
      "Train loss 0.22440343722701073 accuracy 0.8888888955116272\n",
      "Val   loss 0.07830469310283661 accuracy 1.0\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n",
      "Train loss 1.4837076589465141 accuracy 0.8888888955116272\n",
      "Val   loss 0.07684759050607681 accuracy 1.0\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n",
      "Train loss 0.22204866632819176 accuracy 0.8888888955116272\n",
      "Val   loss 0.1286872774362564 accuracy 1.0\n",
      "\n",
      "Epoch 8/10\n",
      "----------\n",
      "Train loss 0.2333529144525528 accuracy 0.8888888955116272\n",
      "Val   loss 0.15087705850601196 accuracy 1.0\n",
      "\n",
      "Epoch 9/10\n",
      "----------\n",
      "Train loss 0.2332834228873253 accuracy 0.8888888955116272\n",
      "Val   loss 0.15156474709510803 accuracy 1.0\n",
      "\n",
      "Epoch 10/10\n",
      "----------\n",
      "Train loss 0.22650428861379623 accuracy 0.8888888955116272\n",
      "Val   loss 0.14722134172916412 accuracy 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# サンプルデータセットの作成（ポジティブ: 1, ネガティブ: 0）\n",
    "reviews = [\n",
    "    \"鮨 さいとうに4回目の訪問. 今回はランチでディナー同様, 摘みありのコースを注文させて頂きました. タイトルにもありますが, 気付けば2年ぶりの訪問. 食べ歩きをしてると2.3年再訪してないお店が沢山出てきますが, 再訪してもそれほど月日が経ってないように感じるのは私だけでしょうか. . 笑さて, 本題のお料理ですが, 摘み握り共に何を食べても美味しく, 今回も流石の安定感です. 何一つとして気になるものはありません. また, この日は以前よりずっと飲んでみたかった黒龍酒造の『ESHIKOTO』を頂きました. 超入手困難なスパークリングの日本酒です. 当たりがとてもドライで食事の邪魔を一切しないテイスト. 香りはほのかに日本酒を感じさせます. こんな貴重なお酒を入るのはさすが齋藤さんですね. 次回はいつ来れるか分かりませんが, またぜひ伺いたいです. ご馳走様でした. \",\n",
    "    \"個人的に, 都内では大好きなお店の一つ. 3度目の訪問ですが, さいとうさんは時期が変わっても毎度ツマミも握りも安定感があり素晴らしいですね. この日, 初めて頂く「穴子の白焼き」は今まで食べた事ないくらい身がぷりぷりしており, 特に印象深い一品でした. さらに1人30,000円ちょっとと, 内容対してコスパの高さも嬉しいですね. また, 昼でも夜でも時期を変えて伺いたいです. ご馳走様でした. \",\n",
    "    \"今月2度目のさいとうさんへ. 今回はランチ利用です. 握り15貫のみのコースを頂きました. （人によっては少し量が少なく感じる方もいらっしゃるかもしれません. ）マグロ中心に今回も大変美味しく頂きました. 価格も1人16,500円と, とても良心的な価格でびっくりしました. この立地でこの価格だと, そりゃ中々予約取れないわかです. また伺います. ご馳走様でした. \",\n",
    "    \"言わずと知れた4年連続食べログゴールド, 2019年まで10年連続ミシュラン3つ星のお店です. 今回はお誘い頂き訪問してきました. その人気ぶりから現在では, 完全会員制を取っており, 一見での予約は不可になっております. さて, お寿司に関しては非常に素晴らしいです. できることなら会員になって通い続けたいお店です. ネタもシャリもとても個人的に好みでした. 特にシャリは酢と塩味が強く無く, 割と万人受けするかな, といった印象. 次いついけるか分かりませんが, ぜひまた伺いたいです. ご馳走様でした. \",\n",
    "    \"楽しい時間を過ごす事が出来ました. また是非伺いたいと思います. ご馳走様でした. \",\n",
    "    \"今回は個室で『鮨さいとう』二番手の沼尾さんの鮨を堪能しました. 仕事も所作も丁寧で, 安心して食に集中出来ました. 酢飯の酸度・塩味・硬さ等かなり好み. ネタも間違いのないものばかりでした！ご馳走様でした. \",\n",
    "    \"最高峰と言われるお鮨屋さんお鮨だけを楽しみに行くのではなく, 大将との会話, 雰囲気, 異空間を味わいながら食べるお鮨屋さん. お鮨は美味しい. 特にこれがというのはないが, 美味しい. 1番驚いたのは鮨屋とは思えない独特な雰囲気があるお店. 大将とお客さんの一体感のある空間でお鮨を楽しめます. 大将の人柄で人気なっているお店. お鮨だけを食べに行くには勿体無いいいお鮨屋さんでした. さいとうさんのにぎるお鮨を食べられたことに感謝. \",\n",
    "    \"念願の大将のお席!カツオのたたきはこれまで食べた1番の美味しさ. 熟成されたねっとり感で, 旨みがギュッ!パサつき全く無い仕上がり. ￥優しい, 鮑, たこ, など, おつまみも最高!握りはふわっと優しいシャリとの一体感が素晴らしい. 最初のあたたかめのシャリと白身が新鮮で美味. 甘すぎないツメもよく, 蛤や穴子も, 素材の美味しさか際立つ！来年ですが, また, 次回も楽しみ！\",\n",
    "    \"日本の鮨店, 最高峰の1つ. 超予約困難店です. 1度訪れてみたかったお店ですが, 常連様にお誘い頂き, 伺うことができました. こちらのお店は・10年連続ミシュラン3つ星も会員制にするために返上・食べログGOLD(全国で30店舗ほどのみ)連続獲得・世界のグルメガイド, フランスの「ラ・リスト2024」で99.5点の日本最高評価を獲得. また, 世界でも上位7位. ・新規予約は基本受付しておらず, 食オクでのオークションのみ・食オクでは1席40万円や70万円の値がつくこともお店は六本木一丁目駅直結のアークヒルズタワー1階にあります. やや分かりづらい場所です. 店内は個室が2つあり, 個室内はL字のカウンター8席ほど. この日は, 2番手の沼尾大将の貸切会でした. お鮨はもちろんですが蒸し鮑と蛸の桜煮の旨味が凄く, 鰹の皮目がパリッとした火入れと最初のつまみがとても美味しく感動しました. つまみも握りもハイクオリティですが会話も楽しく雰囲気づくりも抜群. 価格は高いですが, 他のお鮨やさんと一線を画すほど美味しく満足度は高いです. 純粋に美味しくて, また来たいなぁと思える素晴らしいお鮨でした！ご馳走様でした！\",\n",
    "    \"日本最高峰のお鮨のお店に, 幸運にもお誘いいただき, 訪問することができました. この日は, 個室の沼尾大将に握っていただきました. 貸切ということもあり, リラックスして, 美味しいお酒を飲みながら, 最高のお鮨を食べて, 幸せな時間を過ごすことができました. ご馳走様でした！！！\",\n",
    "    \"食べログお鮨ランキング1位にしてミシュラン3つ星, 泣く子もだまるさいとう, 2月に続いて3月もさいとうさんへ, ミシュラン3つ星を取ったのは随分前だが最近になっても美味しさが増している気がする. \",\n",
    "    \"日本最高峰のお寿司と聞いていたのですが, お値段に比べてあまり美味しいと思いませんでした. \"\n",
    "]\n",
    "\n",
    "# ラベルの追加（ポジティブ: 1, ネガティブ: 0）\n",
    "labels = [1] * 11 + [0]\n",
    "\n",
    "# データフレームの作成\n",
    "df = pd.DataFrame({'text': reviews, 'label': labels})\n",
    "\n",
    "# データの分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# トークナイザーの初期化\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# データセットの作成\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, reviews, labels, tokenizer, max_len):\n",
    "        self.reviews = reviews\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        review = str(self.reviews[item])\n",
    "        label = self.labels[item]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            review,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'review_text': review,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# トレーニングと検証のデータセット\n",
    "train_dataset = ReviewDataset(\n",
    "    reviews=train_df.text.to_numpy(),\n",
    "    labels=train_df.label.to_numpy(),\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=500\n",
    ")\n",
    "\n",
    "val_dataset = ReviewDataset(\n",
    "    reviews=val_df.text.to_numpy(),\n",
    "    labels=val_df.label.to_numpy(),\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=500\n",
    ")\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_data_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# モデルのファインチューニング\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "def train_epoch(\n",
    "  model, \n",
    "  data_loader, \n",
    "  loss_fn, \n",
    "  optimizer, \n",
    "  device, \n",
    "  scheduler, \n",
    "  n_examples\n",
    "):\n",
    "    model = model.train()\n",
    "\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for data in data_loader:\n",
    "        input_ids = data['input_ids'].to(device)\n",
    "        attention_mask = data['attention_mask'].to(device)\n",
    "        labels = data['label'].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "\n",
    "        _, preds = torch.max(outputs.logits, dim=1)\n",
    "        loss = loss_fn(outputs.logits, labels)\n",
    "\n",
    "        correct_predictions += torch.sum(preds == labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return correct_predictions.float() / n_examples, np.mean(losses)\n",
    "\n",
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "    model = model.eval()\n",
    "\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            input_ids = data['input_ids'].to(device)\n",
    "            attention_mask = data['attention_mask'].to(device)\n",
    "            labels = data['label'].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "\n",
    "            _, preds = torch.max(outputs.logits, dim=1)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    return correct_predictions.float() / n_examples, np.mean(losses)\n",
    "\n",
    "# モデルの初期化\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "model = model.to(device)\n",
    "\n",
    "EPOCHS = 10\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "# トレーニングループ\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    train_acc, train_loss = train_epoch(\n",
    "        model,\n",
    "        train_data_loader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        device,\n",
    "        scheduler,\n",
    "        len(train_df)\n",
    "    )\n",
    "\n",
    "    print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "    val_acc, val_loss = eval_model(\n",
    "        model,\n",
    "        val_data_loader,\n",
    "        loss_fn,\n",
    "        device,\n",
    "        len(val_df)\n",
    "    )\n",
    "\n",
    "    print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
