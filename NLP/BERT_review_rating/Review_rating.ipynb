{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/master/.pyenv/versions/3.12.2/lib/python3.12/site-packages (4.42.3)\n",
      "Requirement already satisfied: filelock in /Users/master/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from transformers) (3.15.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /Users/master/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in /Users/master/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/master/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/master/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/master/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /Users/master/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/master/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/master/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/master/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/master/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/master/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/master/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/master/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/master/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/master/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from requests->transformers) (2024.6.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import classification_report\n",
    "# from transformers.tokenization_bert_japanese import BertJapaneseTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `torch`: PyTorchライブラリをインポートします. これは, 深層学習モデルを構築するための主要なライブラリです. \n",
    "- `transformers`: Transformerライブラリをインポートします. このライブラリは, BERTやGPT-2などの最先端自然言語処理モデルを簡単に利用できるようにします. \n",
    "- `AdamW`: AdamWオプティマイザをインポートします. これは, 深層学習モデルの訓練に使用される手法です. \n",
    "- `get_linear_schedule_with_warmup`: 学習率を徐々に上げていくスケジュールを取得するための関数をインポートします. \n",
    "- `DataLoader`: PyTorch DataLoaderをインポートします. これは, データセットを効率的に読み込むためのツールです. \n",
    "- `Dataset`: PyTorch Datasetクラスをインポートします. これは, カスタムデータセットを作成するための基底クラスです. \n",
    "- `pandas`: データ分析ライブラリであるpandasをインポートします. \n",
    "- `re`: 正規表現ライブラリであるreをインポートします. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 口コミデータ\n",
    "reviews = [\n",
    "    \"鮨 さいとうに4回目の訪問. 今回はランチでディナー同様, 摘みありのコースを注文させて頂きました. タイトルにもありますが, 気付けば2年ぶりの訪問. 食べ歩きをしてると2.3年再訪してないお店が沢山出てきますが, 再訪してもそれほど月日が経ってないように感じるのは私だけでしょうか. . 笑さて, 本題のお料理ですが, 摘み握り共に何を食べても美味しく, 今回も流石の安定感です. 何一つとして気になるものはありません. また, この日は以前よりずっと飲んでみたかった黒龍酒造の『ESHIKOTO』を頂きました. 超入手困難なスパークリングの日本酒です. 当たりがとてもドライで食事の邪魔を一切しないテイスト. 香りはほのかに日本酒を感じさせます. こんな貴重なお酒を入るのはさすが齋藤さんですね. 次回はいつ来れるか分かりませんが, またぜひ伺いたいです. ご馳走様でした. \",\n",
    "    \"個人的に, 都内では大好きなお店の一つ. 3度目の訪問ですが, さいとうさんは時期が変わっても毎度ツマミも握りも安定感があり素晴らしいですね. この日, 初めて頂く「穴子の白焼き」は今まで食べた事ないくらい身がぷりぷりしており, 特に印象深い一品でした. さらに1人30,000円ちょっとと, 内容対してコスパの高さも嬉しいですね. また, 昼でも夜でも時期を変えて伺いたいです. ご馳走様でした. \",\n",
    "    \"今月2度目のさいとうさんへ. 今回はランチ利用です. 握り15貫のみのコースを頂きました. （人によっては少し量が少なく感じる方もいらっしゃるかもしれません. ）マグロ中心に今回も大変美味しく頂きました. 価格も1人16,500円と, とても良心的な価格でびっくりしました. この立地でこの価格だと, そりゃ中々予約取れないわかです. また伺います. ご馳走様でした. \",\n",
    "    \"言わずと知れた4年連続食べログゴールド, 2019年まで10年連続ミシュラン3つ星のお店です. 今回はお誘い頂き訪問してきました. その人気ぶりから現在では, 完全会員制を取っており, 一見での予約は不可になっております. さて, お寿司に関しては非常に素晴らしいです. できることなら会員になって通い続けたいお店です. ネタもシャリもとても個人的に好みでした. 特にシャリは酢と塩味が強く無く, 割と万人受けするかな, といった印象. 次いついけるか分かりませんが, ぜひまた伺いたいです. ご馳走様でした. \",\n",
    "    \"楽しい時間を過ごす事が出来ました. また是非伺いたいと思います. ご馳走様でした. \",\n",
    "    \"今回は個室で『鮨さいとう』二番手の沼尾さんの鮨を堪能しました. 仕事も所作も丁寧で, 安心して食に集中出来ました. 酢飯の酸度・塩味・硬さ等かなり好み. ネタも間違いのないものばかりでした！ご馳走様でした. \",\n",
    "    \"最高峰と言われるお鮨屋さんお鮨だけを楽しみに行くのではなく, 大将との会話, 雰囲気, 異空間を味わいながら食べるお鮨屋さん. お鮨は美味しい. 特にこれがというのはないが, 美味しい. 1番驚いたのは鮨屋とは思えない独特な雰囲気があるお店. 大将とお客さんの一体感のある空間でお鮨を楽しめます. 大将の人柄で人気なっているお店. お鮨だけを食べに行くには勿体無いいいお鮨屋さんでした. さいとうさんのにぎるお鮨を食べられたことに感謝. \",\n",
    "    \"念願の大将のお席!カツオのたたきはこれまで食べた1番の美味しさ. 熟成されたねっとり感で, 旨みがギュッ!パサつき全く無い仕上がり. 優しい, 鮑, たこ, など, おつまみも最高!握りはふわっと優しいシャリとの一体感が素晴らしい. 最初のあたたかめのシャリと白身が新鮮で美味. 甘すぎないツメもよく, 蛤や穴子も, 素材の美味しさか際立つ！来年ですが, また, 次回も楽しみ！\",\n",
    "    \"日本の鮨店, 最高峰の1つ. 超予約困難店です. 1度訪れてみたかったお店ですが, 常連様にお誘い頂き, 伺うことができました. こちらのお店は・10年連続ミシュラン3つ星も会員制にするために返上・食べログGOLD(全国で30店舗ほどのみ)連続獲得・世界のグルメガイド, フランスの「ラ・リスト2024」で99.5点の日本最高評価を獲得. また, 世界でも上位7位. ・新規予約は基本受付しておらず, 食オクでのオークションのみ・食オクでは1席40万円や70万円の値がつくこともお店は六本木一丁目駅直結のアークヒルズタワー1階にあります. やや分かりづらい場所です. 店内は個室が2つあり, 個室内はL字のカウンター8席ほど. この日は, 2番手の沼尾大将の貸切会でした. お鮨はもちろんですが蒸し鮑と蛸の桜煮の旨味が凄く, 鰹の皮目がパリッとした火入れと最初のつまみがとても美味しく感動しました. つまみも握りもハイクオリティですが会話も楽しく雰囲気づくりも抜群. 価格は高いですが, 他のお鮨やさんと一線を画すほど美味しく満足度は高いです. 純粋に美味しくて, また来たいなぁと思える素晴らしいお鮨でした！ご馳走様でした！\",\n",
    "    \"日本最高峰のお鮨のお店に, 幸運にもお誘いいただき, 訪問することができました. この日は, 個室の沼尾大将に握っていただきました. 貸切ということもあり, リラックスして, 美味しいお酒を飲みながら, 最高のお鮨を食べて, 幸せな時間を過ごすことができました. ご馳走様でした！！！\",\n",
    "    \"食べログお鮨ランキング1位にしてミシュラン3つ星, 泣く子もだまるさいとう, 2月に続いて3月もさいとうさんへ, ミシュラン3つ星を取ったのは随分前だが最近になっても美味しさが増している気がする. \",\n",
    "    \"日本最高峰のお寿司と聞いていたのですが, お値段に比べてあまり美味しいと思いませんでした. \",\n",
    "    \"イベントの際にお邪魔しました. 少し値段が高い気がします. \",\n",
    "    \"イカやタコが美味しかったですが, マグロは微妙でした.\",\n",
    "    \"お値段が高いので, もう少し美味しいものが食べたかったです.\",\n",
    "    \"雰囲気が少し怖く感じました.\",\n",
    "    \"味がイマイチだったので, また行くかは検討中です.\",\n",
    "    \"お値段が高いので, 期待していたほど美味しくなかったです.\",\n",
    "    \"電話対応が悪かったので, また行くかは検討中です.\",\n",
    "]\n",
    "\n",
    "# 感情ラベルの追加（手動で設定, ここでは全てポジティブと仮定）\n",
    "# labels = [1] * len(reviews)\n",
    "\n",
    "\n",
    "# 感情ラベルの追加（ポジティブ: 1, ネガティブ: 0）\n",
    "labels = [1] * 11 + [0] * 8\n",
    "\n",
    "output_dir = 'text'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "for i, (review, label) in enumerate(zip(reviews, labels)):\n",
    "    df = pd.DataFrame({'text': [review], 'label': [label]})\n",
    "    df.to_csv(os.path.join(output_dir, f'review_{i}.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. 口コミデータの準備**\n",
    "\n",
    "```python\n",
    "reviews = [\n",
    "    \"鮨 さいとうに4回目の訪問. 今回はランチでディナー同様, 摘みありのコースを注文させて頂きました. タイトルにもありますが, 気付けば2年ぶりの訪問. 食べ歩きをしてると2.3年再訪してないお店が沢山出てきますが, 再訪してもそれほど月日が経ってないように感じるのは私だけでしょうか. . 笑さて, 本題のお料理ですが, 摘み握り共に何を食べても美味しく, 今回も流石の安定感です. 何一つとして気になるものはありません. また, この日は以前よりずっと飲んでみたかった黒龍酒造の『ESHIKOTO』を頂きました. 超入手困難なスパークリングの日本酒です. 当たりがとてもドライで食事の邪魔を一切しないテイスト. 香りはほのかに日本酒を感じさせます. こんな貴重なお酒を入るのはさすが齋藤さんですね. 次回はいつ来れるか分かりませんが, またぜひ伺いたいです. ご馳走様でした. \",\n",
    "    # ... (9件の口コミデータ省略)\n",
    "]\n",
    "\n",
    "labels = [1] * len(reviews)\n",
    "```\n",
    "\n",
    "- `reviews`: リスト形式で, 12個の「鮨 さいとう」の口コミデータが格納されています. \n",
    "- `labels`: 各口コミデータに対応する感情ラベルをリスト形式で格納しています. **ここでは全て1（ポジティブ）に設定**されています. \n",
    "\n",
    "**2. 個別のCSVファイルへの保存**\n",
    "\n",
    "```python\n",
    "for i, (review, label) in enumerate(zip(reviews, labels)):\n",
    "    df = pd.DataFrame({'text': [review], 'label': [label]})\n",
    "    df.to_csv(f'review_{i}.csv', index=False)\n",
    "```\n",
    "\n",
    "- 上記の口コミデータと感情ラベルを, `review_0.csv`, `review_1.csv` ... のように個別のCSVファイルに保存します. \n",
    "    - `pd.DataFrame`: 口コミデータと感情ラベルをDataFrameに変換します. \n",
    "    - `to_csv`: DataFrameをCSVファイルに出力します. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_973d8_row0_col0, #T_973d8_row0_col1, #T_973d8_row1_col0, #T_973d8_row1_col1, #T_973d8_row2_col0, #T_973d8_row2_col1, #T_973d8_row3_col0, #T_973d8_row3_col1, #T_973d8_row4_col0, #T_973d8_row4_col1, #T_973d8_row5_col0, #T_973d8_row5_col1, #T_973d8_row6_col0, #T_973d8_row6_col1, #T_973d8_row7_col0, #T_973d8_row7_col1, #T_973d8_row8_col0, #T_973d8_row8_col1, #T_973d8_row9_col0, #T_973d8_row9_col1, #T_973d8_row10_col0, #T_973d8_row10_col1, #T_973d8_row11_col0, #T_973d8_row11_col1, #T_973d8_row12_col0, #T_973d8_row12_col1, #T_973d8_row13_col0, #T_973d8_row13_col1, #T_973d8_row14_col0, #T_973d8_row14_col1, #T_973d8_row15_col0, #T_973d8_row15_col1, #T_973d8_row16_col0, #T_973d8_row16_col1, #T_973d8_row17_col0, #T_973d8_row17_col1, #T_973d8_row18_col0, #T_973d8_row18_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_973d8\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_973d8_level0_col0\" class=\"col_heading level0 col0\" >口コミ内容</th>\n",
       "      <th id=\"T_973d8_level0_col1\" class=\"col_heading level0 col1\" >評価</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_973d8_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_973d8_row0_col0\" class=\"data row0 col0\" >鮨 さいとうに4回目の訪問. 今回はランチでディナー同様, 摘みありのコースを注文させて頂きました. タイトルにもありますが, 気付けば2年ぶりの訪問. 食べ歩きをしてると2.3年再訪してないお店が沢山出てきますが, 再訪してもそれほど月日が経ってないように感じるのは私だけでしょうか. . 笑さて, 本題のお料理ですが, 摘み握り共に何を食べても美味しく, 今回も流石の安定感です. 何一つとして気になるものはありません. また, この日は以前よりずっと飲んでみたかった黒龍酒造の『ESHIKOTO』を頂きました. 超入手困難なスパークリングの日本酒です. 当たりがとてもドライで食事の邪魔を一切しないテイスト. 香りはほのかに日本酒を感じさせます. こんな貴重なお酒を入るのはさすが齋藤さんですね. 次回はいつ来れるか分かりませんが, またぜひ伺いたいです. ご馳走様でした. </td>\n",
       "      <td id=\"T_973d8_row0_col1\" class=\"data row0 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_973d8_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_973d8_row1_col0\" class=\"data row1 col0\" >個人的に, 都内では大好きなお店の一つ. 3度目の訪問ですが, さいとうさんは時期が変わっても毎度ツマミも握りも安定感があり素晴らしいですね. この日, 初めて頂く「穴子の白焼き」は今まで食べた事ないくらい身がぷりぷりしており, 特に印象深い一品でした. さらに1人30,000円ちょっとと, 内容対してコスパの高さも嬉しいですね. また, 昼でも夜でも時期を変えて伺いたいです. ご馳走様でした. </td>\n",
       "      <td id=\"T_973d8_row1_col1\" class=\"data row1 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_973d8_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_973d8_row2_col0\" class=\"data row2 col0\" >今月2度目のさいとうさんへ. 今回はランチ利用です. 握り15貫のみのコースを頂きました. （人によっては少し量が少なく感じる方もいらっしゃるかもしれません. ）マグロ中心に今回も大変美味しく頂きました. 価格も1人16,500円と, とても良心的な価格でびっくりしました. この立地でこの価格だと, そりゃ中々予約取れないわかです. また伺います. ご馳走様でした. </td>\n",
       "      <td id=\"T_973d8_row2_col1\" class=\"data row2 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_973d8_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_973d8_row3_col0\" class=\"data row3 col0\" >言わずと知れた4年連続食べログゴールド, 2019年まで10年連続ミシュラン3つ星のお店です. 今回はお誘い頂き訪問してきました. その人気ぶりから現在では, 完全会員制を取っており, 一見での予約は不可になっております. さて, お寿司に関しては非常に素晴らしいです. できることなら会員になって通い続けたいお店です. ネタもシャリもとても個人的に好みでした. 特にシャリは酢と塩味が強く無く, 割と万人受けするかな, といった印象. 次いついけるか分かりませんが, ぜひまた伺いたいです. ご馳走様でした. </td>\n",
       "      <td id=\"T_973d8_row3_col1\" class=\"data row3 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_973d8_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_973d8_row4_col0\" class=\"data row4 col0\" >楽しい時間を過ごす事が出来ました. また是非伺いたいと思います. ご馳走様でした. </td>\n",
       "      <td id=\"T_973d8_row4_col1\" class=\"data row4 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_973d8_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_973d8_row5_col0\" class=\"data row5 col0\" >今回は個室で『鮨さいとう』二番手の沼尾さんの鮨を堪能しました. 仕事も所作も丁寧で, 安心して食に集中出来ました. 酢飯の酸度・塩味・硬さ等かなり好み. ネタも間違いのないものばかりでした！ご馳走様でした. </td>\n",
       "      <td id=\"T_973d8_row5_col1\" class=\"data row5 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_973d8_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_973d8_row6_col0\" class=\"data row6 col0\" >最高峰と言われるお鮨屋さんお鮨だけを楽しみに行くのではなく, 大将との会話, 雰囲気, 異空間を味わいながら食べるお鮨屋さん. お鮨は美味しい. 特にこれがというのはないが, 美味しい. 1番驚いたのは鮨屋とは思えない独特な雰囲気があるお店. 大将とお客さんの一体感のある空間でお鮨を楽しめます. 大将の人柄で人気なっているお店. お鮨だけを食べに行くには勿体無いいいお鮨屋さんでした. さいとうさんのにぎるお鮨を食べられたことに感謝. </td>\n",
       "      <td id=\"T_973d8_row6_col1\" class=\"data row6 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_973d8_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_973d8_row7_col0\" class=\"data row7 col0\" >念願の大将のお席!カツオのたたきはこれまで食べた1番の美味しさ. 熟成されたねっとり感で, 旨みがギュッ!パサつき全く無い仕上がり. 優しい, 鮑, たこ, など, おつまみも最高!握りはふわっと優しいシャリとの一体感が素晴らしい. 最初のあたたかめのシャリと白身が新鮮で美味. 甘すぎないツメもよく, 蛤や穴子も, 素材の美味しさか際立つ！来年ですが, また, 次回も楽しみ！</td>\n",
       "      <td id=\"T_973d8_row7_col1\" class=\"data row7 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_973d8_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_973d8_row8_col0\" class=\"data row8 col0\" >日本の鮨店, 最高峰の1つ. 超予約困難店です. 1度訪れてみたかったお店ですが, 常連様にお誘い頂き, 伺うことができました. こちらのお店は・10年連続ミシュラン3つ星も会員制にするために返上・食べログGOLD(全国で30店舗ほどのみ)連続獲得・世界のグルメガイド, フランスの「ラ・リスト2024」で99.5点の日本最高評価を獲得. また, 世界でも上位7位. ・新規予約は基本受付しておらず, 食オクでのオークションのみ・食オクでは1席40万円や70万円の値がつくこともお店は六本木一丁目駅直結のアークヒルズタワー1階にあります. やや分かりづらい場所です. 店内は個室が2つあり, 個室内はL字のカウンター8席ほど. この日は, 2番手の沼尾大将の貸切会でした. お鮨はもちろんですが蒸し鮑と蛸の桜煮の旨味が凄く, 鰹の皮目がパリッとした火入れと最初のつまみがとても美味しく感動しました. つまみも握りもハイクオリティですが会話も楽しく雰囲気づくりも抜群. 価格は高いですが, 他のお鮨やさんと一線を画すほど美味しく満足度は高いです. 純粋に美味しくて, また来たいなぁと思える素晴らしいお鮨でした！ご馳走様でした！</td>\n",
       "      <td id=\"T_973d8_row8_col1\" class=\"data row8 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_973d8_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_973d8_row9_col0\" class=\"data row9 col0\" >日本最高峰のお鮨のお店に, 幸運にもお誘いいただき, 訪問することができました. この日は, 個室の沼尾大将に握っていただきました. 貸切ということもあり, リラックスして, 美味しいお酒を飲みながら, 最高のお鮨を食べて, 幸せな時間を過ごすことができました. ご馳走様でした！！！</td>\n",
       "      <td id=\"T_973d8_row9_col1\" class=\"data row9 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_973d8_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_973d8_row10_col0\" class=\"data row10 col0\" >食べログお鮨ランキング1位にしてミシュラン3つ星, 泣く子もだまるさいとう, 2月に続いて3月もさいとうさんへ, ミシュラン3つ星を取ったのは随分前だが最近になっても美味しさが増している気がする. </td>\n",
       "      <td id=\"T_973d8_row10_col1\" class=\"data row10 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_973d8_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_973d8_row11_col0\" class=\"data row11 col0\" >日本最高峰のお寿司と聞いていたのですが, お値段に比べてあまり美味しいと思いませんでした. </td>\n",
       "      <td id=\"T_973d8_row11_col1\" class=\"data row11 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_973d8_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_973d8_row12_col0\" class=\"data row12 col0\" >イベントの際にお邪魔しました. 少し値段が高い気がします. </td>\n",
       "      <td id=\"T_973d8_row12_col1\" class=\"data row12 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_973d8_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_973d8_row13_col0\" class=\"data row13 col0\" >イカやタコが美味しかったですが, マグロは微妙でした.</td>\n",
       "      <td id=\"T_973d8_row13_col1\" class=\"data row13 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_973d8_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_973d8_row14_col0\" class=\"data row14 col0\" >お値段が高いので, もう少し美味しいものが食べたかったです.</td>\n",
       "      <td id=\"T_973d8_row14_col1\" class=\"data row14 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_973d8_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_973d8_row15_col0\" class=\"data row15 col0\" >雰囲気が少し怖く感じました.</td>\n",
       "      <td id=\"T_973d8_row15_col1\" class=\"data row15 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_973d8_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_973d8_row16_col0\" class=\"data row16 col0\" >味がイマイチだったので, また行くかは検討中です.</td>\n",
       "      <td id=\"T_973d8_row16_col1\" class=\"data row16 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_973d8_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_973d8_row17_col0\" class=\"data row17 col0\" >お値段が高いので, 期待していたほど美味しくなかったです.</td>\n",
       "      <td id=\"T_973d8_row17_col1\" class=\"data row17 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_973d8_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_973d8_row18_col0\" class=\"data row18 col0\" >電話対応が悪かったので, また行くかは検討中です.</td>\n",
       "      <td id=\"T_973d8_row18_col1\" class=\"data row18 col1\" >0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x168d01b80>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データフレームの作成\n",
    "all_data = pd.DataFrame({'text': reviews, 'label': labels})\n",
    "\n",
    "# 列名の変更\n",
    "all_data.rename(columns={'text': '口コミ内容', 'label': '評価'}, inplace=True)\n",
    "\n",
    "# インデックスを列に格納\n",
    "all_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# フレーム作成\n",
    "frame = all_data\n",
    "\n",
    "# 左揃え設定\n",
    "frame.style.set_properties(**{'text-align': 'left'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. データフレームの作成**\n",
    "\n",
    "```python\n",
    "all_data = pd.DataFrame({'text': reviews, 'label': labels})\n",
    "```\n",
    "\n",
    "- `pd.DataFrame`: リスト形式で格納された口コミデータ (`reviews`) と感情ラベル (`labels`) を, PandasのDataFrame形式に変換します. \n",
    "- `'text'`: 口コミ内容を格納する列を `'text'` と命名します. \n",
    "- `'label'`: 感情ラベルを格納する列を `'評価'` と命名します. \n",
    "\n",
    "**2. 列名の変更**\n",
    "\n",
    "```python\n",
    "all_data.rename(columns={'text': '口コミ内容', 'label': '評価'}, inplace=True)\n",
    "```\n",
    "\n",
    "- `rename(columns=...)`: 列名を変更します. \n",
    "    - `'text'`: 元の列名\n",
    "    - `'口コミ内容'`: 変更後の列名\n",
    "    - `inplace=True`: 変更を元のDataFrameに反映します. \n",
    "- 同様に, `'label'` 列名を `'評価'` に変更します. \n",
    "\n",
    "**3. インデックスを列に格納**\n",
    "\n",
    "```python\n",
    "all_data.reset_index(drop=True, inplace=True)\n",
    "```\n",
    "\n",
    "- `reset_index`: DataFrameの行インデックスを列として追加します. \n",
    "    - `drop=True`: 元の行インデックスを削除します. \n",
    "    - `inplace=True`: 変更を元のDataFrameに反映します. \n",
    "\n",
    "**4. フレーム作成**\n",
    "\n",
    "```python\n",
    "frame = all_data\n",
    "```\n",
    "\n",
    "- `frame = all_data`: 上記で加工したDataFrameを `frame` という変数に格納します. \n",
    "\n",
    "**5. 左揃え設定**\n",
    "\n",
    "```python\n",
    "frame.style.set_properties(**{'text-align': 'left'})\n",
    "```\n",
    "\n",
    "- `style.set_properties`: DataFrameの表示形式を設定します. \n",
    "    - `**{...}``: 辞書形式で, 設定したいプロパティとその値を指定します. \n",
    "    - `'text-align': 'left'`: '口コミ内容' 列の文字列を左揃えに設定します. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの作成\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, reviews, labels, tokenizer, max_len):\n",
    "        self.reviews = reviews\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        review = str(self.reviews[item])\n",
    "        label = self.labels[item]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            review,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'review_text': review,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. クラスの定義**\n",
    "\n",
    "```python\n",
    "class ReviewDataset(Dataset):\n",
    "```\n",
    "\n",
    "- `class ReviewDataset(Dataset)`: `Dataset` クラスを継承した `ReviewDataset` クラスを定義します. \n",
    "- `Dataset` クラスは, PyTorchでデータローダーと連携してデータ処理を行うための基底クラスです. \n",
    "\n",
    "**2. コンストラクタ (`__init__`)**\n",
    "\n",
    "```python\n",
    "def __init__(self, reviews, labels, tokenizer, max_len):\n",
    "    self.reviews = reviews\n",
    "    self.labels = labels\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_len = max_len\n",
    "```\n",
    "\n",
    "- `__init__(self, reviews, labels, tokenizer, max_len)`: コンストラクタは, データセットを作成する際に呼び出されるメソッドです. \n",
    "    - `reviews`: 口コミデータのリスト\n",
    "    - `labels`: 感情ラベルのリスト\n",
    "    - `tokenizer`: Transformerライブラリのトークナイザ\n",
    "    - `max_len`: 最大トークン長\n",
    "- 上記の引数を, クラスのインスタンス変数として保持します. \n",
    "\n",
    "**3. データ件数取得 (`__len__`)**\n",
    "\n",
    "```python\n",
    "def __len__(self):\n",
    "    return len(self.reviews)\n",
    "```\n",
    "\n",
    "- `__len__(self)`: データセットに含まれるデータ件数を返します. \n",
    "- `len(self.reviews)`: `reviews` リストの長さを返します. \n",
    "\n",
    "**4. データ取得 (`__getitem__`)**\n",
    "\n",
    "```python\n",
    "def __getitem__(self, item):\n",
    "    review = str(self.reviews[item])\n",
    "    label = self.labels[item]\n",
    "\n",
    "    encoding = self.tokenizer.encode_plus(\n",
    "        review,\n",
    "        add_special_tokens=True,\n",
    "        max_length=self.max_len,\n",
    "        return_token_type_ids=False,\n",
    "        padding='max_length',\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt',\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'review_text': review,\n",
    "        'input_ids': encoding['input_ids'].flatten(),\n",
    "        'attention_mask': encoding['attention_mask'].flatten(),\n",
    "        'label': torch.tensor(label, dtype=torch.long)\n",
    "    }\n",
    "```\n",
    "\n",
    "- `__getitem__(self, item)`: 特定のインデックス `item` に対応するデータを返します. \n",
    "    - `review`: `reviews` リストから `item` 番目の口コミデータを取得します. \n",
    "    - `label`: `labels` リストから `item` 番目の感情ラベルを取得します. \n",
    "    - `tokenizer.encode_plus`: Transformerライブラリの `encode_plus` 関数を使って, 口コミデータをモデルに入力できる形式に変換します. \n",
    "        - `review`: 変換する口コミデータ\n",
    "        - `add_special_tokens=True`: 特別トークンを追加します. \n",
    "        - `max_length=self.max_len`: 最大トークン長を `self.max_len` に設定します. \n",
    "        - `return_token_type_ids=False`: トークンタイプIDを返しません. \n",
    "        - `padding='max_length'`: 最大トークン長までパディングを行います. \n",
    "        - `return_attention_mask=True`: アテンションマスクを返します. \n",
    "        - `return_tensors='pt'`: PyTorchテンソルとして返します. \n",
    "    - 変換されたデータと感情ラベルを辞書形式でまとめ, 返します. \n",
    "        - `'review_text'`: 変換前の口コミデータ\n",
    "        - `'input_ids'`: トークンIDのテンソル\n",
    "        - `'attention_mask'`: アテンションマスクのテンソル\n",
    "        - `'label'`: 感情ラベルのテンソル（long型）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込みと前処理\n",
    "def load_and_preprocess_data(filepaths):\n",
    "    reviews = []\n",
    "    labels = []\n",
    "    \n",
    "    for filepath in filepaths:\n",
    "        df = pd.read_csv(filepath)\n",
    "        reviews.extend(df['text'].tolist())\n",
    "        labels.extend(df['label'].tolist())\n",
    "\n",
    "    return reviews, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. 関数定義**\n",
    "\n",
    "```python\n",
    "def load_and_preprocess_data(filepaths):\n",
    "    reviews = []\n",
    "    labels = []\n",
    "    \n",
    "    for filepath in filepaths:\n",
    "        df = pd.read_csv(filepath)\n",
    "        reviews.extend(df['text'].tolist())\n",
    "        labels.extend(df['label'].tolist())\n",
    "\n",
    "    return reviews, labels\n",
    "```\n",
    "\n",
    "- `def load_and_preprocess_data(filepaths)`: 関数名を `load_and_preprocess_data` と定義し, 引数として `filepaths` を受け取ります. \n",
    "    - `filepaths`: 読み込むCSVファイルのパスをリスト形式で渡します. \n",
    "\n",
    "**2. データ読み込み**\n",
    "\n",
    "```python\n",
    "for filepath in filepaths:\n",
    "    df = pd.read_csv(filepath)\n",
    "    reviews.extend(df['text'].tolist())\n",
    "    labels.extend(df['label'].tolist())\n",
    "```\n",
    "\n",
    "- `for filepath in filepaths`: `filepaths` リスト内の各ファイルパスに対して処理を繰り返します. \n",
    "- `df = pd.read_csv(filepath)`: 指定されたファイルパスからCSVデータを読み込み, DataFrame形式に変換します. \n",
    "- `reviews.extend(df['text'].tolist())`: DataFrameの `'text'` 列の値をすべてリスト `reviews` に追加します. \n",
    "- `labels.extend(df['label'].tolist())`: DataFrameの `'label'` 列の値をすべてリスト `labels` に追加します. \n",
    "\n",
    "**3. 処理結果の返却**\n",
    "\n",
    "```python\n",
    "return reviews, labels\n",
    "```\n",
    "\n",
    "- 処理が完了したら, `reviews` と `labels` のリストをタプル形式で返します. \n",
    "\n",
    "**この関数を実行すると**\n",
    "\n",
    "- `filepaths` で指定されたCSVファイルから口コミデータと感情ラベルが読み込まれ, リスト形式で返されます. \n",
    "- 返されたリストは, Transformerライブラリのデータセット作成などに利用できます. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "cl-tohoku/bert-japanese-whole-word-masking is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/huggingface_hub/utils/_errors.py:304\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/cl-tohoku/bert-japanese-whole-word-masking/resolve/main/tokenizer_config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/transformers/utils/hub.py:402\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 402\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/huggingface_hub/file_download.py:1221\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, legacy_cache_layout, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[1;32m   1223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[1;32m   1225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1229\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[1;32m   1230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1232\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1234\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[1;32m   1235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1237\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/huggingface_hub/file_download.py:1325\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, headers, proxies, etag_timeout, endpoint, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1324\u001b[0m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[43m_raise_on_head_call_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_call_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/huggingface_hub/file_download.py:1823\u001b[0m, in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1821\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, RepositoryNotFoundError) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, GatedRepoError):\n\u001b[1;32m   1822\u001b[0m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[0;32m-> 1823\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[1;32m   1824\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1825\u001b[0m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/huggingface_hub/file_download.py:1722\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1721\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1722\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1723\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/huggingface_hub/file_download.py:1645\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1644\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[0;32m-> 1645\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1647\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1648\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1651\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1652\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1653\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1654\u001b[0m hf_raise_for_status(r)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/huggingface_hub/file_download.py:372\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[0;32m--> 372\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/huggingface_hub/file_download.py:396\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    395\u001b[0m response \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/huggingface_hub/utils/_errors.py:352\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    344\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    345\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    346\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m make sure you are authenticated.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    351\u001b[0m     )\n\u001b[0;32m--> 352\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RepositoryNotFoundError(message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n",
      "\u001b[0;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-66960f02-0c0f63ea50c9584e1f3b5816;a19407b5-04e2-42cf-b4a2-d96713562fdf)\n\nRepository Not Found for url: https://huggingface.co/cl-tohoku/bert-japanese-whole-word-masking/resolve/main/tokenizer_config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m reviews, labels \u001b[38;5;241m=\u001b[39m load_and_preprocess_data(filepaths)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# トークナイザーの初期化\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mBertTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcl-tohoku/bert-japanese-whole-word-masking\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# データセットの作成\u001b[39;00m\n\u001b[1;32m     11\u001b[0m dataset \u001b[38;5;241m=\u001b[39m ReviewDataset(reviews, labels, tokenizer, max_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2082\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2079\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizer_file\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m vocab_files:\n\u001b[1;32m   2080\u001b[0m     \u001b[38;5;66;03m# Try to get the tokenizer config to see if there are versioned tokenizer files.\u001b[39;00m\n\u001b[1;32m   2081\u001b[0m     fast_tokenizer_file \u001b[38;5;241m=\u001b[39m FULL_TOKENIZER_FILE\n\u001b[0;32m-> 2082\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2083\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2084\u001b[0m \u001b[43m        \u001b[49m\u001b[43mTOKENIZER_CONFIG_FILE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2085\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2086\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2087\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2088\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2089\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2090\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2091\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2092\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2093\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2094\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_raise_exceptions_for_gated_repo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2095\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2096\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2097\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2098\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2099\u001b[0m     commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[1;32m   2100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/transformers/utils/hub.py:425\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    421\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to access a gated repo.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMake sure to have access to it at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    422\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    423\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 425\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    426\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a local folder and is not a valid model identifier \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    427\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlisted on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf this is a private repository, make sure to pass a token \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    428\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhaving permission to this repo either by logging in with `huggingface-cli login` or by passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    429\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`token=<your_token>`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    430\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RevisionNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    433\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid git identifier (branch name, tag name or commit id) that exists \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    434\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor this model name. Check the model page at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    435\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for available revisions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    436\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: cl-tohoku/bert-japanese-whole-word-masking is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"
     ]
    }
   ],
   "source": [
    "# CSVファイルのパスリストを作成\n",
    "filepaths = [os.path.join('text', f'review_{i}.csv') for i in range(19)]\n",
    "\n",
    "# データの読み込み\n",
    "reviews, labels = load_and_preprocess_data(filepaths)\n",
    "\n",
    "# トークナイザーの初期化\n",
    "tokenizer = BertTokenizer.from_pretrained('cl-tohoku/bert-japanese-whole-word-masking')\n",
    "\n",
    "# データセットの作成\n",
    "dataset = ReviewDataset(reviews, labels, tokenizer, max_len=500)\n",
    "data_loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# 前処理したデータを表示\n",
    "for i, data in enumerate(data_loader):\n",
    "    print(f\"Review {i}:\")\n",
    "    print(f\"Text: {data['review_text'][0]}\")\n",
    "    print(f\"Input IDs: {data['input_ids'][0]}\")\n",
    "    print(f\"Attention Mask: {data['attention_mask'][0]}\")\n",
    "    print(f\"Label: {data['label'][0]}\")\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. CSVファイルパスリストの作成**\n",
    "\n",
    "```python\n",
    "filepaths = [f'review_{i}.csv' for i in range(12)]\n",
    "```\n",
    "\n",
    "- `[f'review_{i}.csv' for i in range(12)]`: 0から11までのインデックスを持つリストを作成し, 各要素に `f'review_{i}.csv'` という形式の文字列を代入します. \n",
    "    - `f'review_{i}.csv'`: 文字列フォーマットを用いて, `i` を動的に文字列に埋め込みます. \n",
    "- 結果的に, `filepaths` リストには以下のファイルパスが含まれます. \n",
    "    - `review_0.csv`\n",
    "    - `review_1.csv`\n",
    "    - ...\n",
    "    - `review_10.csv`\n",
    "    - `review_11.csv`\n",
    "\n",
    "**2. データの読み込み**\n",
    "\n",
    "```python\n",
    "reviews, labels = load_and_preprocess_data(filepaths)\n",
    "```\n",
    "\n",
    "- `load_and_preprocess_data` 関数を呼び出し, `filepaths` リストを引数として渡します. \n",
    "- 関数から返された口コミデータと感情ラベルを, それぞれ `reviews` と `labels` 変数に格納します. \n",
    "\n",
    "**3. トークナイザーの初期化**\n",
    "\n",
    "```python\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "```\n",
    "\n",
    "- `BertTokenizer.from_pretrained('bert-base-uncased')`: 事前に学習済みのBERTトークナイザ `bert-base-uncased` をロードし, `tokenizer` 変数に格納します. \n",
    "- このトークナイザは, 日本語を含む様々な言語のテキストを, Transformerモデルで利用できる形式に変換するために使用されます. \n",
    "\n",
    "**4. データセットの作成**\n",
    "\n",
    "```python\n",
    "dataset = ReviewDataset(reviews, labels, tokenizer, max_len=160)\n",
    "```\n",
    "\n",
    "- `ReviewDataset` クラスを使って, `reviews`, `labels`, `tokenizer`, `max_len` を引数として `dataset` インスタンスを作成します. \n",
    "    - `reviews`: 前処理済みの口コミデータ\n",
    "    - `labels`: 感情ラベル\n",
    "    - `tokenizer`: トークナイザ\n",
    "    - `max_len`: 最大トークン長（160に設定）\n",
    "- `ReviewDataset` クラスは, Transformerライブラリで利用できる形式のデータセットを生成します. \n",
    "\n",
    "**5. データローダーの作成**\n",
    "\n",
    "```python\n",
    "data_loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "```\n",
    "\n",
    "- `DataLoader` クラスを使って, `dataset` インスタンスを基に `data_loader` インスタンスを作成します. \n",
    "    - `batch_size=1`: 1つのバッチに1つのデータのみを含めます. \n",
    "    - `shuffle=False`: データの順番をランダムにシャッフルしません. \n",
    "- `data_loader` は, ミニバッチ単位でデータを効率的に処理するためのツールです. \n",
    "\n",
    "**6. 前処理したデータの表示**\n",
    "\n",
    "```python\n",
    "for i, data in enumerate(data_loader):\n",
    "    print(f\"Review {i}:\")\n",
    "    print(f\"Text: {data['review_text'][0]}\")\n",
    "    print(f\"Input IDs: {data['input_ids'][0]}\")\n",
    "    print(f\"Attention Mask: {data['attention_mask'][0]}\")\n",
    "    print(f\"Label: {data['label'][0]}\")\n",
    "    print(\"=\"*50)\n",
    "```\n",
    "\n",
    "- `for i, data in enumerate(data_loader)`: `data_loader` からミニバッチ単位でデータをループ処理します. \n",
    "    - `i`: バッチのインデックス\n",
    "    - `data`: ミニバッチデータ\n",
    "- 各バッチについて, 以下の情報を表示します. \n",
    "    - `Review {i}`: バッチのインデックス\n",
    "    - `Text`: 元の口コミテキスト\n",
    "    - `Input IDs`: トークンIDのリスト\n",
    "    - `Attention Mask`: アテンションマスクのリスト\n",
    "    - `Label`: 感情ラベル\n",
    "    - `=` * 50: 区切り線\n",
    "- この処理により, 前処理された口コミデータがどのようにTransformerモデルに入力されるのかを確認することができます. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "# モデルの定義\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "  device = torch.device('mps')\n",
    "else:\n",
    "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. モデルの定義**\n",
    "\n",
    "```python\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "```\n",
    "\n",
    "- `BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)`: 事前に学習済みのBERTモデル `bert-base-uncased` をロードし, `model` 変数に格納します. \n",
    "    - `BertForSequenceClassification`: テキスト分類タスクに特化したBERTモデルクラス\n",
    "    - `'bert-base-uncased'`: 事前に学習済みのモデル名\n",
    "    - `num_labels=2`: 出力ラベルの数を2つに設定（ポジティブ/ネガティブの2クラス分類）\n",
    "- このモデルは, 2つの文章を比較したり, 文章の感情を分析したりするようなタスクに適しています. \n",
    "\n",
    "**2. デバイス設定**\n",
    "\n",
    "```python\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "  device = torch.device('mps')\n",
    "else:\n",
    "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "model = model.to(device)\n",
    "```\n",
    "\n",
    "- このコードは, モデルを実行するデバイスを設定します. \n",
    "    - `torch.device('cuda')`: GPUを利用する場合\n",
    "    - `torch.device('cpu')`: CPUを利用する場合\n",
    "- 処理速度向上のため, GPUが利用可能であれば優先的に利用するようにしています. \n",
    "- `model.to(device)`: モデルを指定されたデバイスに移動します. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.42105263157894735\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.42      1.00      0.59         8\n",
      "    Positive       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.42        19\n",
      "   macro avg       0.21      0.50      0.30        19\n",
      "weighted avg       0.18      0.42      0.25        19\n",
      "\n",
      "Review 1:\n",
      "Text: 鮨 さいとうに4回目の訪問. 今回はランチでディナー同様, 摘みありのコースを注文させて頂きました. タイトルにもありますが, 気付けば2年ぶりの訪問. 食べ歩きをしてると2.3年再訪してないお店が沢山出てきますが, 再訪してもそれほど月日が経ってないように感じるのは私だけでしょうか. . 笑さて, 本題のお料理ですが, 摘み握り共に何を食べても美味しく, 今回も流石の安定感です. 何一つとして気になるものはありません. また, この日は以前よりずっと飲んでみたかった黒龍酒造の『ESHIKOTO』を頂きました. 超入手困難なスパークリングの日本酒です. 当たりがとてもドライで食事の邪魔を一切しないテイスト. 香りはほのかに日本酒を感じさせます. こんな貴重なお酒を入るのはさすが齋藤さんですね. 次回はいつ来れるか分かりませんが, またぜひ伺いたいです. ご馳走様でした. \n",
      "True Label: Positive\n",
      "Predicted Label: Negative\n",
      "Probabilities: Positive - 0.3823, Negative - 0.6177\n",
      "==================================================\n",
      "Review 2:\n",
      "Text: 個人的に, 都内では大好きなお店の一つ. 3度目の訪問ですが, さいとうさんは時期が変わっても毎度ツマミも握りも安定感があり素晴らしいですね. この日, 初めて頂く「穴子の白焼き」は今まで食べた事ないくらい身がぷりぷりしており, 特に印象深い一品でした. さらに1人30,000円ちょっとと, 内容対してコスパの高さも嬉しいですね. また, 昼でも夜でも時期を変えて伺いたいです. ご馳走様でした. \n",
      "True Label: Positive\n",
      "Predicted Label: Negative\n",
      "Probabilities: Positive - 0.3815, Negative - 0.6185\n",
      "==================================================\n",
      "Review 3:\n",
      "Text: 今月2度目のさいとうさんへ. 今回はランチ利用です. 握り15貫のみのコースを頂きました. （人によっては少し量が少なく感じる方もいらっしゃるかもしれません. ）マグロ中心に今回も大変美味しく頂きました. 価格も1人16,500円と, とても良心的な価格でびっくりしました. この立地でこの価格だと, そりゃ中々予約取れないわかです. また伺います. ご馳走様でした. \n",
      "True Label: Positive\n",
      "Predicted Label: Negative\n",
      "Probabilities: Positive - 0.3872, Negative - 0.6128\n",
      "==================================================\n",
      "Review 4:\n",
      "Text: 言わずと知れた4年連続食べログゴールド, 2019年まで10年連続ミシュラン3つ星のお店です. 今回はお誘い頂き訪問してきました. その人気ぶりから現在では, 完全会員制を取っており, 一見での予約は不可になっております. さて, お寿司に関しては非常に素晴らしいです. できることなら会員になって通い続けたいお店です. ネタもシャリもとても個人的に好みでした. 特にシャリは酢と塩味が強く無く, 割と万人受けするかな, といった印象. 次いついけるか分かりませんが, ぜひまた伺いたいです. ご馳走様でした. \n",
      "True Label: Positive\n",
      "Predicted Label: Negative\n",
      "Probabilities: Positive - 0.3768, Negative - 0.6232\n",
      "==================================================\n",
      "Review 5:\n",
      "Text: 楽しい時間を過ごす事が出来ました. また是非伺いたいと思います. ご馳走様でした. \n",
      "True Label: Positive\n",
      "Predicted Label: Negative\n",
      "Probabilities: Positive - 0.4047, Negative - 0.5953\n",
      "==================================================\n",
      "Review 6:\n",
      "Text: 今回は個室で『鮨さいとう』二番手の沼尾さんの鮨を堪能しました. 仕事も所作も丁寧で, 安心して食に集中出来ました. 酢飯の酸度・塩味・硬さ等かなり好み. ネタも間違いのないものばかりでした！ご馳走様でした. \n",
      "True Label: Positive\n",
      "Predicted Label: Negative\n",
      "Probabilities: Positive - 0.3922, Negative - 0.6078\n",
      "==================================================\n",
      "Review 7:\n",
      "Text: 最高峰と言われるお鮨屋さんお鮨だけを楽しみに行くのではなく, 大将との会話, 雰囲気, 異空間を味わいながら食べるお鮨屋さん. お鮨は美味しい. 特にこれがというのはないが, 美味しい. 1番驚いたのは鮨屋とは思えない独特な雰囲気があるお店. 大将とお客さんの一体感のある空間でお鮨を楽しめます. 大将の人柄で人気なっているお店. お鮨だけを食べに行くには勿体無いいいお鮨屋さんでした. さいとうさんのにぎるお鮨を食べられたことに感謝. \n",
      "True Label: Positive\n",
      "Predicted Label: Negative\n",
      "Probabilities: Positive - 0.3780, Negative - 0.6220\n",
      "==================================================\n",
      "Review 8:\n",
      "Text: 念願の大将のお席!カツオのたたきはこれまで食べた1番の美味しさ. 熟成されたねっとり感で, 旨みがギュッ!パサつき全く無い仕上がり. 優しい, 鮑, たこ, など, おつまみも最高!握りはふわっと優しいシャリとの一体感が素晴らしい. 最初のあたたかめのシャリと白身が新鮮で美味. 甘すぎないツメもよく, 蛤や穴子も, 素材の美味しさか際立つ！来年ですが, また, 次回も楽しみ！\n",
      "True Label: Positive\n",
      "Predicted Label: Negative\n",
      "Probabilities: Positive - 0.3692, Negative - 0.6308\n",
      "==================================================\n",
      "Review 9:\n",
      "Text: 日本の鮨店, 最高峰の1つ. 超予約困難店です. 1度訪れてみたかったお店ですが, 常連様にお誘い頂き, 伺うことができました. こちらのお店は・10年連続ミシュラン3つ星も会員制にするために返上・食べログGOLD(全国で30店舗ほどのみ)連続獲得・世界のグルメガイド, フランスの「ラ・リスト2024」で99.5点の日本最高評価を獲得. また, 世界でも上位7位. ・新規予約は基本受付しておらず, 食オクでのオークションのみ・食オクでは1席40万円や70万円の値がつくこともお店は六本木一丁目駅直結のアークヒルズタワー1階にあります. やや分かりづらい場所です. 店内は個室が2つあり, 個室内はL字のカウンター8席ほど. この日は, 2番手の沼尾大将の貸切会でした. お鮨はもちろんですが蒸し鮑と蛸の桜煮の旨味が凄く, 鰹の皮目がパリッとした火入れと最初のつまみがとても美味しく感動しました. つまみも握りもハイクオリティですが会話も楽しく雰囲気づくりも抜群. 価格は高いですが, 他のお鮨やさんと一線を画すほど美味しく満足度は高いです. 純粋に美味しくて, また来たいなぁと思える素晴らしいお鮨でした！ご馳走様でした！\n",
      "True Label: Positive\n",
      "Predicted Label: Negative\n",
      "Probabilities: Positive - 0.4028, Negative - 0.5972\n",
      "==================================================\n",
      "Review 10:\n",
      "Text: 日本最高峰のお鮨のお店に, 幸運にもお誘いいただき, 訪問することができました. この日は, 個室の沼尾大将に握っていただきました. 貸切ということもあり, リラックスして, 美味しいお酒を飲みながら, 最高のお鮨を食べて, 幸せな時間を過ごすことができました. ご馳走様でした！！！\n",
      "True Label: Positive\n",
      "Predicted Label: Negative\n",
      "Probabilities: Positive - 0.3710, Negative - 0.6290\n",
      "==================================================\n",
      "Review 11:\n",
      "Text: 食べログお鮨ランキング1位にしてミシュラン3つ星, 泣く子もだまるさいとう, 2月に続いて3月もさいとうさんへ, ミシュラン3つ星を取ったのは随分前だが最近になっても美味しさが増している気がする. \n",
      "True Label: Positive\n",
      "Predicted Label: Negative\n",
      "Probabilities: Positive - 0.3809, Negative - 0.6191\n",
      "==================================================\n",
      "Review 12:\n",
      "Text: 日本最高峰のお寿司と聞いていたのですが, お値段に比べてあまり美味しいと思いませんでした. \n",
      "True Label: Negative\n",
      "Predicted Label: Negative\n",
      "Probabilities: Positive - 0.3909, Negative - 0.6091\n",
      "==================================================\n",
      "Review 13:\n",
      "Text: イベントの際にお邪魔しました. 少し値段が高い気がします. \n",
      "True Label: Negative\n",
      "Predicted Label: Negative\n",
      "Probabilities: Positive - 0.4003, Negative - 0.5997\n",
      "==================================================\n",
      "Review 14:\n",
      "Text: イカやタコが美味しかったですが, マグロは微妙でした.\n",
      "True Label: Negative\n",
      "Predicted Label: Negative\n",
      "Probabilities: Positive - 0.4056, Negative - 0.5944\n",
      "==================================================\n",
      "Review 15:\n",
      "Text: お値段が高いので, もう少し美味しいものが食べたかったです.\n",
      "True Label: Negative\n",
      "Predicted Label: Negative\n",
      "Probabilities: Positive - 0.4012, Negative - 0.5988\n",
      "==================================================\n",
      "Review 16:\n",
      "Text: 雰囲気が少し怖く感じました.\n",
      "True Label: Negative\n",
      "Predicted Label: Negative\n",
      "Probabilities: Positive - 0.3968, Negative - 0.6032\n",
      "==================================================\n",
      "Review 17:\n",
      "Text: 味がイマイチだったので, また行くかは検討中です.\n",
      "True Label: Negative\n",
      "Predicted Label: Negative\n",
      "Probabilities: Positive - 0.4082, Negative - 0.5918\n",
      "==================================================\n",
      "Review 18:\n",
      "Text: お値段が高いので, 期待していたほど美味しくなかったです.\n",
      "True Label: Negative\n",
      "Predicted Label: Negative\n",
      "Probabilities: Positive - 0.4024, Negative - 0.5976\n",
      "==================================================\n",
      "Review 19:\n",
      "Text: 電話対応が悪かったので, また行くかは検討中です.\n",
      "True Label: Negative\n",
      "Predicted Label: Negative\n",
      "Probabilities: Positive - 0.3986, Negative - 0.6014\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/master/.pyenv/versions/3.12.2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/master/.pyenv/versions/3.12.2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/master/.pyenv/versions/3.12.2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# モデルの評価\n",
    "def evaluate_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    probabilities = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            input_ids = data['input_ids'].to(device)\n",
    "            attention_mask = data['attention_mask'].to(device)\n",
    "            labels = data['label'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            probs = torch.nn.functional.softmax(logits, dim=1)\n",
    "\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            predictions.extend(preds.cpu().numpy())  # CPUに移動してからnumpyに変換\n",
    "            true_labels.extend(labels.cpu().numpy())  # CPUに移動してからnumpyに変換\n",
    "            probabilities.extend(probs.cpu().numpy())  # CPUに移動してからnumpyに変換\n",
    "\n",
    "    return predictions, true_labels, probabilities\n",
    "\n",
    "# モデルの評価\n",
    "predictions, true_labels, probabilities = evaluate_model(model, data_loader, device)\n",
    "\n",
    "# 評価結果の表示\n",
    "accuracy = sum([1 if pred == true else 0 for pred, true in zip(predictions, true_labels)]) / len(true_labels)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(classification_report(true_labels, predictions, target_names=['Negative', 'Positive']))\n",
    "\n",
    "# 各データの予測結果を表示\n",
    "for i, (review, true_label, pred_label, prob) in enumerate(zip(reviews, true_labels, predictions, probabilities)):\n",
    "    print(f\"Review {i+1}:\")\n",
    "    print(f\"Text: {review}\")\n",
    "    print(f\"True Label: {'Positive' if true_label == 1 else 'Negative'}\")\n",
    "    print(f\"Predicted Label: {'Positive' if pred_label == 1 else 'Negative'}\")\n",
    "    print(f\"Probabilities: Positive - {prob[1]:.4f}, Negative - {prob[0]:.4f}\")\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この出力結果は, BERTモデルを使ったテキスト分類（感情分析）の結果を表示しています. 以下に各部分の説明をします. \n",
    "\n",
    "### 評価結果の表示\n",
    "まず, モデルの全体的な評価結果が表示されます. \n",
    "\n",
    "```plaintext\n",
    "Accuracy: 0.42105263157894735\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "    Negative       0.42      1.00      0.59         8\n",
    "    Positive       0.00      0.00      0.00        11\n",
    "\n",
    "    accuracy                           0.42        19\n",
    "   macro avg       0.21      0.50      0.30        19\n",
    "weighted avg       0.18      0.42      0.25        19\n",
    "```\n",
    "\n",
    "#### 各指標の説明\n",
    "- **Accuracy**: 全体の正解率. ここでは約42%です. \n",
    "- **Precision**: 予測が正解である割合. Negativeクラスでは42%, Positiveクラスでは0%. \n",
    "- **Recall**: 実際の正解データに対して正しく予測された割合. Negativeクラスでは100%, Positiveクラスでは0%. \n",
    "- **F1-score**: PrecisionとRecallの調和平均. Negativeクラスでは0.59, Positiveクラスでは0.00. \n",
    "- **Support**: 各クラスの実際のデータ数. Negativeクラスは8, Positiveクラスは11. \n",
    "\n",
    "### 各レビューの予測結果の表示\n",
    "次に, 各レビューの予測結果が個別に表示されます. \n",
    "\n",
    "#### 表示形式の説明\n",
    "```plaintext\n",
    "Review {i}:\n",
    "Text: {review text}\n",
    "True Label: {'Positive' if true_label == 1 else 'Negative'}\n",
    "Predicted Label: {'Positive' if pred_label == 1 else 'Negative'}\n",
    "Probabilities: Positive - {prob[1]:.4f}, Negative - {prob[0]:.4f}\n",
    "==================================================\n",
    "```\n",
    "- **Review {i}**: レビューのインデックス. \n",
    "- **Text**: レビューのテキスト. \n",
    "- **True Label**: レビューの実際のラベル（PositiveまたはNegative）. \n",
    "- **Predicted Label**: モデルによる予測ラベル（PositiveまたはNegative）. \n",
    "- **Probabilities**: モデルによる予測確率（PositiveとNegativeの確率）. \n",
    "\n",
    "### 各レビューの予測結果の例\n",
    "```plaintext\n",
    "Review 1:\n",
    "Text: 鮨 さいとうに4回目の訪問. ...\n",
    "True Label: Positive\n",
    "Predicted Label: Negative\n",
    "Probabilities: Positive - 0.4394, Negative - 0.5606\n",
    "==================================================\n",
    "```\n",
    "- **Review 1**: インデックス1のレビュー. \n",
    "- **Text**: レビューの内容. \n",
    "- **True Label**: 実際のラベルはPositive. \n",
    "- **Predicted Label**: モデルの予測はNegative. \n",
    "- **Probabilities**: Positiveの確率が約0.4394, Negativeの確率が約0.5606. \n",
    "\n",
    "### 全体的な結果の解析\n",
    "- **Accuracy**が42.1%であることから, 全体的にモデルの予測精度は低いです. \n",
    "- **Negative**クラスは全て正しく予測されましたが, **Positive**クラスは全て誤った予測となっています. \n",
    "- **Precision**や**Recall**が**Positive**クラスで0%となっているため, このモデルは**Positive**クラスを全く識別できていません. \n",
    "- **Probabilities**を見ると, 多くのレビューでPositiveとNegativeの確率が近い値になっており, モデルがどちらに分類すべきか確信を持っていないことが伺えます. \n",
    "\n",
    "### 改善方法\n",
    "- **データセットのバランスを改善する**: ポジティブとネガティブのレビューの数を均等にすることで, モデルがどちらのクラスも正しく学習できるようにします. \n",
    "- **モデルの再トレーニング**: より多くのデータを使ってモデルを再トレーニングし, 過学習やデータ不足を防ぎます. \n",
    "- **ハイパーパラメータのチューニング**: 学習率やバッチサイズなどのハイパーパラメータを調整してモデルの性能を向上させます. \n",
    "- **データの前処理の改善**: データの前処理を見直し, モデルがより良い特徴を学習できるようにします. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/master/.pyenv/versions/3.12.2/lib/python3.12/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n",
      "Train loss 1.0304685235023499 accuracy 0.6666666865348816\n",
      "Val   loss 0.3965409994125366 accuracy 1.0\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n",
      "Train loss 0.40633469820022583 accuracy 0.8888888955116272\n",
      "Val   loss 0.3124300241470337 accuracy 1.0\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n",
      "Train loss 0.3297441452741623 accuracy 0.8888888955116272\n",
      "Val   loss 0.19672556221485138 accuracy 1.0\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n",
      "Train loss 0.27607132494449615 accuracy 0.8888888955116272\n",
      "Val   loss 0.11254560947418213 accuracy 1.0\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n",
      "Train loss 0.22440343722701073 accuracy 0.8888888955116272\n",
      "Val   loss 0.07830469310283661 accuracy 1.0\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n",
      "Train loss 1.4837076589465141 accuracy 0.8888888955116272\n",
      "Val   loss 0.07684759050607681 accuracy 1.0\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n",
      "Train loss 0.22204866632819176 accuracy 0.8888888955116272\n",
      "Val   loss 0.1286872774362564 accuracy 1.0\n",
      "\n",
      "Epoch 8/10\n",
      "----------\n",
      "Train loss 0.2333529144525528 accuracy 0.8888888955116272\n",
      "Val   loss 0.15087705850601196 accuracy 1.0\n",
      "\n",
      "Epoch 9/10\n",
      "----------\n",
      "Train loss 0.2332834228873253 accuracy 0.8888888955116272\n",
      "Val   loss 0.15156474709510803 accuracy 1.0\n",
      "\n",
      "Epoch 10/10\n",
      "----------\n",
      "Train loss 0.22650428861379623 accuracy 0.8888888955116272\n",
      "Val   loss 0.14722134172916412 accuracy 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# データの分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# トークナイザーの初期化\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# データセットの作成\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, reviews, labels, tokenizer, max_len):\n",
    "        self.reviews = reviews\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        review = str(self.reviews[item])\n",
    "        label = self.labels[item]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            review,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'review_text': review,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# トレーニングと検証のデータセット\n",
    "train_dataset = ReviewDataset(\n",
    "    reviews=train_df.text.to_numpy(),\n",
    "    labels=train_df.label.to_numpy(),\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=500\n",
    ")\n",
    "\n",
    "val_dataset = ReviewDataset(\n",
    "    reviews=val_df.text.to_numpy(),\n",
    "    labels=val_df.label.to_numpy(),\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=500\n",
    ")\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_data_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# モデルのファインチューニング\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "def train_epoch(\n",
    "  model, \n",
    "  data_loader, \n",
    "  loss_fn, \n",
    "  optimizer, \n",
    "  device, \n",
    "  scheduler, \n",
    "  n_examples\n",
    "):\n",
    "    model = model.train()\n",
    "\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for data in data_loader:\n",
    "        input_ids = data['input_ids'].to(device)\n",
    "        attention_mask = data['attention_mask'].to(device)\n",
    "        labels = data['label'].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "\n",
    "        _, preds = torch.max(outputs.logits, dim=1)\n",
    "        loss = loss_fn(outputs.logits, labels)\n",
    "\n",
    "        correct_predictions += torch.sum(preds == labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return correct_predictions.float() / n_examples, np.mean(losses)\n",
    "\n",
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "    model = model.eval()\n",
    "\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            input_ids = data['input_ids'].to(device)\n",
    "            attention_mask = data['attention_mask'].to(device)\n",
    "            labels = data['label'].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "\n",
    "            _, preds = torch.max(outputs.logits, dim=1)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    return correct_predictions.float() / n_examples, np.mean(losses)\n",
    "\n",
    "# モデルの初期化\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "model = model.to(device)\n",
    "\n",
    "EPOCHS = 10\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "# トレーニングループ\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    train_acc, train_loss = train_epoch(\n",
    "        model,\n",
    "        train_data_loader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        device,\n",
    "        scheduler,\n",
    "        len(train_df)\n",
    "    )\n",
    "\n",
    "    print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "    val_acc, val_loss = eval_model(\n",
    "        model,\n",
    "        val_data_loader,\n",
    "        loss_fn,\n",
    "        device,\n",
    "        len(val_df)\n",
    "    )\n",
    "\n",
    "    print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
